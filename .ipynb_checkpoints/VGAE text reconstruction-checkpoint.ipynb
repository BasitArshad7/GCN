{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "#model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "\n",
    "#text = (\"After Abraham Lincoln won the November 1860 presidential \"\n",
    "#        \"election on an anti-slavery platform, an initial seven \"\n",
    "#        \"slave states declared their secession from the country \"\n",
    "#        \"to form the Confederacy. War broke out in April 1861 \"\n",
    "#        \"when secessionist forces attacked Fort Sumter in South \"\n",
    "#        \"Carolina, just over a month after Lincoln's \"\n",
    "#        \"inauguration.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs = tokenizer(text, return_tensors='pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs['labels'] = inputs.input_ids.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random array of floats in equal dimension to input_ids\n",
    "#rand = torch.rand(inputs.input_ids.shape)\n",
    "# where the random array is less than 0.15, we set true\n",
    "#mask_arr = rand < 0.15\n",
    "#mask_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(inputs.input_ids != 101) * (inputs.input_ids != 102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * (inputs.input_ids != 102)\n",
    "#mask_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create selection from mask_arr\n",
    "#selection = torch.flatten((mask_arr[0]).nonzero()).tolist()\n",
    "#selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply selection index to inputs.input_ids, adding MASK tokens\n",
    "#inputs.input_ids[0, selection] = 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Utility functions for torch.\n",
    "\"\"\"\n",
    "\n",
    "import click, ast, torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### torch specific functions\n",
    "def get_optimizer(name, parameters, lr, l2=0):\n",
    "    if name == 'sgd':\n",
    "        return torch.optim.SGD(parameters, lr=lr, weight_decay=l2)\n",
    "    elif name == 'adam':\n",
    "        return torch.optim.Adam(parameters, weight_decay=l2) # use default lr\n",
    "    elif name == 'adamax':\n",
    "        return torch.optim.Adamax(parameters, weight_decay=l2) # use default lr\n",
    "    elif name == 'adadelta':\n",
    "        return torch.optim.Adadelta(parameters, lr=lr, weight_decay=l2)\n",
    "    else:\n",
    "        raise Exception(\"Unsupported optimizer: {}\".format(name))\n",
    "\n",
    "\n",
    "def visualize_performance(performance, repo_name, show=False):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # accuracy\n",
    "    ax = plt.subplot(3, 2, 1)\n",
    "    ax.set_title('Accuracy')\n",
    "    ax.plot(performance['acc_test'], label='test')\n",
    "    ax.plot(performance['acc_train'], label='train')\n",
    "\n",
    "    ax.set_ylim([0.5, 1])\n",
    "    ax.set_ylabel('%')\n",
    "    ax.set_xlabel('epoch')\n",
    "    plt.legend()\n",
    "\n",
    "    # precision\n",
    "    ax = plt.subplot(3, 2, 2)\n",
    "    ax.set_title('Precision')\n",
    "    ax.plot(performance['prec_test'], label='test')\n",
    "    ax.plot(performance['prec_train'], label='train')\n",
    "\n",
    "    ax.set_ylim([.5, 1])\n",
    "    ax.set_ylabel('%')\n",
    "    ax.set_xlabel('epoch')\n",
    "    plt.legend()\n",
    "\n",
    "    # recall\n",
    "    ax = plt.subplot(3, 2, 3)\n",
    "    ax.set_title('Recall')\n",
    "    ax.plot(performance['recall_test'], label='test')\n",
    "    ax.plot(performance['recall_train'], label='train')\n",
    "\n",
    "    ax.set_ylim([.5, 1])\n",
    "    ax.set_ylabel('%')\n",
    "    ax.set_xlabel('epoch')\n",
    "    plt.legend()\n",
    "\n",
    "    # f1\n",
    "    ax = plt.subplot(3, 2, 4)\n",
    "    ax.set_title('F1')\n",
    "    ax.plot(performance['f1_test'], label='test')\n",
    "    ax.plot(performance['f1_train'], label='train')\n",
    "\n",
    "    ax.set_ylim([.5, 1])\n",
    "    ax.set_ylabel('%')\n",
    "    ax.set_xlabel('epoch')\n",
    "    plt.legend()\n",
    "\n",
    "    # loss\n",
    "    ax = plt.subplot(3, 1, 3)\n",
    "    ax.set_title('loss')\n",
    "    ax.plot(performance['loss'])\n",
    "\n",
    "    ax.set_ylim([0, 0.5])\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    plt.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.35,\n",
    "                        wspace=0.35)\n",
    "\n",
    "    if not show:\n",
    "        plt.savefig(repo_name + 'performance_vis.png')\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "class PythonLiteralOption(click.Option):\n",
    "    def type_cast_value(self, ctx, value):\n",
    "        # Either we denote a range, or a list with precise samples:\n",
    "        # 1) Range:\n",
    "        if 'range' in value:\n",
    "            idx_open = value.find('(')\n",
    "            idx_close = value.find(')')\n",
    "            # Get the range input\n",
    "            range_input = value[idx_open + 1:idx_close].split(',')\n",
    "            # Make it to numbers:\n",
    "            range_input = [int(num) for num in range_input]\n",
    "            try :\n",
    "                return list(range(*range_input))\n",
    "            except:\n",
    "                raise click.BadParameter(value)\n",
    "        else:\n",
    "            try:\n",
    "                return ast.literal_eval(value)\n",
    "            except:\n",
    "                raise click.BadParameter(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# For general use\n",
    "class GCNsimple(nn.Module):\n",
    "    \"\"\" It's a simple version of a GCN module operated on dependency graphs.\"\"\"\n",
    "    def __init__(self,  in_dim, out_dim, use_cuda = False, bias=False):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.use_cuda = use_cuda\n",
    "        self.out_dim = out_dim\n",
    "        self.in_dim = in_dim\n",
    "\n",
    "        self.W = nn.Linear(self.in_dim, self.out_dim, bias=bias)\n",
    "\n",
    "        # self.weight = self.W.weight\n",
    "        # self.bias = self.W.bias\n",
    "\n",
    "    def forward(self, x, lamb, relu=True):\n",
    "        # Push the data through gcn.\n",
    "        Lx = lamb.bmm(x)\n",
    "        LxW = self.W(Lx)\n",
    "        if relu:\n",
    "            gLxW = F.relu(LxW)\n",
    "        else:\n",
    "            gLxW = LxW\n",
    "\n",
    "        return gLxW\n",
    "\n",
    "\n",
    "class GCNModel(nn.Module):\n",
    "    \"\"\" A module that represents the multi-layer GCN model.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_of_layer, input_dimension=1, hidden_dimension=1, bias=False):\n",
    "        super().__init__()\n",
    "        self.num_of_layer = num_of_layer\n",
    "        self.hidden_dimension = hidden_dimension\n",
    "        self.input_dimension = input_dimension\n",
    "        self.all_layer = nn.ModuleList()\n",
    "\n",
    "        if num_of_layer >0:\n",
    "            # first layer.\n",
    "            self.all_layer.append(GCNsimple(input_dimension,\n",
    "                                            hidden_dimension,\n",
    "                                            bias=bias))\n",
    "            for _ in range(num_of_layer - 1):\n",
    "                self.all_layer.append(GCNsimple(hidden_dimension, hidden_dimension))\n",
    "\n",
    "    def forward(self, x, lamb):\n",
    "        for i in range(self.num_of_layer):\n",
    "            x = self.all_layer[i](x, lamb)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.all_layer.parameters()\n",
    "\n",
    "    def cuda(self):\n",
    "        self.all_layer.cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from VGAE https://github.com/DaehanKim/vgae_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGAE(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(VGAE,self).__init__()\n",
    "\t\tself.base_gcn = GraphConvSparse(input_dim, hidden1_dim, activation=F.relu)\n",
    "\t\tself.base2_gcn = GraphConvSparse(hidden1_dim, hidden2_dim, activation=F.relu)\n",
    "\t\tself.gcn_mean = GraphConvSparse(hidden2_dim, hidden3_dim, activation=None)\n",
    "\t\tself.gcn_logstddev = GraphConvSparse(hidden2_dim, hidden3_dim, activation=None)\n",
    "\t\tself.dec_1 = GraphConvSparse(hidden3_dim, hidden2_dim, activation=F.relu)\n",
    "\t\tself.dec_2 = GraphConvSparse(hidden2_dim, hidden1_dim, activation=F.relu)\n",
    "\t\tself.dec_3 = GraphConvSparse(hidden1_dim, output_dim, activation=F.tanh)\n",
    "\t\tself.kl = 0\n",
    "        \n",
    "        \n",
    "\tdef encode(self, X,adj):\n",
    "\t\thidden = self.base_gcn(X,adj)\n",
    "\t\thidden = self.base2_gcn(hidden,adj)\n",
    "\t\tself.mean = self.gcn_mean(hidden,adj)\n",
    "\t\tself.logstd = self.gcn_logstddev(hidden,adj)\n",
    "\t\tgaussian_noise = torch.randn(X.size(0), hidden3_dim)\n",
    "\t\tsampled_z = gaussian_noise*torch.exp(self.logstd) + self.mean\n",
    "\t\tself.kl = (self.logstd ** 2 + self.mean ** 2 - torch.log(self.logstd) - 0.5).sum()\n",
    "\t\tprint(self.kl)\n",
    "\t\treturn sampled_z\n",
    "    \n",
    "\tdef decode(self,Z,adj):\n",
    "\t\tA_pred = self.dec_1(Z,adj)\n",
    "\t\tA_pred = self.dec_2(A_pred,adj)\n",
    "\t\tA_pred = self.dec_3(A_pred,adj)\n",
    "\t\treturn A_pred\n",
    "\n",
    "\tdef forward(self, X,adj):\n",
    "\t\tZ = self.encode(X,adj)\n",
    "\t\tA_pred = self.decode(Z,adj)\n",
    "\t\treturn A_pred\n",
    "\n",
    "class GraphConvSparse(nn.Module):\n",
    "\tdef __init__(self, input_dim, output_dim, activation = F.relu, **kwargs):\n",
    "\t\tsuper(GraphConvSparse, self).__init__(**kwargs)\n",
    "\t\tself.weight = glorot_init(input_dim, output_dim) \n",
    "\t\tself.activation = activation\n",
    "\n",
    "\tdef forward(self, inputs, adj):\n",
    "\t\tx = inputs\n",
    "\t\tx = torch.mm(x,self.weight)\n",
    "\t\tx = torch.mm(adj, x)\n",
    "\t\tif self.activation:\n",
    "\t\t\toutputs = self.activation(x)\n",
    "\t\t\treturn outputs\n",
    "\t\treturn x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def glorot_init(input_dim, output_dim):\n",
    "\tinit_range = np.sqrt(6.0/(input_dim + output_dim))\n",
    "\tinitial = torch.rand(input_dim, output_dim)*2*init_range - init_range\n",
    "\treturn nn.Parameter(initial)\n",
    "\n",
    "\n",
    "class GAE(nn.Module):\n",
    "\tdef __init__(self,input_dim, hidden1_dim,hidden2_dim):\n",
    "\t\tsuper(GAE,self).__init__()\n",
    "\t\tself.base_gcn = GraphConvSparse(input_dim, hidden1_dim)\n",
    "\t\tself.gcn_mean = GraphConvSparse(hidden1_dim, hidden2_dim, activation=lambda x:x)\n",
    "\n",
    "\tdef encode(self, X):\n",
    "\t\thidden = self.base_gcn(X)\n",
    "\t\tz = self.mean = self.gcn_mean(hidden)\n",
    "\t\treturn z\n",
    "\n",
    "\tdef forward(self, X):\n",
    "\t\tZ = self.encode(X)\n",
    "\t\tA_pred = dot_product_decode(Z)\n",
    "\t\treturn A_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 450\n",
    "hidden1_dim = 256\n",
    "hidden2_dim = 128\n",
    "hidden3_dim = 100\n",
    "output_dim = 450\n",
    "use_feature = True\n",
    "num_epoch = 20\n",
    "learning_rate = 0.001\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "def unpack_batch(batch, cuda):\n",
    "    if cuda:\n",
    "        inputs = [Variable(b.cuda()) for b in batch[:10]]\n",
    "        labels = Variable(batch[10].cuda())\n",
    "    else:\n",
    "        inputs = [Variable(b) for b in batch[:10]]\n",
    "        labels = Variable(batch[10])\n",
    "\n",
    "    # To have the possibility to pass custom adjacency matrix and words vectors to the prediction.\n",
    "    inputs += [None, None]  # It will be referenced as [cust_adj, cust_words]\n",
    "    tokens = batch[0]\n",
    "    head = batch[5]\n",
    "    subj_pos = batch[6]\n",
    "    obj_pos = batch[7]\n",
    "    lens = batch[1].eq(0).long().sum(1).squeeze()\n",
    "\n",
    "    return inputs, labels, tokens, head, subj_pos, obj_pos, lens\n",
    "\n",
    "\n",
    "# A helping function.\n",
    "def make_eyes(lambs, lens):\n",
    "    eyes = torch.zeros(lambs.shape)\n",
    "    for i, le in enumerate(lens):\n",
    "        eyes[i,:le, :le] = torch.eye(le)\n",
    "    return eyes\n",
    "\n",
    "\n",
    "class MLM:\n",
    "    def __init__(self, cfg, cuda=False):\n",
    "        # First check if we load the model:\n",
    "        if cfg['load_model']:\n",
    "            assert 'repo_name' in cfg, 'We need a file name to load the model.'\n",
    "            # Get all hyperparameter:\n",
    "            cfg.update(json.load(open(cfg['repo_name'] + 'config.json', 'r')))\n",
    "            # Set cuda:\n",
    "            cfg['cuda'] = cuda\n",
    "            self.cuda = cuda\n",
    "            checkpoint = torch.load(cfg['repo_name'] + 'model_params.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "            # just get the vocab dimensions:\n",
    "            cfg['vocab_len'] = checkpoint['embedding']['weight'].shape[0]\n",
    "            cfg['pos_vocab_len'] = checkpoint['pos_embedding']['weight'].shape[0]\n",
    "            cfg['lemma_vocab_len'] = checkpoint['lemma_embedding']['weight'].shape[0]\n",
    "            # don't need the checkpoints anymmore\n",
    "            del checkpoint\n",
    "\n",
    "            # Vocab initialisation:\n",
    "            self.vocab = Vocab()\n",
    "            self.pos_vocab = Vocab()\n",
    "            self.lemma_vocab = Vocab()\n",
    "\n",
    "            # make random model initialization:\n",
    "            self.random_model_init_(cfg)\n",
    "\n",
    "            # load pretrainded weights:\n",
    "            self.load(cfg['repo_name'], cuda=cfg['cuda'])\n",
    "\n",
    "        else:\n",
    "            # Set cuda:\n",
    "            cfg['cuda'] = cuda\n",
    "            self.cuda = cuda\n",
    "\n",
    "            # We need the vocabs given in cfg:\n",
    "            self.vocab = cfg['vocab']\n",
    "            self.pos_vocab = cfg['pos_vocab']\n",
    "            self.lemma_vocab = cfg['lemma_vocab']\n",
    "\n",
    "            # set up necessary vocab lens:\n",
    "            cfg['vocab_len'] = len(self.vocab)\n",
    "            cfg['pos_vocab_len'] = len(self.pos_vocab)\n",
    "            cfg['lemma_vocab_len'] = len(self.lemma_vocab)\n",
    "\n",
    "            # init parameter:\n",
    "            self.random_model_init_(cfg)\n",
    "\n",
    "            if self.vocab.word_embed is None: self.vocab.init_word_embed(cfg)\n",
    "            self.embedding = self.vocab.word_embed\n",
    "\n",
    "\n",
    "        self.model_type = cfg['model_type']\n",
    "        self.new_model = True\n",
    "\n",
    "        if self.cuda:\n",
    "            self.mp_model.cuda()\n",
    "            #self.output_layer.cuda()\n",
    "            self.embedding.cuda()\n",
    "            #self.first_layer.cuda()\n",
    "            #self.last_layer.cuda()\n",
    "            self.pos_embedding.cuda()\n",
    "            self.word_embedding.cuda()\n",
    "            self.lemma_embedding.cuda()\n",
    "\n",
    "        # Init optimizer:\n",
    "        #params = list(self.model.parameters()) \\\n",
    "        #         + list(self.pos_embedding.parameters()) \\\n",
    "        #         + list(self.word_embedding.parameters()) \\\n",
    "        #         + list(self.lemma_embedding.parameters())\n",
    "                # + list(self.first_layer.parameters()) \\\n",
    "                # + list(self.last_layer.parameters()) \\\n",
    "                # + list(self.output_layer.parameters()) \\\n",
    "\n",
    "        #self.optim = get_optimizer(cfg['optimizer'],\n",
    "        #                                         params,\n",
    "        #                                         cfg['lr'])\n",
    "\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "    def random_model_init_(self, cfg):\n",
    "        assert all(x in cfg for x in ['vocab_len', 'pos_vocab_len',\n",
    "                                      'lemma_vocab_len']), 'Please indicate the dimensions of the vocabularies.'\n",
    "        \n",
    "        # Embedding layer:\n",
    "        self.embedding = nn.Embedding(cfg['vocab_len'], cfg['input_dimension'])\n",
    "\n",
    "        # Trainable word embedding\n",
    "        self.word_embedding = nn.Embedding(cfg['vocab_len'], cfg['word_emb_dim'])\n",
    "        with torch.no_grad(): self.word_embedding.weight[0] = 0. # set '<PAD>' to zero\n",
    "        self.word_embedding.weight = nn.parameter.Parameter(self.word_embedding.weight, requires_grad=True) \n",
    "        # Make it to leaf variable again\n",
    "\n",
    "        # Pos embedding layer\n",
    "        self.pos_embedding = nn.Embedding(cfg['pos_vocab_len'], cfg['pos_emb_dim'])\n",
    "        with torch.no_grad(): self.pos_embedding.weight[0] = 0. # set '<PAD>' to zero\n",
    "        self.pos_embedding.weight = nn.parameter.Parameter(self.pos_embedding.weight, requires_grad=True)\n",
    "\n",
    "        # lemma embedding laayer\n",
    "        self.lemma_embedding = nn.Embedding(cfg['lemma_vocab_len'], cfg['lemma_emb_dim'])\n",
    "        with torch.no_grad(): self.lemma_embedding.weight[0] = 0. # set '<PAD>' to zero\n",
    "        self.lemma_embedding.weight = nn.parameter.Parameter(self.lemma_embedding.weight, requires_grad=True)\n",
    "        \n",
    "        # Add a first layer if wanted:\n",
    "        \n",
    "        #self.first_layer = GCNModel(num_of_layer=1,\n",
    "        #                    input_dimension=cfg['input_dimension'] + cfg['pos_emb_dim'] + cfg[\n",
    "         #                       'word_emb_dim'] + cfg['lemma_emb_dim'],\n",
    "         #                   hidden_dimension=cfg['hidden_dimension'],\n",
    "         #                   bias=cfg['bias'])\n",
    "        print(cfg['input_dimension'] + cfg['pos_emb_dim'] + \n",
    "                                 cfg['word_emb_dim'] + cfg['lemma_emb_dim'])\n",
    "        self.model = VGAE()\n",
    "        self.optim = Adam(self.model.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Set up the model:\n",
    "        #self.mp_model = GCNModel(num_of_layer=cfg['num_of_layer'],\n",
    "        #                         input_dimension=cfg['hidden_dimension'],\n",
    "        #                         hidden_dimension=cfg['hidden_dimension'],\n",
    "        #                         bias=cfg['bias']\n",
    "         #                        )\n",
    "\n",
    "        # Last layer\n",
    "        #self.last_layer = GCNModel(num_of_layer=1,\n",
    "        #                           input_dimension=cfg['hidden_dimension'],\n",
    "         #                          hidden_dimension=cfg['hidden_dimension'],\n",
    "          #                         bias=cfg['bias'])\n",
    "        # Output layer:\n",
    "\n",
    "        #self.output_layer = nn.Linear(cfg['hidden_dimension'],\n",
    "        #                              cfg['num_of_classes'],\n",
    "        #                              bias=cfg['bias'])\n",
    "\n",
    "    def update(self, batch):\n",
    "        # Free the optimizer:\n",
    "        #self.optim.zero_grad()\n",
    "        # Unwrap batch\n",
    "        batch_loss = []\n",
    "        \n",
    "        \n",
    "        lambs, poss, texts, labels, lens, _, lemmas = batch[:7]\n",
    "        lambs = lambs.to(torch.int64)\n",
    "            # Adjacency in the first matrix are identity matrices:\n",
    "            #eyes = make_eyes(lambs, lens)\n",
    "\n",
    "            # Set on cuda:\n",
    "#             if self.cuda:\n",
    "#                 lambs = lambs.cuda()\n",
    "#                 texts = texts.cuda()\n",
    "#                 labels = labels.cuda()\n",
    "#                 eyes = eyes.cuda()\n",
    "#                 poss = poss.cuda()\n",
    "#                 lemmas = lemmas.cuda()\n",
    "        #print(np.shape(poss))\n",
    "            # Propagate through the the model\n",
    "            # Embedding layers\n",
    "        \n",
    "            \n",
    "        const_word_vec = self.embedding(texts)\n",
    "        word_vec = self.word_embedding(texts)\n",
    "        pos_vec = self.pos_embedding(poss)\n",
    "        lemma_vec = self.lemma_embedding(lemmas)\n",
    "\n",
    "\n",
    "\n",
    "        #print(np.shape(texts),np.shape(poss),np.shape(lemmas))\n",
    "        #x = torch.cat([texts, poss, lemmas], dim=0).transpose(0,1)\n",
    "\n",
    "       # print(texts[:5],poss[:5],lemmas[:5],x[:5])\n",
    "        x = torch.cat([word_vec, pos_vec, const_word_vec, lemma_vec], dim=2)\n",
    "        #print(np.shape(x))\n",
    "        #x = x[0]\n",
    "        x = x.float()\n",
    "        #print(x[0])\n",
    "        lambs = lambs.float()\n",
    "        #print(np.shape(lambs))\n",
    "\n",
    "        #print(np.shape(x))\n",
    "        #print(np.shape(lambs))\n",
    "        const_word_vec_lab = self.embedding(labels)\n",
    "        word_vec_lab = self.word_embedding(labels)\n",
    "        pos_vec_lab = self.pos_embedding(poss)\n",
    "\n",
    "        lemma_ve_lab = self.lemma_embedding(lemmas)\n",
    "        labels = torch.cat([word_vec_lab, pos_vec_lab, const_word_vec_lab, lemma_ve_lab], dim=2)\n",
    "\n",
    "        #labels = labels[0]\n",
    "        #print(labels)\n",
    "\n",
    "        norm = lambs.shape[0] * lambs.shape[0] / float((lambs.shape[0] * lambs.shape[0] - lambs.sum()) * 2)\n",
    "        \n",
    "        #print(np.shape(x),np.shape(lambs))\n",
    "        for sample in range(len(batch[0])):\n",
    "            #try:\n",
    "            A_pred = self.model(x[sample],lambs[sample])\n",
    "            #print(np.shape(A_pred))\n",
    "            #print(np.shape(labels))\n",
    "            self.optim.zero_grad()\n",
    "            #make_dot(yhat, params=dict(list(model.named_parameters()))).render(\"rnn_torchviz\", format=\"png\")\n",
    "\n",
    "            #pos_weight = float(lambs.shape[0] * lambs.shape[0] - lambs.sum()) / lambs.sum()\n",
    "            #weight_tensor = torch.ones(weight_mask.size(0)) \n",
    "            #weight_tensor[weight_mask] = pos_weight\n",
    "\n",
    "\n",
    "            #for i in A_pred[0]:\n",
    "            #    print(i)\n",
    "            #print(labels)\n",
    "\n",
    "            loss = log_lik = norm*F.cross_entropy(A_pred,labels[sample])\n",
    "            print('loss : ', log_lik)\n",
    "\n",
    "            #kl loss from gpt\n",
    "            #kl_divergence = torch.sum(1 + self.model.logstd - self.model.mean.pow(2) - self.model.logstd.exp())\n",
    "\n",
    "            #loss from vgae paper\n",
    "            #kl_divergence = 0.5/ A_pred.size(0) * (1 + 2*self.model.logstd - self.model.mean**2 - torch.exp(self.model.logstd)**2).sum(1).mean()\n",
    "            loss += self.model.kl\n",
    "            loss.backward(retain_graph=True)\n",
    "            self.optim.step()\n",
    "            batch_loss.append(float(loss.detach()))\n",
    "            #print('avg_loss = ',sum(batch_loss) / len(batch_loss))\n",
    "            print('KLD : ',self.model.kl)\n",
    "            #print ('lgstd, meansq, logstdexp', self.model.logstd, self.model.mean.pow(2), self.model.logstd.exp())\n",
    "            #except:\n",
    "            #    print('weird thing happening')\n",
    "            #    pass\n",
    "           \n",
    "            \n",
    "        #print('loss : ', loss)\n",
    "        #loss_mse = nn.MSELoss()\n",
    "        #output_mse = loss_mse(A_pred.view(-1), labels.view(-1))\n",
    "        #output_mse.backward()\n",
    "        #self.optim.step()\n",
    "        # last layer:\n",
    "        #x = self.last_layer(x, eyes)\n",
    "\n",
    "        # Mean pooling: We expect xTs is of shape (batch_size, seq_len, hidden_dim)\n",
    "        #x = x.sum(1) / x.shape[1]\n",
    "\n",
    "        # Propagate through the last layer:\n",
    "        #x = self.output_layer(x)\n",
    "\n",
    "        # x.shape should be (batch_size, num_of_classes).\n",
    "        # label.shape should be (batch_size).\n",
    "        \n",
    "        #loss_val = self.loss(x, labels.to(torch.float32))\n",
    "\n",
    "        # Do the backward step:\n",
    "        #loss_val.backward()\n",
    "\n",
    "        # And the step \n",
    "        #self.optim.step()\n",
    "\n",
    "        #print('loss_mse : ', output_mse)\n",
    "        return batch_loss \n",
    "\n",
    "    def predict(self, batch, debug=False, custom_vect_input=None):\n",
    "        lambs, poss, texts, labels, lens, _, lemmas = batch[:7]\n",
    "\n",
    "        # Adjacency in the first matrix are identity matrices:\n",
    "        eyes = make_eyes(lambs, lens)\n",
    "\n",
    "        # Set on cuda\n",
    "        if self.cuda:\n",
    "            lambs = lambs.cuda()\n",
    "            texts = texts.cuda()\n",
    "            labels = labels.cuda()\n",
    "            eyes = eyes.cuda()\n",
    "            poss = poss.cuda()\n",
    "            lemmas = lemmas.cuda()\n",
    "        if custom_vect_input is None:\n",
    "            # Embedding layers\n",
    "            const_word_vec = self.embedding(texts)\n",
    "            word_vec = self.word_embedding(texts)\n",
    "            pos_vec = self.pos_embedding(poss)\n",
    "            lemma_vec = self.lemma_embedding(lemmas)\n",
    "\n",
    "            x = torch.cat([word_vec, pos_vec, const_word_vec, lemma_vec], dim=2)\n",
    "        else:\n",
    "            x = custom_vect_input\n",
    "\n",
    "        # first layer:\n",
    "        # Adjacency matrix is the identity matrix.\n",
    "        x = self.first_layer(x, eyes)\n",
    "\n",
    "        # MPNN model\n",
    "        x = self.mp_model(x, lambs)\n",
    "\n",
    "        # last layer:\n",
    "        x = self.last_layer(x, eyes)\n",
    "\n",
    "        # Mean pooling: We expect xTs is of shape (batch_size, seq_len, hidden_dim)\n",
    "        x = x.sum(1) / x.shape[1]\n",
    "\n",
    "        # Propagate through the last layer:\n",
    "        logits = self.output_layer(x)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def load(self, filename, cuda=False):\n",
    "        if cuda:\n",
    "            device = torch.device('cuda')\n",
    "        else:\n",
    "            device = torch.device('cpu')\n",
    "        try:\n",
    "            checkpoint = torch.load(filename + 'model_params.pt', map_location=device)\n",
    "        except BaseException:\n",
    "            print(\"Cannot load model from {}\".format(filename + 'model_params.pt'))\n",
    "            exit()\n",
    "\n",
    "        self.embedding.load_state_dict(checkpoint['embedding'])\n",
    "        self.pos_embedding.load_state_dict(checkpoint['pos_embedding'])\n",
    "        self.word_embedding.load_state_dict(checkpoint['word_embedding'])\n",
    "        self.lemma_embedding.load_state_dict(checkpoint['lemma_embedding'])\n",
    "        self.mp_model.load_state_dict(checkpoint['mp_model'])\n",
    "        #self.output_layer.load_state_dict(checkpoint['output_layer'])\n",
    "        #self.last_layer.load_state_dict(checkpoint['last_layer'])\n",
    "        #self.first_layer.load_state_dict(checkpoint['first_layer'])\n",
    "\n",
    "        self.vocab.load(filename + 'vocab.p')\n",
    "        self.pos_vocab.load(filename + 'pos_vocab.p')\n",
    "        self.lemma_vocab.load(filename + 'lemma_vocab.p')\n",
    "\n",
    "        self.vocab.word_embed = self.embedding\n",
    "        self.pos_vocab.word_embed = self.pos_embedding\n",
    "\n",
    "    def save(self, filename):\n",
    "        params = {\n",
    "            'embedding': self.embedding.state_dict(),\n",
    "            'pos_embedding': self.pos_embedding.state_dict(),\n",
    "            'mp_model': self.mp_model.state_dict(),\n",
    "            #'output_layer': self.output_layer.state_dict(),\n",
    "            #'last_layer': self.last_layer.state_dict(),\n",
    "            #'first_layer': self.first_layer.state_dict(),\n",
    "            'word_embedding': self.word_embedding.state_dict(),\n",
    "            'lemma_embedding': self.lemma_embedding.state_dict()\n",
    "        }\n",
    "        try:\n",
    "            torch.save(params, filename + 'model_params.pt')\n",
    "            self.vocab.save(filename + 'vocab.p')\n",
    "            self.pos_vocab.save(filename + 'pos_vocab.p')\n",
    "            self.lemma_vocab.save(filename + 'lemma_vocab.p')\n",
    "\n",
    "        except BaseException:\n",
    "            print(\"[Warning: Saving failed... continuing anyway.]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450\n"
     ]
    }
   ],
   "source": [
    "mp_trainer = MLM(cfg, cuda=cfg['cuda'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/51 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 0:\n",
      "tensor(inf, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(2.0474, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(inf, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "avg_loss =  nan\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n",
      "tensor(nan, grad_fn=<SumBackward0>)\n",
      "loss :  tensor(nan, grad_fn=<MulBackward0>)\n",
      "KLD :  tensor(nan, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/51 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-675-e90d8af15672>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Train epoch {}:'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmp_trainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 633\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 677\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    678\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-590-9c1ee30dab2f>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mtxt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtxt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m65\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mtoken_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1012\u001b[0m                 \u001b[0merror_handler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_error_handler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m                 \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m                 \u001b[1;31m# This typically happens if a component is not initialized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.transition_parser.Parser.predict\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.transition_parser.Parser.greedy_parse\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\thinc\\model.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[0monly\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstead\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m         \"\"\"\n\u001b[1;32m--> 315\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfinish_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\ml\\tb_framework.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     step_model = ParserStepModel(\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\ml\\parser_model.pyx\u001b[0m in \u001b[0;36mspacy.ml.parser_model.ParserStepModel.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\thinc\\model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    289\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[0;32m    290\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[1;32m--> 291\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"Model\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\thinc\\layers\\chain.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\thinc\\model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    289\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[0;32m    290\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[1;32m--> 291\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"Model\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\thinc\\layers\\chain.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\thinc\\model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    289\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[0;32m    290\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[1;32m--> 291\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"Model\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\thinc\\layers\\chain.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\thinc\\model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    289\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[0;32m    290\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[1;32m--> 291\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"Model\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\thinc\\layers\\with_array.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(model, Xseq, is_train)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mSeqT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeqT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXseq\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSeqT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXseq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRagged\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         return _ragged_forward(\n\u001b[0m\u001b[0;32m     31\u001b[0m             \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mRagged\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRagged\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRagged\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\thinc\\layers\\with_array.py\u001b[0m in \u001b[0;36m_ragged_forward\u001b[1;34m(model, Xr, is_train)\u001b[0m\n\u001b[0;32m     88\u001b[0m ) -> Tuple[Ragged, Callable]:\n\u001b[0;32m     89\u001b[0m     \u001b[0mlayer\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mArrayXd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mArrayXd\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_dX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataXd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdYr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mRagged\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mRagged\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\thinc\\model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    289\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[0;32m    290\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[1;32m--> 291\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"Model\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\thinc\\layers\\concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOutT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mInT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mYs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_list_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\thinc\\layers\\concatenate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOutT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mInT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mYs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_list_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\thinc\\model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    289\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[0;32m    290\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[1;32m--> 291\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"Model\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\thinc\\layers\\chain.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\thinc\\model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    289\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[0;32m    290\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[1;32m--> 291\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"Model\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\thinc\\layers\\hashembed.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(model, ids, is_train)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mseed\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"seed\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhash\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mnV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m         \u001b[0mdrop_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = cfg['epochs']\n",
    "for epoch in tqdm(range(cfg['epochs'] + 1)):\n",
    "    if epoch > int(epochs*0.8):\n",
    "        for g in mp_trainer.optim.param_groups:\n",
    "            g['lr'] = g['lr']/10\n",
    "\n",
    "\n",
    "    if epoch == range(cfg['epochs']):\n",
    "        # It's the last epoch, don't train again.\n",
    "        break\n",
    "\n",
    "    print('Train epoch {}:'.format(epoch))\n",
    "    epoch_loss = []\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        loss = mp_trainer.update(batch)\n",
    "        epoch_loss += loss\n",
    "        if i % 10 == 0:\n",
    "            print('avg_loss = ',sum(epoch_loss) / len(epoch_loss))\n",
    "    #performance['loss'].append(np.mean(np.array(epoch_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "class Vocab(object):\n",
    "\n",
    "    def __init__(self, filename='', load=False, threshold=5):\n",
    "        if load:\n",
    "            assert os.path.exists(filename), \"Vocab file does not exist at \" + filename\n",
    "\n",
    "            self.id2word, self.word2id = self.load(filename)\n",
    "            self.size = len(self.id2word)\n",
    "            self.threshold = threshold\n",
    "            self.wordCounter = None\n",
    "        else:\n",
    "            self.id2word, self.word2id = {}, {}\n",
    "            self.size = 0\n",
    "            self.threshold = threshold\n",
    "            # We always add some custom tokens into the vocabulary.\n",
    "            self.add_words(\n",
    "                {'<PAD>': float('inf'), '<UNK>': float('inf'),'<MSK>' : 103})\n",
    "        self.word_embed = None\n",
    "\n",
    "    def add_words(self, counterOfTokens):\n",
    "        for item, value in counterOfTokens.items():\n",
    "            if value >= self.threshold:\n",
    "                if item not in self.word2id:\n",
    "                    # add it to the vocab\n",
    "                    self.word2id[item] = self.size\n",
    "                    self.id2word[self.size] = item\n",
    "                    self.size += 1\n",
    "\n",
    "    def load(self, filename):\n",
    "        with open(filename, 'rb') as infile:\n",
    "            id2word = pickle.load(infile)\n",
    "            word2id = {word:id for id, word in id2word.items()}\n",
    "            self.id2word, self.word2id = id2word, word2id\n",
    "            self.size = len(self.id2word)\n",
    "\n",
    "        return id2word, word2id\n",
    "\n",
    "    def save(self, filename):\n",
    "        if os.path.exists(filename):\n",
    "            os.remove(filename)\n",
    "           \n",
    "        with open(filename, 'wb') as outfile:\n",
    "            pickle.dump(self.id2word, outfile)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "\n",
    "    def init_word_embed(self, cfg, cache_dir='datasets/.word_vectors_cache'):\n",
    "        if cfg['word_vectors'] == 'Word2Vec':\n",
    "            from torchnlp.word_to_vector import FastText\n",
    "            all_word_vector = FastText(language=cfg['language'], cache=cache_dir, aligned=True)\n",
    "        else:\n",
    "            raise NotImplementedError('No word_vectors found which are called {}.'.format(cfg['word_vectors']))\n",
    "\n",
    "        # The the vectors only correspond to lower character words:\n",
    "        all_words = [word.lower() for word in list(self.word2id.keys())]\n",
    "        weights = all_word_vector[all_words]\n",
    "        \n",
    "        word_embed = torch.nn.Embedding(*weights.shape, _weight=weights)\n",
    "        #if cfg['device'] == 'cuda':\n",
    "        #    word_embed.cuda()\n",
    "\n",
    "        self.word_embed = word_embed\n",
    "        self.embed_size = weights.shape[1]\n",
    "\n",
    "    def words2vecs(self, words: list):\n",
    "        if not self.word_embed:\n",
    "            raise AttributeError(\"The word embeddings aren't initialized yet.\")\n",
    "        else:\n",
    "            vecs = self.word_embed(torch.tensor(self.map(words), requires_grad=False))\n",
    "        return vecs\n",
    "\n",
    "    def one_hot_ids2vecs(self, ids):\n",
    "        vecs = self.word_embed(ids)\n",
    "        return vecs\n",
    "\n",
    "    def map(self, token_list):\n",
    "        \"\"\"\n",
    "        Map a list of tokens to their ids.\n",
    "        \"\"\"\n",
    "        return [self.word2id[w] if w in self.word2id else self.word2id['<UNK>'] for w in token_list]\n",
    "\n",
    "    def unmap(self, idx_list):\n",
    "        \"\"\"\n",
    "        Unmap ids back to tokens.\n",
    "        \"\"\"\n",
    "        return [self.id2word[idx] for idx in idx_list]\n",
    "    \n",
    "def get_pos_vocab():\n",
    "    \"\"\"\n",
    "    Function to set up a part of speech vocabulary handcrafed.\n",
    "    \"\"\"\n",
    "    pos_id2word = {0: '<PAD>', 1: '<UNK>', 2: 'DET', 3: 'PROPN', 4: 'VERB', 5: 'PART', 6: 'ADJ', 7: 'PUNCT', 8: 'CCONJ',\n",
    "                   9: 'ADP', 10: 'PRON', 11: 'NOUN', 12: 'ADV', 13: 'INTJ', 14: 'NUM', 15: 'X', 16: 'SYM'}\n",
    "    pos_word2id = {word: id for id, word in pos_id2word.items()}\n",
    "    pos_vocab = Vocab()\n",
    "    pos_vocab.id2word = pos_id2word\n",
    "    pos_vocab.word2id = pos_word2id\n",
    "    pos_vocab.size = len(pos_vocab.id2word)\n",
    "    \n",
    "    return pos_vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to load sst data\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class SSTData(Dataset):\n",
    "    def __init__(self,\n",
    "                 sst_data,\n",
    "                 vocab,\n",
    "                 nlp,\n",
    "                 lemma_vocab,\n",
    "                 pos_vocab = None,\n",
    "                 self_loop=True):\n",
    "\n",
    "        self.lemma_vocab = lemma_vocab\n",
    "        self.self_loop = self_loop\n",
    "        \n",
    "        \n",
    "        #sst_data = [sample for sample in sst_data if sample['label'] != 'neutral']\n",
    "        self.sst_data = sst_data\n",
    "        #self.sentiment_vocab = {'negative': 0, 'positive': 1}\n",
    "        \n",
    "        # Add sentencizer in the nlp if not already in it:\n",
    "        if \"sentencizer\" not in nlp.pipe_names:\n",
    "            # sentencizer = nlp.create_pipe(\"sentencizer\")\n",
    "            nlp.add_pipe('sentencizer', first=True)\n",
    "        self.nlp = nlp\n",
    "\n",
    "        self.vocab = vocab\n",
    "        if pos_vocab is None:\n",
    "            self.pos_vocab = get_pos_vocab()\n",
    "        else:\n",
    "            self.pos_vocab = pos_vocab\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        txt = self.sst_data[idx]\n",
    "        if len(txt) <64:\n",
    "            txt = txt + ' PAD'*(64-len(txt))\n",
    "            doc = self.nlp(txt)\n",
    "        elif len(txt) > 64:\n",
    "            txt = txt[:65]\n",
    "            \n",
    "        doc = self.nlp(txt)\n",
    "\n",
    "        token_ids = self.vocab.map([token.text for token in doc])\n",
    "        # create random array of floats in equal dimension to input_ids\n",
    "        rand = torch.rand(np.shape(vocab.map([token.text for token in doc])))\n",
    "        # where the random array is less than 0.15, we set true\n",
    "        mask_arr = rand < 0.15\n",
    "        # create selection from mask_arr\n",
    "        selection = torch.flatten((mask_arr).nonzero()).tolist()\n",
    "        for i in selection: \n",
    "            token_ids[i] = 103\n",
    "            break\n",
    "            \n",
    "            \n",
    "        \n",
    "        # make lambda\n",
    "        adj, root_id = doc_to_adj(doc, directed=False, self_loop=self.self_loop)\n",
    "\n",
    "        lamb = adj\n",
    "\n",
    "        # normalize\n",
    "        denom = lamb.sum(1)\n",
    "        lamb /= denom\n",
    "\n",
    "        # make text indices\n",
    "        \n",
    "        \n",
    "        # make pos ids\n",
    "        pos_ids = self.pos_vocab.map([token.pos_ for token in doc])\n",
    "        for i in selection: \n",
    "            pos_ids[i] = 1\n",
    "            break\n",
    "\n",
    "        # make lemma ids\n",
    "        lemma_ids = self.lemma_vocab.map([token.lemma_ for token in doc])\n",
    "        for i in selection: \n",
    "            lemma_ids[i] = 103\n",
    "            break\n",
    "        # make label\n",
    "        label = self.vocab.map([token.text for token in doc])\n",
    "\n",
    "        return token_ids, pos_ids, lamb, label, root_id, lemma_ids\n",
    "\n",
    "    \n",
    "    def data_check(self):\n",
    "        for idx,sent in enumerate(self.sst_data):\n",
    "            if len(sent) < 10:\n",
    "                self.sst_data.remove(sent)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.sst_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def collate_fn_sentim(batch):\n",
    "    lens = []\n",
    "    for sample in batch:\n",
    "        text, pos, lamb, label, root_id, lemma = sample[:6]\n",
    "        lens.append(lamb.shape[1])\n",
    "\n",
    "    max_len = max(lens)\n",
    "    lambs = []\n",
    "    texts = []\n",
    "    poss = []\n",
    "    lemmas = []\n",
    "    labels = []\n",
    "    root_ids = []\n",
    "    for sample in batch:\n",
    "        text, pos, lamb, label, root_id, lemma = sample[:6]\n",
    "        # Big lamb\n",
    "        lamb_ = torch.zeros(1, max_len, max_len)\n",
    "        lamb_[0, :lamb.shape[0], :lamb.shape[1]] = lamb\n",
    "        lambs.append(lamb_)\n",
    "\n",
    "        # Big text\n",
    "        text_ = torch.zeros(1, max_len, dtype=torch.long)\n",
    "        text_[0, :len(text)] = torch.tensor(text)\n",
    "        texts.append(text_)\n",
    "\n",
    "        # Big pos\n",
    "        pos_ = torch.zeros(1, max_len, dtype=torch.long)\n",
    "        pos_[0, :len(pos)] = torch.tensor(pos)\n",
    "        poss.append(pos_)\n",
    "\n",
    "        # Big lemma\n",
    "        lemma_ = torch.zeros(1, max_len, dtype=torch.long)\n",
    "        lemma_[0, :len(lemma)] = torch.tensor(lemma)\n",
    "        lemmas.append(lemma_)\n",
    "\n",
    "        # Big label:\n",
    "        label_ = torch.zeros(1, max_len, dtype=torch.long)\n",
    "        label_[0, :len(label)] = torch.tensor(label)\n",
    "        labels.append(label_)\n",
    "\n",
    "        # Big root_id:\n",
    "        root_id_ = torch.ones(1) * root_id\n",
    "        root_ids.append(root_id_.long())\n",
    "\n",
    "    lambs = torch.cat(lambs, dim=0)\n",
    "    texts = torch.cat(texts, dim=0)\n",
    "    poss = torch.cat(poss, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    root_ids = torch.cat(root_ids, dim=0)\n",
    "    lemmas = torch.cat(lemmas, dim=0)\n",
    "\n",
    "    return lambs, poss, texts, labels, lens, root_ids, lemmas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def doc_to_adj(sent, directed=True, self_loop=False):\n",
    "    # Sent should be a spacy document. Can also be longer than a sentence.\n",
    "    sent_len = len(sent)\n",
    "    root_id = 1\n",
    "    ret = torch.zeros(sent_len, sent_len, dtype=torch.float32)\n",
    "\n",
    "    for token in sent:\n",
    "        for child in token.children:\n",
    "            if child.i >= sent_len:\n",
    "                #print('Something goes wrong here.')\n",
    "                print(child.i, sent_len, sent, token.i, token)\n",
    "                pass\n",
    "            ret[token.i, child.i] = 1\n",
    "        if token.dep_ == 'ROOT':\n",
    "            root_id = token.i\n",
    "\n",
    "    if not directed:\n",
    "        ret = ret + ret.transpose(0, 1)\n",
    "\n",
    "    if self_loop:\n",
    "        for i in range(sent_len):\n",
    "            ret[i, i] = 1\n",
    "        \n",
    "    return ret, root_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchnlp.datasets import smt_dataset\n",
    "from torchtext.datasets import WikiText103\n",
    "import click\n",
    "\n",
    "import spacy\n",
    "\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\"repo_name\": \"saved_models/sst_model1+/\", \n",
    "       \"epochs\": 50, \"optimizer\": \"adam\", \n",
    "       \"cuda\": False, \n",
    "       \"lr\": 0.0002, \n",
    "       \"num_of_layer\": 3, \n",
    "       \"hidden_dimension\": 10, \n",
    "       \"batch_size\": 1,\n",
    "       \"word_vectors\": \"Word2Vec\",\n",
    "       \"bias\": False, \n",
    "       \"pos_emb_dim\": 30,\n",
    "       \"model_type\": \"gcn\",\n",
    "       \"data_amount\": 1.0, \n",
    "       \"data_set\": \"sst\", \n",
    "       \"word_emb_dim\": 70,\n",
    "       \"lemma_emb_dim\": 50, \n",
    "       \"trainerfilename\": \"saved_models/sst_model1+/\",\n",
    "       \"logfilename\": \"saved_models/sst_model1+/log.txt\",\n",
    "       \"num_of_classes\": 64,\n",
    "       \"language\": \"en\",\n",
    "       \"normalize_lamb\": True,\n",
    "       \"laplacian\": False,\n",
    "       \"input_dimension\": 300,\n",
    "       'load_model' : False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "train_data = Path('datasets/wikitext-103/wiki.train.tokens').read_text(encoding='utf-8')\n",
    "val_data = Path('datasets/wikitext-103/wiki.valid.tokens').read_text(encoding='utf-8')\n",
    "test_data = Path('datasets/wikitext-103/wiki.test.tokens').read_text(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "heading_pattern = '( \\n \\n = [^=]*[^=] = \\n \\n )'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split out train headings and articles\n",
    "train_split = re.split(heading_pattern, train_data)\n",
    "train_headings = [x[7:-7] for x in train_split[1::2]]\n",
    "train_articles = [x for x in train_split[2::2]]\n",
    "\n",
    "# Split out validation headings and articles\n",
    "val_split = re.split(heading_pattern, val_data)\n",
    "val_headings = [x[7:-7] for x in val_split[1::2]]\n",
    "val_articles = [x for x in val_split[2::2]]\n",
    "\n",
    "# Split out test headings and articles\n",
    "test_split = re.split(heading_pattern, test_data)\n",
    "test_headings = [x[7:-7] for x in test_split[1::2]]\n",
    "test_articles = [x for x in test_split[2::2]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [i.split('. ') for i in train_articles]\n",
    "val_data = [i.split('. ') for i in val_articles]\n",
    "test_data = [i.split('. ') for i in test_articles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [item for sublist in test_data for item in sublist]\n",
    "val_data = [item for sublist in val_data for item in sublist]\n",
    "train_data = [item for sublist in train_data for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "data_amount = .005\n",
    "\n",
    "print('Loading data...')\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "cw = Counter()\n",
    "cl = Counter()\n",
    "\n",
    "\n",
    "\n",
    "train_set, test_set = train_data, val_data\n",
    "\n",
    "# only use the the percentage of data we want:\n",
    "train_set = train_set[:int(len(train_set) * data_amount)]\n",
    "test_set = test_set[:int(len(test_set) * data_amount)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Count words:\n",
    "for sample in train_set + test_set: cw += Counter([token.text for token in nlp(sample)])\n",
    "# Count lemma:\n",
    "for sample in train_set + test_set: cl += Counter([token.lemma_ for token in nlp(sample)])\n",
    "\n",
    "vocab = Vocab()\n",
    "lemma_vocab = Vocab()\n",
    "\n",
    "\n",
    "# prepare vocab\n",
    "vocab.add_words(cw)\n",
    "#cfg['input_dimension'] = 300\n",
    "\n",
    "lemma_vocab.add_words(cl)\n",
    "pos_vocab = get_pos_vocab()\n",
    "\n",
    "# Save the parameter:\n",
    "#with open(repo_name + 'config.json', 'w') as fp:\n",
    "#    json.dump(cfg.get_as_dict(), fp)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare data ...\n"
     ]
    }
   ],
   "source": [
    "print('Prepare data ...')\n",
    "\n",
    "\n",
    "train_data = SSTData(\n",
    "    train_set,\n",
    "    vocab,\n",
    "    nlp,\n",
    "    lemma_vocab,\n",
    ")\n",
    "test_data = SSTData(\n",
    "    test_set,\n",
    "    vocab,\n",
    "    nlp,\n",
    "    lemma_vocab,\n",
    ")\n",
    "\n",
    "cfg['vocab'] = vocab\n",
    "cfg['pos_vocab'] = lemma_vocab\n",
    "cfg['lemma_vocab'] = lemma_vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19438"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.data_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19043"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Tower Building of the Little Rock Arsenal , also known as U.S',\n",
       " 'Arsenal Building , is a building located in MacArthur Park in downtown Little Rock , Arkansas ',\n",
       " \"Built in 1840 , it was part of Little Rock 's first military installation \",\n",
       " 'Since its decommissioning , The Tower Building has housed two museums ',\n",
       " 'It was home to the Arkansas Museum of Natural History and Antiquities from 1942 to 1997 and the MacArthur Museum of Arkansas Military History since 2001 ',\n",
       " 'It has also been the headquarters of the Little Rock Æsthetic Club since 1894 ',\n",
       " '\\n The building receives its name from its distinct octagonal tower ',\n",
       " 'Besides being the last remaining structure of the original Little Rock Arsenal and one of the oldest buildings in central Arkansas , it was also the birthplace of General Douglas MacArthur , who became the supreme commander of US forces in the South Pacific during World War II ',\n",
       " 'It was also the starting place of the Camden Expedition ',\n",
       " 'In 2011 it was named as one of the top 10 attractions in the state of Arkansas by <unk> \\n \\n = = Construction = = \\n \\n The arsenal was constructed at the request of Governor James Sevier Conway in response to the perceived dangers of frontier life and fears of the many Native Americans who were passing through the state on their way to the newly established Oklahoma Territory ',\n",
       " 'Thirty @-@ six acres were appropriated on the outskirts of Little Rock by Major Robert B',\n",
       " 'Lee of the U.S',\n",
       " 'The land had been previously used as a racetrack by the local jockey club ',\n",
       " 'John Wormley Walker , a builder for the Federal Government , supervised the construction ',\n",
       " 'Originally $ 14 @,@ 000 was allocated for the construction of the arsenal , but proved inadequate ',\n",
       " 'The budget was later increased to $ 30 @,@ 000 ',\n",
       " 'Work began on the Tower Building in 1840 , and it was the first permanent structure of the arsenal to be built ',\n",
       " 'Being originally constructed to store ammunition , the building was designed with 3 @-@ foot @-@ thick ( 0 @.@ 91 m ) exterior walls ',\n",
       " 'The original plans called for it to be built of stone , however , masonry was used instead ',\n",
       " 'The Arkansas Gazette referred to the structure as \" A splendid specimen of masonry \" ',\n",
       " '\\n \\n = = Civil War = = \\n \\n For several years the arsenal , which was owned by the federal government , served as a simple arms depot and was staffed with only a handful of soldiers ',\n",
       " 'But in November 1860 , with the American Civil War on the horizon , a company of the Second United States Artillery , consisting of sixty @-@ five men , was transferred to Little Rock under the command of Captain James Totten ',\n",
       " 'On January 15 , 1861 , the state legislature decided to hold a referendum to determine if a state convention should be held to consider the issue of secession and to elect delegates to such a convention ',\n",
       " 'It was planned for February 18 ; however , events at the arsenal , would not wait ',\n",
       " 'On January 28 , then Governor Henry Massey Rector informed Captain Totten that he and his soldiers would be \" permitted to remain in the possession of the Federal officers until the State , by authority of the people , shall have determined to sever their connection with the General Government , \" Totten responded to this by telling the Governor that his orders came from the United States Government and began a desperate but ultimately futile dispatch of letters and telegrams asking for reinforcements , although rumors were widely spread that they were already coming ',\n",
       " 'The first telegraph wire to span between Little Rock and Memphis had recently been completed ',\n",
       " \"Local attorney John M Harrel was asked to compose the first telegraph dispatched from Arkansas 's capital \",\n",
       " 'In his message , Harrel reported unconfirmed rumors that more federal troops had been sent to reinforce the Little Rock Arsenal ',\n",
       " '\\n The United States troops at the outposts of the western frontier of the state and in the Indian nation have all been recalled from winter quarters to reinforce the garrison at Fort Smith ',\n",
       " 'The garrison at Fort Smith had been previously transferred to the United States Arsenal in this city ( Little Rock ) ',\n",
       " 'The arsenal is one of the richest depositories of military stores in the United States and is supposed to be the ultimate destination of the <unk> [ sic ] ordered from the frontier ',\n",
       " '\\n <unk> M Harrel Telegram , January 31 , 1861 \\n The item was intended simply as a piece of news , but telegraph lines quickly spread the news throughout the state , fueling procession sentiment ',\n",
       " 'The rumor was interpreted by some Arkansans as a call from the governor to assemble to help expel the federal troops from the arsenal ',\n",
       " 'By February 5 , six militia units , consisting of 1 @,@ 000 men , with a guarantee that the numbers could be increased to 5 @,@ 000 if the situations deemed it necessary , had assembled in Little Rock ',\n",
       " 'Governor Rector vehemently denied ordering the troops to assemble or giving any order at all in connection with the troops ',\n",
       " 'Faced with the fact that the military had assembled believing they were following his orders and the consensus of the citizens of Little Rock against any armed conflict between the civilian army and federal troops , Governor Rector was forced to take control of the situation ',\n",
       " 'On February 6 , he sent a formal demand for surrender of the arsenal to Captain Totten , \\n This movement is prompted by the feeling that pervades the citizens of this State that in the present emergency the arms and munitions of war in the Arsenal should be under the control of the State authorities , in order to their security ',\n",
       " 'This movement , although not authorized by me , has assumed such an aspect that it becomes my duty , as the executive of this <unk> , to interpose my official authority to prevent a collision between the people of the State and the Federal troops under your command ',\n",
       " 'I therefore demand in the name of the State the delivery of the possession of the Arsenal and munitions of war under your charge to the State authorities , to be held subject to the action of the convention to be held on the 4th of March next ',\n",
       " '\\n Perhaps because Abraham Lincoln had not yet been inaugurated as President , Captain Totten received no instructions from his superiors and was forced to withdraw his troops ',\n",
       " 'He agreed to surrender the arsenal as long as the governor agreed to three provisions : \\n The governor would take possession of the arsenal in the name of the United States ',\n",
       " '\\n The soldiers would be allowed safe passage in any direction carrying any personal and public property besides munitions of war ',\n",
       " '\\n The soldiers would be allowed to march away as men leaving under orders , not as conquered and surrendering soldiers ',\n",
       " '\\n On the morning of February 8 , 1861 , Rector and Totten signed an agreement placing the arsenal in the hands of state officials ',\n",
       " 'That afternoon , the citizen militia marched to the arsenal with Governor Rector at its head ',\n",
       " \"All of the federal troops had left at this point , except Totten who had stayed behind to listen to the Governor 's speech and to hand the arsenal over in person \",\n",
       " '\\n The Little Rock Arsenal was classified in 1860 as an \" arsenal of deposit , \" meaning that it was simply a warehouse for the storage of weapons intended for the use of the state militia in times of crisis ',\n",
       " 'Thus there were no substantial operations for ordnance fabrication or repairs , nor for the manufacture of cartridges at the time the Arsenal fell into State hands ',\n",
       " 'Most of these operations were started from scratch through the efforts of the Arkansas Military Board ',\n",
       " \"\\n Inside the Little Rock Arsenal after its seizure in February , 1861 , the Confederates inventoried some 10 @,@ 247 weapons , 250 @,@ 000 musket cartridges , and 520 @,@ 000 percussion caps , as well as the four bronze cannon of Totten 's battery \",\n",
       " 'Long arms in the Arsenal \\'s inventory consisted of : \\n M1822 .69 cal ( flintlock ) 5 @,@ 625 \\n M1822 .69 cal ( percussion @-@ converted ) 53 \\n <unk> .69 cal smoothbore ( percussion ) 357 \\n <unk> .58 cal rifle @-@ muskets 900 \\n <unk> common rifles 125 \\n <unk> rifle ( \" Mississippi Rifle \" ) 54 \\n <unk> <unk> 2 \\n Hall \\'s carbines 267 \\n Hall \\'s rifles ( flintlock ) 2 @,@ 864 \\n Total 10 @,@ 247 \\n Of this number , approximately 9600 weapons were serviceable , or ready @-@ for @-@ issue ',\n",
       " 'Note there were only 1 @,@ 364 percussion weapons available ',\n",
       " 'Disposition of the weapons found in the Arsenal is somewhat sketchy , but from various records it can be surmised that the 5th , 6th , 7th , and 8th Arkansas Infantry Regiments , mustered in June , 1861 , were issued <unk> / M1822 .69 caliber flintlocks ',\n",
       " \"The 9th and 10th Arkansas , four companies of Kelly 's 9th Arkansas Battalion , and the 3rd Arkansas Cavalry Regiment were issued flintlock Hall 's Rifles \",\n",
       " \"The units comprising the infantry force of Van Dorn 's Army of the West were the 1st and 2nd Arkansas Mounted Rifles were also armed with M1822 flintlocks from the Little Rock Arsenal \",\n",
       " 'By the time the 11th and 12th Arkansas Infantry Regiments mustered in at Little Rock , the supply of arms had been almost completely exhausted , and only old \" junker \" weapons were left ',\n",
       " '\\n Most of the equipment , arms , and machinery at the Little Rock Arsenal was removed to east of the Mississippi River by order of Maj',\n",
       " 'Earl Van Dorn in April and May 1862 , and accountability for it is lost at that point ',\n",
       " 'By all appearances , the equipment was sent down the river to Napoleon , Arkansas , and from there to Jackson Mississippi , where it was probably destroyed during the Vicksburg campaign in the early summer of 1863 ',\n",
       " '\\n Major General Thomas C',\n",
       " 'Hindman , sent to command the district of Arkansas in May , 1862 , found the state nearly destitute of military material ',\n",
       " 'Hindman established another armory at Arkadelphia , and revived the Little Rock Arsenal as a collection point and depot for armaments and ammunition manufacture for small arms ',\n",
       " 'Hindman recorded : \\n \" Machinery was made for manufacturing percussion caps and small arms , and both were turned out in small quantity , but of excellent quality ',\n",
       " 'Lead mines were opened and worked , and a chemical laboratory was established and successfully operated in aid of the Ordnance Department and in the manufacture of calomel , castor oil , spirits of nitre , the various tinctures of iron , and other valuable medicines ',\n",
       " 'Most of these works were located at or near Arkadelphia on the Ouachita River , 75 miles south from Little Rock ',\n",
       " 'The tools , machinery , and the material were gathered piecemeal or else made by hand labor ',\n",
       " 'Nothing of this sort had been before attempted on Government account in Arkansas to my knowledge , except for the manufacture of small arms , the machinery for which was taken away by General Van Dorn and there was neither capital nor sufficient enterprise among the citizens to engage in such undertakings <unk> A further supply , along with lead and caps , was procured from the citizens of Little Rock and vicinity by donation , purchases , and impressments ',\n",
       " '\\n This ammunition , and that which I brought with me , was rapidly prepared for use at the Laboratory established at the Little Rock Arsenal for that purpose ',\n",
       " 'As illustrating as the pitiful scarcity of material in the country , the fact may be stated that it was found necessary to use public documents of the State Library for cartridge paper ',\n",
       " '<unk> were employed or conscripted , tools purchased or impressed , and the repair of the damaged guns I brought with me and about an equal number found at Little Rock commenced at once ',\n",
       " \"But , after inspecting the work and observing the spirit of the men I decided that a garrison 500 strong could hold out against Fitch and that I would lead the remainder - about 1500 - to Gen 'l Rust as soon as shotguns and rifles could be obtained from Little Rock instead of pikes and lances , with which most of them were armed \",\n",
       " 'Two days elapsed before the change could be effected ',\n",
       " '\" \\n The Confederate ordnance establishment at Little Rock was reactivated in August , 1862 ',\n",
       " 'Looking around for a suitable person to head this activity , General Hindman turned to the Confederate Navy and borrowed Lieutenant John W',\n",
       " 'Dunnington ',\n",
       " 'Dunnington was the commander of the gunboat C.S.S',\n",
       " 'Ponchartrain , which had been brought to Little Rock in hopes of converting it to an ironclad ',\n",
       " 'Dunnington was selected to head the ordnance works at Little Rock , and although he continued to draw his pay from the Confederate Navy Department , he was placed in charge of all Confederate ordnance activities ( which included artillery functions ) there with the rank of lieutenant colonel ',\n",
       " 'Dunnington \\'s \" Returns for the month of August , 1862 , at Little Rock Arsenal , C.S.A',\n",
       " ', \" are found in Vol ',\n",
       " '149 , Chapter IV of the \" Captured Rebel Ordnance Records , \" and are most enlightening as to the scope of Confederate ordnance activities at Little Rock during this crucial time ',\n",
       " 'According to Dunnington , \" When I assumed command at this Post , all material had been removed to Arkadelphia ',\n",
       " 'There were no persons employed ',\n",
       " 'No shops were open for repair of arms or for fabricating ammunition ',\n",
       " 'Material , tools , etc ',\n",
       " ', had to be procured as well as the employment of laborers ',\n",
       " 'Work commenced the last part of the month ',\n",
       " '\" \\n The military force at Little Rock under Dunnington \\'s command consisted of four officers : himself , Major John B',\n",
       " 'Lockman , Captain C.C',\n",
       " 'Green , and 2nd Lt',\n",
       " 'Murphy ',\n",
       " 'In addition to these , he had 20 enlisted men and a civilian force composed of a foreman , 2 clerks , 3 gunsmiths for repairing small arms , a <unk> , 26 laborers in the ammunition laboratory , and a carpenter for making packing boxes ',\n",
       " '\\n During the month of August , 1862 , the following work was performed : \" <unk> : one pair of musket bullet moulds ; 10 @,@ 000 buck & ball shot cartridges ; repaired : 750 muskets , shotguns , and rifles ; received and repaired : ordnance stores and <unk> ; performed : guard , office , and police duties ; inspected : Posts at Camden and Arkadelphia ',\n",
       " 'Col',\n",
       " 'Dunnington continued to build up his works at Little Rock until November 1862 , when Captain Sanford C',\n",
       " 'Faulkner ( composer of The Arkansas Traveler ) was placed in charge of the Arsenal ',\n",
       " 'Dunnington presumably returned to his naval duties and the Ponchartrain ',\n",
       " '\\n A \" Summary of the Work Done for November , 1862 , Little Rock Arsenal \" shows : Fabrication : \\n 75 @,@ 000 buck & ball cartridges - percussion \\n 14 @,@ 000 buck & ball cartridges - flint \\n 275 paper fuzes \\n 117 rounds , 6 @-@ pounder canister shot \\n 130 rounds , 6 @-@ pounder ball shot \\n 96 ammunition packing boxes \\n Repaired : \\n 2 @,@ 236 shotguns and rifles ( repaired mostly for troops in service ) \\n 23 pistols ( repaired mostly for troops in service ) \\n Received & Issued : \\n 752 packages of ordnance and ordnance stores received and mostly issued to troops in service ',\n",
       " '\\n Repaired and painted : \\n 4 gun carriages \\n Performed : \\n Guard , office , and police duties ',\n",
       " '\\n Perhaps the most illuminating points of the above \" Summary of Work \" and those for following months are that the standard ammunition made was ',\n",
       " '\" buck & ball \" , indicating that the .69 caliber smoothbores and shotguns remained the predominant caliber weapon in use , and of this , nearly one sixth or more of all small arms ammunition was still for flintlock weapons , indicating that no less than a sixth of the Confederate troops in this vicinity were still armed with obsolete flintlock weapons ',\n",
       " '\\n The \" Summaries of Work done at Little Rock Arsenal , C.S.A',\n",
       " '\" continue at about the same pace and scale from August 1862 until August 1863 ',\n",
       " '<unk> to the \" Summary \" for August , 1863 is the ominous notation , \" During the last week in the month , nearly all stores at the Arsenal have been packed and sent to Arkadelphia , in obedience to orders from Chief of Ordnance , District of Arkansas ',\n",
       " '\" This then marks the beginning of the evacuation of ordnance activities from Little Rock , with the city being surrendered to the advancing Federal troops of Frederick Steele \\'s Arkansas Expedition on September 11 , 1863 ',\n",
       " '\\n In 1864 , after Little Rock fell to the Union Army and the arsenal had been recaptured , General Fredrick Steele marched 8 @,@ 500 troops from the arsenal beginning the Camden Expedition ',\n",
       " '\\n The arsenal was briefly seized once more by Joseph Brooks loyalists during the Brooks @-@ Baxter War of 1874 ',\n",
       " '\\n \\n = = Decommissioning = = \\n \\n In 1873 , the building was renamed Little Rock Barracks and used as a barracks for married officers and their families ',\n",
       " 'The building was drastically altered the inside and outside ',\n",
       " 'Prior to renovation , a rear basement door provided the only entrance to the building , while the tower served as a hoist to move munitions between floors ',\n",
       " 'By 1868 , front and rear porches had been added to the building , as well as interior walls and stairs , some of which remain today , including the central staircase ',\n",
       " 'In 1880 , Douglas MacArthur was born on the northwest upper floor of this building while his father , Captain Arthur MacArthur , was stationed there ',\n",
       " '\\n In the 1880s , the federal government began closing many small arsenals around the country in favor of smaller ones built near railroads for quick deployment ',\n",
       " 'The arsenal commander received word from Washington that the Little Rock site must be abandoned \" not later than October 1 , 1890 ',\n",
       " '\" On April 12 , 1893 the tower building and the surrounding buildings were traded to the city of Little Rock for 1 @,@ 000 acres ( 4 km ² ) in North Little Rock under the condition that the building and land be \" forever exclusively devoted to the uses and purposes of a public park \" for 1 @,@ 000 acres ( 4 km ² ) in Big Rock Mountain on the north side of the Arkansas River , present day North Little Rock ',\n",
       " 'That site later became Fort Logan H',\n",
       " 'All of the original buildings surrounding the Tower Building were demolished ',\n",
       " \"\\n \\n = = Æsthetic Club = = \\n \\n In 1894 the Little Rock Æsthetic Club , one of the oldest women 's societies west of the Mississippi River , moved into the Tower Building \",\n",
       " 'This was prompted due to increased membership and a need for larger , more permanent quarters ',\n",
       " \"The previous year , club members working with women 's organizations throughout the state , raised money to furnish the Arkansas Building of the Columbian Exposition at The Chicago World 's Fair \",\n",
       " 'At the fair \\'s conclusion , artifacts from the exhibit were displayed in the Tower Building , with the Æsthetic Club invited to meet in the \" Columbian Room ',\n",
       " '\" \\n Except for Æsthetic Club meetings , the Tower Building remained largely unoccupied for almost fifty years and suffered significant deterioration ',\n",
       " 'The Æsthetic Club provided much @-@ needed financial support during the period and even paid the electric bill during the Great Depression ',\n",
       " 'The Æsthetic Club is still headquartered in the Tower Building ',\n",
       " '\\n \\n = = Public use = = \\n \\n The building and the surrounding park were used for many public purposes throughout the early 20th century ',\n",
       " 'The Tower Building served as headquarters for the United Confederate Veterans Reunion , May 15 – 18 , 1911 ',\n",
       " 'Over 106 @,@ 000 Civil War veterans , the largest popular gathering in the history of the city up to that time , attended and were housed in the building or camped in the park , which had also become a popular camping area ',\n",
       " 'Later the building served as an armory for the Arkansas National Guard ',\n",
       " \"In 1912 , the second floor of the Tower Building became Little Rock 's first public library \",\n",
       " 'In 1917 , Little Rock built a fire station in the park , that building is now gone ',\n",
       " 'A band shell named for H',\n",
       " 'Foster also was built in the park during this time , but also no longer exists ',\n",
       " 'In 1936 , Works Progress Administration built the Museum of Fine Arts , now called the Arkansas Arts Center , just south of the Tower Building ',\n",
       " '\\n The arsenal was listed in the National Register of Historic Places in 1970 ',\n",
       " 'Due to its association with the Camden Expedition of 1864 , the arsenal may be included in the Camden Expedition Sites National Historic Landmark designated in 1994 ',\n",
       " '\\n In 1942 , the Tower Building was renovated due to the efforts of the Æsthetic Club , Little Rock philanthropist Frederick W',\n",
       " 'Allsop , and the Works Progress Administration ',\n",
       " 'It became the new home of The Arkansas Museum of Natural History and Antiquities , which had been located in Little Rock City Hall ',\n",
       " 'The museum remained in the tower building for approximately fifty @-@ five years ',\n",
       " 'The area surrounding the Tower Building had been known as Arsenal Park when the first decommissioned and then later renamed City Park ',\n",
       " 'Due to the efforts of Bernie Babcock , however , the city finally named it MacArthur Park in 1942 in honor of Douglas MacArthur ',\n",
       " \"\\n In 1997 , the Museum of Science and Natural History merged with the Little Rock Children 's Museum , which had been located in Union Station , to form the Arkansas Museum of Discovery \",\n",
       " 'The new museum was relocated to a historic building in the Little Rock River Market District ',\n",
       " 'The MacArthur Museum of Arkansas Military History opened on May 19 , 2001 in the Tower Building ',\n",
       " \"The new museum 's goal is to educate and inform visitors about the military history of Arkansas , preserve the Tower Building , honor servicemen and servicewomen of the United States and commemorate the birthplace of Douglas MacArthur \",\n",
       " 'Cicely Mary Barker ( 28 June 1895 – 16 February 1973 ) was an English illustrator best known for a series of fantasy illustrations depicting fairies and flowers ',\n",
       " \"Barker 's art education began in girlhood with correspondence courses and instruction at the Croydon School of Art \",\n",
       " 'Her earliest professional work included greeting cards and juvenile magazine illustrations , and her first book , Flower Fairies of the Spring , was published in 1923 ',\n",
       " 'Similar books were published in the following decades ',\n",
       " '\\n Barker was a devout Anglican , and donated her artworks to Christian fundraisers and missionary organizations ',\n",
       " 'She produced a few Christian @-@ themed books such as The Children ’ s Book of Hymns and , in collaboration with her sister Dorothy , He Leadeth Me ',\n",
       " 'She designed a stained glass window for St',\n",
       " \"Edmund 's Church , Pitlake , and her painting of the Christ Child , The Darling of the World Has Come , was purchased by Queen Mary \",\n",
       " '\\n Barker was equally proficient in watercolour , pen and ink , oils , and pastels ',\n",
       " 'Kate Greenaway and the Pre @-@ Raphaelites were the principal influences on her work ',\n",
       " 'She claimed to paint instinctively and rejected artistic theories ',\n",
       " 'Barker died in 1973 ',\n",
       " \"Though she published Flower Fairy books with spring , summer , and autumn themes , it wasn 't until 1985 that a winter collection was assembled from her remaining work and published posthumously \",\n",
       " '\\n \\n = = Biography = = \\n \\n \\n = = = Early life = = = \\n \\n Barker was born the second daughter and youngest child of Walter Barker , a partner in a seed supply company and an amateur artist , and his wife Mary Eleanor ( Oswald ) Barker on 28 June 1895 at home at 66 Waddon Road in Croydon , Surrey , England ',\n",
       " 'Barker was an epileptic as a child , and cared for at home by her parents ',\n",
       " 'Later , her sister and elder by two years , Dorothy Oswald Barker , continued the care ',\n",
       " '\\n The family of four was moderately well off , and belonged to the lower end of the upper middle class ',\n",
       " 'A nanny , a governess , and a cook to prepare special meals for Barker were hired ',\n",
       " 'She spent much time in bed at home amusing herself with painting books and a nursery library that included the works of Kate Greenaway and Randolph Caldecott – two artists who exerted strong influences on her later art ',\n",
       " '\\n \\n = = = Art education and first professional work = = = \\n \\n Barker took correspondence courses in art , probably until about 1919 ',\n",
       " 'In 1908 at 13 years , she entered an evening class at the Croydon School of Art , and attended the school into the 1940s ',\n",
       " 'In time , she received a teaching position ',\n",
       " '\\n In 1911 , Raphael Tuck & Sons bought four of Barker \\'s \" little drawings \" for half a sovereign , and published them as postcards ',\n",
       " \"In October 1911 , she won second prize in the Croydon Art Society 's poster competition , and shortly afterward was elected the youngest member of the Society \",\n",
       " 'The art critic for the Croydon Advertiser remarked , \" Her drawings show a remarkable freedom of spirit ',\n",
       " 'She has distinct promise ',\n",
       " '\" \\n Following her father ’ s death in June 1912 , the seventeen @-@ year @-@ old Barker submitted art and poetry to My Magazine , Child ’ s Own , Leading Strings , and Raphael Tuck annuals in an effort to support both her mother and sister ',\n",
       " 'Her sister Dorothy taught kindergarten in two private schools before opening a kindergarten at home ',\n",
       " \"She brought in some money for the family 's support while supervising the household \",\n",
       " '\\n \\n = = = Flower Fairies of the Spring , 1923 = = = \\n \\n Fairies became a popular theme in art and literature in the early 20th century following the releases of The Coming of the Fairies by Sir Arthur Conan Doyle , Peter Pan by J.M',\n",
       " 'Barrie , and the fairy @-@ themed work of Australian Ida <unk> Outhwaite ',\n",
       " 'Queen Mary made such themes even more popular by sending Outhwaite postcards to friends during the 1920s ',\n",
       " 'In 1918 , Barker produced a postcard series depicting elves and fairies ',\n",
       " '\\n In 1923 , Barker sent her flower fairy paintings to various publishers ',\n",
       " \"Blackie paid £ 25 for 24 paintings with accompanying verses , but it wasn 't until publication of Flower Fairies of the Summer in 1925 that Barker received royalties for her work \",\n",
       " 'Mary Violet Clayton Calthrop , wife of author Dion Clayton Calthrop , wrote in April 1925 about Barker and Flower Fairies of the Spring : \" She has such exquisite taste , besides draughtsmanship ',\n",
       " '\" \\n \\n = = = The Waldrons = = = \\n \\n In 1924 , the family moved into a four @-@ level , semi @-@ detached Victorian house at 23 The Waldrons ',\n",
       " 'Barker had a studio built in the garden and her sister conducted a kindergarten in a room at the back of the house ',\n",
       " 'The family lived frugally and attended both St',\n",
       " \"Edmund 's and St\",\n",
       " 'Andrew \\'s in Croydon – \" low \" churches for the less privileged ',\n",
       " 'Barker sometimes incorporated portraits of her fellow parishioners in her religious works ',\n",
       " 'She was described by Canon Ingram Hill as \" one of the pillars \" of St',\n",
       " \"Andrew 's \",\n",
       " '\\n The children in the kindergarten modelled for the Flower Fairies until the kindergarten closed in 1940 ',\n",
       " 'In an interview in 1958 , Barker said , \" My sister ran a kindergarten and I used to borrow her students for models ',\n",
       " 'For many years I had an atmosphere of children about me – I never forgot it ',\n",
       " '\" She also painted the children of relatives as well as Gladys Tidy , the Barkers \\' young housekeeper , who posed for the Primrose Fairy in 1923 ',\n",
       " 'The plants were painted from life , and if a specimen was not readily at hand , Kew Gardens staff would provide her the specimens needed ',\n",
       " 'Barker designed and built the Flower Fairy costumes , and based each on the flowers and leaves of the particular plant to be illustrated ',\n",
       " 'The costumes were kept in a trunk in her studio along with wings made of twigs and gauze ',\n",
       " 'Each was broken down after an illustration was completed and the parts recycled for other costumes ',\n",
       " \"She often referred to Dion Clayton Calthrop 's English Costume \",\n",
       " '\\n \\n = = = Middle years = = = \\n \\n In the late 1920s , Barker began to doubt she was doing enough for the church and considered focusing solely on sacred works ',\n",
       " 'Family and friends recommended she continue secular and sacred works , which she did ',\n",
       " '\\n Barker continued to attend evening classes at the Croydon Art School between the 1920s and the 1940s , eventually receiving a teaching position ',\n",
       " 'She took sketching trips to Amberley and Storrington in Sussex and to Cornwall and the southern coast with family and friends ',\n",
       " 'She visited and stayed with artist Margaret Tarrant in Gomshall , Surrey and with family in <unk> , Near Whitby , North Yorkshire ',\n",
       " \"\\n In 1940 , the Barker 's live @-@ in maid retired , and Dorothy Barker closed her school at the back of the house in The Waldrons \",\n",
       " 'She continued to supervise the household , and to give both her mother and sister the care they needed ',\n",
       " \"Dorothy and her sister collaborated upon only two books : Our Darling 's First Book and the Christian @-@ themed , He Leadeth Me \",\n",
       " 'In 1954 Dorothy Barker died of a heart attack ',\n",
       " \"Barker was unable to pursue her art to any significant extent following her sister 's death , as all the care of her aged mother devolved upon her , but she did manage to begin planning a stained glass window design in her sister 's memory for St\",\n",
       " \"Edmund 's , Pitlake \",\n",
       " \"\\n \\n = = = Later life and death = = = \\n \\n Barker 's mother died in 1960 , and , in 1961 , Barker moved from 23 The Waldrons to 6 <unk> Avenue in Croydon \",\n",
       " 'She restored a maisonette in Storrington , Sussex , England , bequeathed by her friend Edith Major , and named it St',\n",
       " \"Andrew 's \",\n",
       " 'After taking up residence , her health began to deteriorate ',\n",
       " 'She was in and out of nursing and convalescent homes , and tended by relatives and friends ',\n",
       " '\\n Barker died at Worthing Hospital on 16 February 1973 , aged 77 years ',\n",
       " \"Two funeral services were held – one in Storrington Church and one in Barker 's maisonette \",\n",
       " 'Her ashes were scattered in Storrington churchyard ',\n",
       " 'In 1989 , Frederick Warne , a division of Penguin Books since 1983 , acquired the Flower Fairies properties ',\n",
       " '\\n \\n = = Art = = \\n \\n Barker worked principally in watercolor with pen @-@ and @-@ ink , but she was equally competent in black @-@ and @-@ white , in oils , and in pastels ',\n",
       " 'She carried a sketchbook with her for capturing interesting children ',\n",
       " 'She once indicated , \" I have always tried to paint instinctively in a way that comes naturally to me , without any real thought or attention to artistic theories ',\n",
       " '\" \\n Kate Greenaway was a childhood favorite and an influence on her art ',\n",
       " \"Barker 's child subjects wear nostalgic clothing as Greenaway 's children do , though Barker 's children are less melancholy and less flat in appearance , due perhaps to advances in printing technology \",\n",
       " \"Barker studied flowers with an analytical eye and was friend to children 's illustrator , Margaret Tarrant \",\n",
       " 'Along with Greenaway , illustrator Alice B',\n",
       " \"Woodward also influenced Barker 's work \",\n",
       " '\\n The Pre @-@ Raphaelites were a strong , lifelong influence on Barker ',\n",
       " 'She once indicated , \" I am to some extent influenced by them — not in any technical sense , but in the choice of subject matter and the feeling and atmosphere they could achieve ',\n",
       " '\" She admitted a fondness for the early paintings of John Everett Millais and \" the wonderful things \" of Edward Burne @-@ Jones ',\n",
       " \"\\n \\n = = = Depictions of children = = = \\n \\n Barker 's sketches , drawings , and paintings of children were given to friends or to the parents of the subjects , donated to charitable institutions and church sponsored events , or exhibited through various art organizations \",\n",
       " \"She illustrated magazine covers , dust jackets , and produced series of postcards for Raphael Tuck and other publishers such as Picturesque Children of the Allies ( 1915 ) , Seaside Holidays ( 1918 ) , and Shakespeare 's Boy and Girl Characters ( 1917 , 1920 ) \",\n",
       " 'Her own Old Rhymes for All Times ( 1928 ) and The Lord of the Rushie River ( 1938 ) , a tale about a girl who lives among swans on a riverbank , were critically well received ',\n",
       " 'Set about 1800 , Groundsel and Necklaces ( 1943 ) tells of a girl named Jenny who rescues her family from poverty through the agency of the fairies ',\n",
       " 'The story features an old Scrooge @-@ like man called Mr',\n",
       " '<unk> and tonally suggests a Dickensian social consciousness ',\n",
       " 'Simon the Swan , intended as a sequel to Rushie River was outlined in 1943 with Groundsel , but only developed in 1953 ',\n",
       " 'It was published posthumously in 1988 and is critically considered less successful than Groundsel ',\n",
       " '\\n \\n = = = Christian @-@ themed works = = = \\n \\n Barker was a devout Christian , and produced religious @-@ themed works throughout her life ',\n",
       " 'She published eight postcards and five guardian angel birthday cards for the Society for Promoting Christian Knowledge in 1916 and in 1923 respectively ',\n",
       " \"Christmas cards were designed for The Girls ' Friendly Society over a 20 @-@ year period , and the first three designs sold out a combined printing of 46 @,@ 500 in 1923 \",\n",
       " 'An original design for the society called The Darling of the World Has Come was purchased by Queen Mary for ₤ 5 @.@ 5 @.@ 0 in 1926 ',\n",
       " \"The Croydon Art Society hung Barker 's booklet cover design for the Society for the Propagation of the Gospel in its November 1919 exhibition \",\n",
       " \"\\n Religious @-@ themed books include The Children 's Book of Hymns ( 1929 ) and He Leadeth Me ( 1933 ) , the latter written in collaboration with her sister \",\n",
       " 'Major religious works include the triptychs in oil , The Feeding of the Five Thousand ( 1929 ) , for the chapel in Llandaff House , a home for destitute women at Penarth , Wales , and The Parable of the Great Supper ( 1934 ) for St',\n",
       " \"George 's Chapel , Waddon \",\n",
       " 'The Feeding has since disappeared , and only a black @-@ and @-@ white photograph dated 1929 reproduces the work ',\n",
       " 'In 1941 , she completed oil panels on the subject of the seven sacraments for the baptismal font at St',\n",
       " \"Andrew 's , South Croydon \",\n",
       " 'She designed baptismal rolls for the wall behind the font in 1948 and 1962 ',\n",
       " 'In 1946 , she completed the 4 x 7 ft',\n",
       " 'oil painting , Out of Great Tribulation , for the Memorial Chapel of Norbury Methodist Church ',\n",
       " 'Following the death of her sister in 1954 , Barker began designs for a stained glass memorial window depicting Christ preparing to wash the feet of his disciples ',\n",
       " 'Her last religious @-@ themed work , it was installed in St',\n",
       " \"Edmund 's , Pitlake , in 1962 \",\n",
       " '\\n \\n = = Works = = \\n \\n \\n = = = Cards = = = \\n \\n Picturesque Children of the Allies ; J',\n",
       " \"Salmon , 1916 \\n National Mission ; Society for the Preservation of Christian Knowledge , 1916 \\n Shakespeare 's Boy Characters ; C\",\n",
       " \"Faulkner , 1917 \\n Shakespeare 's Girl Characters ; C\",\n",
       " 'Faulkner , 1920 \\n Seaside Holiday ; J',\n",
       " 'Salmon , 1918 , 1921 \\n Elves and Fairies ; S',\n",
       " \"Harvey , 1918 \\n Guardian Angel ; Society for the Preservation of Christian Knowledge , 1923 \\n Christmas cards ; Girls ' Friendly Society , 1920s , 1930s \\n Christmas cards ( US ) ; Barton @-@ Colton , 1920s , 1930s \\n Beautiful Bible Pictures ; Blackie , 1932 \\n \\n = = = Books = = = \\n \\n Flower Fairies of the Spring ; Blackie , 1923 \\n Spring Songs with Music ; Blackie , 1923 \\n Flower Fairies of the Summer ; Blackie , 1925 \\n Child Thoughts in Picture and Verse ( by M\",\n",
       " 'Westcott ) ; Blackie , 1925 \\n Flower Fairies of the Autumn ; Blackie , 1926 \\n Summer Songs with Music ; Blackie , 1926 \\n The Book of the Flower Fairies ; Blackie , 1927 \\n Autumn Songs with Music ; Blackie , 1927 \\n Old Rhymes for All Times ; Blackie , 1928 \\n The Children ’ s Book of Hymns ; Blackie , 1929 ; rep ',\n",
       " '1933 \\n Our Darling ’ s First Book ( written in collaboration with Dorothy Barker ) ; Blackie , 1929 \\n The Little Picture Hymn Book ; Blackie , 1933 \\n Rhymes New and Old ; Blackie , 1933 \\n A Flower Fairy Alphabet ; Blackie , 1934 \\n A Little Book of Old Rhymes ; Blackie , 1936 \\n He Leadeth Me ( written in collaboration with Dorothy Barker ) ; Blackie , 1936 \\n A Little Book of Rhymes New and Old ; Blackie , 1937 \\n The Lord of the Rushie River ; Blackie , 1938 \\n Flower Fairies of the Trees ; Blackie , 1940 \\n When Spring Came In at the Window ; Blackie , 1942 \\n A Child ’ s Garden of Verses ( Robert Louis Stevenson ) ; Blackie , 1944 \\n Flower Fairies of the Garden ; Blackie , 1944 \\n Groundsel and Necklaces ; Blackie , 1946 ; reprinted as Fairy Necklaces \\n Flower Fairies of the Wayside ; Blackie , 1948 \\n Flower Fairies of the Flowers and Trees ; Blackie , 1950 \\n Lively Stories ; Macmillan , 1954 \\n The Flower Fairy Picture Book ; Blackie , 1955 \\n Lively Numbers ; Macmillan , 1957 \\n Lively Words ; Macmillan , 1961 ',\n",
       " '\\n The Sand , the Sea and the Sun ; Gibson , 1970 \\n \\n = = = = Posthumously published = = = = \\n \\n Flower Fairies of the Winter ; Blackie , 1985 \\n Simon the Swan ; Blackie , 1988 \\n Flower Fairies of the Seasons ; <unk> / Blackie , 1988 \\n A Little Book of Prayers and Hymns ; Frederick Warne , 1994 \\n A Flower Fairies Treasury ; Frederick Warne , 1997 \\n <unk> ; Frederick Warne , 2005 \\n Wild Cherry Makes A Wish ; ( collaboration with Pippa Le Quesne ) Frederick Warne , 2006 \\n How to find Flower Fairies ; Frederick Warne , 2007 \\n Return to <unk> ; Frederick Warne , 2008 \\n \\n = = = Book covers = = = \\n \\n A New Epiphany ; Society for the Preservation of Christian Knowledge , 1919 \\n 43 Annuals ; Blackie , 1920s , 1930s \\n \\n = = = Religious works = = = \\n \\n St',\n",
       " \"Cecily 's Garden ; 1920 \\n Cradle roll design ; St\",\n",
       " \"Edmund 's , Pitlake , 1922 \\n Banner design ; St\",\n",
       " \"Mary 's , <unk> , 1923 \\n The Feeding of the Five Thousand ; reredos triptych , chapel at Penarth , Wales ; 1929 \\n The Parable of the Great Supper ; triptych , St\",\n",
       " \"George 's chapel , Waddon \\n The Seven Sacraments ; baptismal font panels , St\",\n",
       " \"Andrew 's , Croydon \\n St\",\n",
       " 'John the Baptist ; central banner panel , <unk> church , 1943 \\n Lettering , sword , and shield ; mount for a list of men and woman serving in the Forces , St',\n",
       " 'Andrews , Croydon , 1943 \\n <unk> rolls ; St',\n",
       " \"Andrews , Croydon , 1948 , 1962 \\n The font in St Andrew 's Church , South Croydon \\n Out of Great Tribulation ; memorial chapel , Norbury <unk> church , 1948 \\n I Am Among You As He That <unk> ; stained glass window design , St\",\n",
       " \"Edmund 's , Pitlake , 1962 \\n\",\n",
       " \"The Gambia women 's national football team represents the Gambia in international football competition \",\n",
       " \"The team , however , has not competed in a match recognised by FIFA , the sport 's international governing body , despite that organised women 's football has been played in the country since 1998 \",\n",
       " \"The Gambia has two youth teams , an under @-@ 17 side that has competed in FIFA U @-@ 17 Women 's World Cup qualifiers , and an under @-@ 19 side that withdrew from regional qualifiers for an under @-@ 19 World Cup \",\n",
       " \"The development of a national team faces challenges similar to those across Africa , although the national football association has four staff members focusing on women 's football \",\n",
       " \"\\n \\n = = The team = = \\n \\n In 1985 , few countries had women 's national football teams \",\n",
       " \"While the sport gained popularity worldwide in later decades , the Gambia 's national team only played its first game in 2007 \",\n",
       " 'That game was not FIFA @-@ recognised ',\n",
       " 'As of March 2012 , the team was unranked by FIFA , and as of the following month the Gambia had not played in a FIFA @-@ sanctioned match ',\n",
       " \"The team has not participated in major regional and international tournaments , including the Women 's World Cup , the 2010 African Women 's Championship or the 2011 All @-@ Africa Games \",\n",
       " \"\\n The country did not have a FIFA @-@ recognised youth national team until 2012 , when the Gambia under @-@ 17 women 's team competed in Confederation of African Football qualifiers for the FIFA U @-@ 17 World Cup , to be held in Azerbaijan in September 2012 \",\n",
       " 'The Gambia had fielded an under @-@ 17 team of 24 players , narrowed from an initial pool of 49 young women ',\n",
       " 'Two girls from the SOS Children ’ s Village <unk> were chosen as a members of the team ',\n",
       " 'The Gambia first played Sierra Leone in a pair of qualifying matches for the tournament ',\n",
       " \"Gambia won the first match 3 @-@ 0 in Banjul , the Gambia 's capital \",\n",
       " 'The return match was delayed in for 24 hours and played in Makeni ',\n",
       " 'The Gambia beat Sierra Leone 4 @-@ 3 to qualify for the final round ',\n",
       " 'The Gambia then beat Tunisia 1 @-@ 0 at home and won 2 @-@ 1 in Tunisia ',\n",
       " \"Adama Tamba and Awa Demba scored the Gambia 's goals \",\n",
       " \"Tunisia 's only goal was a Gambian own goal \",\n",
       " 'The win qualified Gambia for the 2012 Azerbaijan World Cup ',\n",
       " \"\\n The Gambia also has an under @-@ 19 team that was to play in the African Women 's U @-@ 19 Championship in 2002 \",\n",
       " \"The Gambia 's first match was against Morocco , but the team withdrew from the competition \",\n",
       " \"\\n \\n = = Background and development = = \\n \\n The development of women 's football in Africa faces several challenges , including limited access to education , poverty amongst women , inequalities and human rights abuses targeting women \",\n",
       " 'Funding is another issue impacting the game in Africa , where most financial assistance comes from FIFA and not national football associations ',\n",
       " 'Another challenge is the retention of football players ',\n",
       " 'Many women footballers leave the continent to seek greater opportunity in Europe or the United States ',\n",
       " \"\\n Gambia 's national football association was founded in 1952 , and became affiliated with FIFA in 1968 \",\n",
       " \"Football is the most popular women 's sport in the country , and was first played in an organized system in 1998 \",\n",
       " 'A national competition was launched in 2007 , the same year FIFA started an education course on football for women ',\n",
       " 'Competition was active on both the national and scholastic levels by 2009 ',\n",
       " \"There are four staffers dedicated to women 's football in the Gambia Football Association , and representation of women on the board is required by the association 's charter \",\n",
       " 'The plain maskray or brown stingray ( Neotrygon annotata ) is a species of stingray in the family Dasyatidae ',\n",
       " 'It is found in shallow , soft @-@ bottomed habitats off northern Australia ',\n",
       " 'Reaching 24 cm ( 9 @.@ 4 in ) in width , this species has a diamond @-@ shaped , grayish green pectoral fin disc ',\n",
       " 'Its short , whip @-@ like tail has alternating black and white bands and fin folds above and below ',\n",
       " 'There are short rows of thorns on the back and the base of the tail , but otherwise the skin is smooth ',\n",
       " 'While this species possesses the dark mask @-@ like pattern across its eyes common to its genus , it is not ornately patterned like other maskrays ',\n",
       " '\\n Benthic in nature , the plain maskray feeds mainly on caridean shrimp and polychaete worms , and to a lesser extent on small bony fishes ',\n",
       " 'It is viviparous , with females producing litters of one or two young that are nourished during gestation via histotroph ( \" uterine milk \" ) ',\n",
       " 'This species lacks economic value but is caught incidentally in bottom trawls , which it is thought to be less able to withstand than other maskrays due to its gracile build ',\n",
       " 'As it also has a limited distribution and low fecundity , the International Union for Conservation of Nature ( IUCN ) has listed it as Near Threatened ',\n",
       " '\\n \\n = = Taxonomy and phylogeny = = \\n \\n The first scientific description of the plain maskray was authored by Commonwealth Scientific and Industrial Research Organisation ( CSIRO ) researcher Peter Last in a 1987 issue of Memoirs of the National Museum of Victoria ',\n",
       " 'The specific name <unk> comes from the Latin an ( \" not \" ) and <unk> ( \" marked \" ) , and refers to the ray \\'s coloration ',\n",
       " 'The holotype is a male 21 @.@ 2 cm ( 8 @.@ 3 in ) across , caught off Western Australia ; several paratypes were also designated ',\n",
       " 'Last tentatively placed the species in the genus Dasyatis , noting that it belonged to the \" maskray \" species group that also included the bluespotted stingray ( then Dasyatis kuhlii ) ',\n",
       " 'In 2008 , Last and William White elevated the kuhlii group to the rank of full genus as Neotrygon , on the basis of morphological and molecular phylogenetic evidence ',\n",
       " '\\n In a 2012 phylogenetic analysis based on mitochondrial and nuclear DNA , the plain maskray and the Ningaloo maskray ( N',\n",
       " '<unk> ) were found to be the most basal members of Neotrygon ',\n",
       " 'The divergence of the N',\n",
       " 'annotata lineage was estimated to have occurred ~ 54 Ma ',\n",
       " 'Furthermore , the individuals sequenced in the study sorted into two genetically distinct clades , suggesting that N',\n",
       " 'annotata is a cryptic species complex ',\n",
       " 'The two putative species were estimated to have diverged ~ 4 @.@ 9 Ma ; the precipitating event was likely the splitting of the ancestral population by coastline changes ',\n",
       " '\\n \\n = = Description = = \\n \\n The pectoral fin disc of the plain maskray is thin and diamond @-@ shaped with narrowly rounded outer corners , measuring 1 @.@ 1 – 1 @.@ 3 times longer than wide ',\n",
       " 'The leading margins of the disc are gently concave and converge at a broad angle to the pointed tip of the snout ',\n",
       " 'The small eyes are placed close together , and behind them are the spiracles ',\n",
       " 'The nostrils are elongated and have a skirt @-@ shaped flap of skin between them ',\n",
       " 'The small mouth bears prominent furrows at the corners and contains two slender papillae on the floor ',\n",
       " 'Small papillae are also found around the outside of the mouth ',\n",
       " 'There are five pairs of gill slits ',\n",
       " 'The pelvic fins are fairly large and pointed ',\n",
       " '\\n The tail is short , barely exceeding the length of the disc when intact , and has a broad and flattened base leading to usually two stinging spines ',\n",
       " 'After the stings , the tail becomes slender and bears a long ventral fin fold and a much shorter , lower dorsal fin fold ',\n",
       " 'Most of the body lacks dermal denticles ; a midline row of 4 – 13 small , closely spaced thorns is present behind the spiracles , and another row of 0 – 4 thorns before the stings ',\n",
       " 'The dorsal coloration is grayish green , becoming pinkish towards the disc margins ; there is a dark mask @-@ like shape around the eyes and a pair of small dark blotches behind the spiracles ',\n",
       " 'The tail behind the stings has alternating black and white bands of variable width , ending with black at the tip ',\n",
       " 'The underside is plain white and the ventral fin fold is light grayish in color ',\n",
       " 'This species grows to 24 cm ( 9 @.@ 4 in ) across and 45 cm ( 18 in ) long ',\n",
       " '\\n \\n = = Distribution and habitat = = \\n \\n The plain maskray inhabits the continental shelf of northern Australia from the Wellesley Islands in Queensland to the Bonaparte Archipelago in Western Australia , including the Gulf of Carpentaria and the Timor and Arafura Seas ',\n",
       " 'There are unsubstantiated reports that its range extends to southern Papua New Guinea ',\n",
       " 'It is the least common of the several maskray species native to the region ',\n",
       " 'This species is a bottom @-@ dweller that prefers habitats with fine sediment ',\n",
       " 'It has been recorded from between 12 and 62 m ( 39 and 203 ft ) deep , and tends to be found farther away from shore than other maskrays in its range ',\n",
       " '\\n \\n = = Biology and ecology = = \\n \\n The plain maskray generally hunts at the surface of the bottom substrate , rather than digging for prey ',\n",
       " 'Its diet consists predominantly of caridean shrimp and polychaete worms ',\n",
       " 'Small bony fishes are also eaten , along with the occasional penaeid prawn or amphipod ',\n",
       " 'Larger rays consume a greater variety of prey and relatively more polychaete worms when compared to smaller rays ',\n",
       " 'This species is parasitized by the tapeworm Acanthobothrium <unk> ',\n",
       " '\\n Like other stingrays , the plain maskray is viviparous with the developing embryos sustained to term by histotroph ( \" uterine milk \" ) produced by the mother ',\n",
       " 'Mature females have a single functional ovary and uterus , on the left ',\n",
       " 'Litter size is one or two ; the newborns measure 12 – 14 cm ( 4 @.@ 7 – 5 @.@ 5 in ) across ',\n",
       " 'Males and females reach sexual maturity at disc widths of 20 – 21 cm ( 7 @.@ 9 – 8 @.@ 3 in ) and 18 – 19 cm ( 7 @.@ 1 – 7 @.@ 5 in ) respectively ',\n",
       " 'The maximum lifespan is estimated to be 9 years for males and 13 years for females ',\n",
       " '\\n \\n = = Human interactions = = \\n \\n The main conservation threat to the plain maskray is incidental capture by commercial bottom trawl fisheries ',\n",
       " \"In the present day , this is mostly caused by Australia 's Northern Prawn Fishery , which operates throughout its range \",\n",
       " 'Although this species is discarded when caught , it is more delicate @-@ bodied than other maskrays and is thus unlikely to survive encounters with trawling gear ',\n",
       " 'Historically , this species may also have been negatively affected by Japanese , Chinese , and Taiwanese trawlers that fished intensively off northern Australia from 1959 to 1990 ',\n",
       " \"These factors , coupled with the plain maskray 's limited distribution and low reproductive rate , have resulted in its being assessed as Near Threatened by the International Union for Conservation of Nature ( IUCN ) \",\n",
       " \"The 2011 – 12 Columbus Blue Jackets season was the team 's 12th season in the National Hockey League ( NHL ) \",\n",
       " \"The Blue Jackets ' record of 29 – 46 – 7 [ note 1 ] was the worst record in the NHL for 2011 – 12 and the first time in franchise history they finished in last place \",\n",
       " 'It also marked the third straight year that they missed the playoffs ',\n",
       " 'Consequently , they had the best chance to receive the first overall selection in the 2012 NHL Entry Draft lottery , but lost out to the Edmonton Oilers and received the second pick instead ',\n",
       " '\\n The Blue Jackets began the year with the worst start in franchise history and the worst by any team in an NHL season in 19 years ',\n",
       " 'After an 11 – 25 – 5 start , Head Coach Scott Arniel was fired and replaced by Assistant Coach Todd Richards ',\n",
       " 'The poor season prompted several personnel changes including the trade of All @-@ Star forward Jeff Carter , who was acquired with much fanfare during the off @-@ season ',\n",
       " \"With the prospect of another rebuild looming the Blue Jackets ' captain and best player , Rick Nash , requested to be traded , though he would remain with the team for the entire season \",\n",
       " '\\n The team was involved in a controversial loss to the Los Angeles Kings , when the Staples Center clock appeared to freeze at 1 @.@ 8 seconds allowing the Kings time to score the tying goal , before winning in overtime ',\n",
       " 'During the season Columbus managed only two winning streaks of three or more games ',\n",
       " 'One of which came towards the end of the year helping the Blue Jackets finish with 65 points , the third worst point total in franchise history ',\n",
       " \"\\n \\n = = Off @-@ season = = \\n \\n In the off @-@ season the Blue Jackets ' approach to building their team changed , moving from a team of young developing players into one with established players \",\n",
       " 'The first deal General Manager Scott Howson made was the acquisition of All @-@ Star forward Jeff Carter on June 23 , 2011 ',\n",
       " \"The deal sent Jakub <unk> , Columbus ' first @-@ round draft choice , the eighth overall , and their third @-@ round pick in the 2011 Draft to the Philadelphia Flyers in exchange for Carter \",\n",
       " 'The trade received a positive response in Columbus from fans and management who felt they finally had a number one center to play alongside of their best player , Rick Nash ',\n",
       " 'Next , they traded for the negotiating rights of soon to be free agent James Wisniewski ',\n",
       " 'Wisniewski scored a career high 51 points during the 2010 – 11 season , splitting time between the New York Islanders and Montreal Canadiens ',\n",
       " 'The point total was fifth @-@ highest in the league for defenseman scoring , tying Tobias <unk> ',\n",
       " 'The Blue Jackets came to terms with Wisniewski , just an hour prior to the start of free agency , signing him to a six @-@ year , $ 33 million deal ',\n",
       " '\\n Columbus also traded former first round draft pick Nikita Filatov to the Ottawa Senators for a third @-@ round pick in the 2011 Draft ',\n",
       " 'Filatov had failed to live up to expectations in Columbus , playing in only 44 games over three seasons scoring six goals ',\n",
       " 'Prior to the start of the season , the Blue Jackets were questioned for not signing a veteran back @-@ up to starting goaltender Steve Mason , as the former Calder Memorial Trophy winner had struggled in consecutive seasons ',\n",
       " 'The Blue Jackets signed Mark <unk> as the back @-@ up who had only 50 minutes of NHL experience prior to the start of the season ',\n",
       " 'Columbus did sign a veteran Curtis Sanford to be their third string goaltender and to start for their American Hockey League ( AHL ) affiliate , the Springfield Falcons ',\n",
       " 'Sanford had not played in the NHL since 2009 ',\n",
       " 'During training camp , <unk> suffered a high ankle sprain that was expected to keep him out of the line @-@ up for a month ',\n",
       " 'Additionally , Sanford suffered a groin injury , leaving Allen York as the back @-@ up ',\n",
       " 'York had only played four professional games , all in the AHL , entering the season ',\n",
       " '\\n \\n = = Regular season = = \\n \\n \\n = = = October – December = = = \\n \\n After the first five games , all losses , Jeff Carter suffered a broken foot that kept him out of the line @-@ up for 10 games ',\n",
       " 'While Carter was injured , the Blue Jackets continued to lose games ',\n",
       " 'In the eighth game of the year , they had a chance to end the losing streak against the Ottawa Senators ',\n",
       " 'Columbus held a 3 – 2 lead with under a minute to play ',\n",
       " 'Jason Spezza tied the game on a late power play , and with just 4 @.@ 7 seconds remaining , Milan Michalek notched the winning goal for the Senators ',\n",
       " 'The loss helped set a franchise record for futility with a 0 – 7 – 1 record to start a season ',\n",
       " '[ note 1 ] The losing streak came to an end three days later with a win over the Detroit Red Wings ',\n",
       " 'During the game , several milestones were reached ',\n",
       " 'James Wisniewski made his Columbus debut , Ryan Johansen and John Moore scored their first career NHL goals and Grant <unk> had a career @-@ high three assists ',\n",
       " 'Columbus was unable to create any momentum from the win , however , and continued to struggle , culminating in a 2 – 12 – 1 record , which was the worst start to an NHL season for any team in 19 years ',\n",
       " 'With the team struggling , management attempted to \" shake things up \" by making some roster moves ',\n",
       " 'The first move was the acquisition of center Mark <unk> from the Pittsburgh Penguins ',\n",
       " 'Next , they traded defenseman Kris Russell to the St',\n",
       " 'Louis Blues for Nikita Nikitin ',\n",
       " 'As the clubs slow start continued , there were rumors that Head Coach Scott Arniel would be fired and replaced with Ken Hitchcock ',\n",
       " 'Hitchcock had previously coached the Blue Jackets to their only playoff appearance in club history and was still under contract with the franchise through to the end of the season ',\n",
       " 'Before any of these rumors came to fruition , the St',\n",
       " 'Louis Blues asked Columbus for permission to hire Hitchcock , which the Blue Jackets allowed ',\n",
       " 'Hitchcock began his Blues coaching career with a 6 – 1 – 2 record in his first nine games , while Columbus amassed a 6 – 13 – 3 record to start the season ',\n",
       " '\\n During the same time frame as the Hitchcock rumors , goaltender Curtis Sanford returned from his groin injury on November 13 ',\n",
       " 'He made his first start of the season against the Boston Bruins , losing 2 – 1 in a shootout ',\n",
       " 'Sanford continued his strong play , posting a 3 – 1 – 2 record , 1 @.@ 38 goals against average and <unk> save percentage over his next six games ',\n",
       " 'Sanford started 12 consecutive games before Steve Mason made his next start ',\n",
       " 'The number of starts might not have been as numerous , but prior to the November 23 game , Mason was hit in the head by a shot from Rick Nash during pre @-@ game warm @-@ ups and suffered a concussion ',\n",
       " 'Mason returned from his concussion after two games , making a start against the Vancouver Canucks ',\n",
       " 'Mason allowed only one goal in the game despite suffering from cramping in the third period , temporarily being replaced by Sanford for just over three minutes ',\n",
       " 'Columbus won the game 2 – 1 in a shootout , breaking a nine @-@ game losing streak to the Canucks ',\n",
       " \"After the game , Arniel stated that Sanford was still seen as the team 's number one goaltender \",\n",
       " 'However , Mason started four of the next six games with the Blue Jackets going 0 – 5 – 1 during that stretch ',\n",
       " '\\n \\n = = = January – February = = = \\n \\n With the losing continuing , more rumors began to surface ',\n",
       " 'Unlike before , the rumors were about player moves rather than coaching changes ',\n",
       " 'The majority of rumors were that the Blue Jackets would trade Rick Nash ',\n",
       " 'While Howson stated that he had never brought up trading Nash in discussions , other teams had inquired about his availability ',\n",
       " 'Nash stated that if Columbus felt it would make the franchise better than he would be willing to waive his no @-@ trade clause ',\n",
       " 'Howson publicly stated that he had no intention of trading Nash ',\n",
       " 'More rumors came to light when reports attributed to Réseau des sports stated that Carter was unhappy in Columbus and demanded a trade ',\n",
       " 'Howson , Carter and his agent all denied that a trade request was ever made , and they were unsure where the reports were coming from ',\n",
       " 'With the trade deadline approaching , speculation picked up on the Blue Jackets trading Carter ',\n",
       " 'Reports were that Columbus was trying to trade Carter and that he was \" 100 percent available ',\n",
       " '\" \\n At the halfway point of the season , with the Blue Jackets barely into double digit wins with an 11 – 25 – 5 record , worst in the league , and sitting 20 points out of playoff position , Columbus fired Arniel ',\n",
       " 'He was replaced by Assistant Coach Todd Richards on an interim basis ',\n",
       " 'Richards had previously coached the Minnesota Wild ',\n",
       " 'He recorded his first coaching victory for the Blue Jackets in his second game , a 4 – 3 win over the Phoenix Coyotes ',\n",
       " 'The change in coaching did not change the fortunes of the team , as they reached the All @-@ Star break with a 13 – 30 – 6 record ',\n",
       " \"At the break , Blue Jackets ' owner John P\",\n",
       " 'McConnell sent out a letter to fans stating his understanding of their frustration ',\n",
       " 'He added that action would be taken around the trade deadline , the Entry Draft and free agency to take the team in a new direction ',\n",
       " 'When speaking of the season , McConnell stated \" disappointing is not a strong enough word \" and that he was committed to giving fans a team of which they can be proud of ',\n",
       " 'He also thanked them for their dedication and passion , while reiterating that the team goal was to \" win consistently and compete for the Stanley Cup ',\n",
       " '\" Days later , a 250 @-@ person protest occurred outside of Nationwide Arena ',\n",
       " \"Fans were upset with the Blue Jackets ' management and were calling for changes at the top \",\n",
       " 'The same day the fans protested , it was announced that the franchise would host the 2013 All @-@ Star Game ',\n",
       " 'Columbus was without a representative for the 2012 All @-@ star Game , but Ryan Johansen represented the club as a rookie participant in the Super Skills Competition ',\n",
       " 'In the competition , Johansen participated in the Allstate Insurance NHL Breakaway Challenge , a shootout themed event judged by the fans ',\n",
       " 'He received just 1 % of the vote and finished last ',\n",
       " \"\\n Following the break , the Blue Jackets were on the road playing the Los Angeles Kings , and with the score tied late in the game , Kings ' defenseman Drew Doughty scored with just 0 @.@ 4 seconds remaining to win the game \",\n",
       " 'Upon review of the goal it , was determined that the clock at Staples Center froze at 1 @.@ 8 seconds for over a full second , which would have resulted in time expiring prior to the goal being scored ',\n",
       " \"Kings ' General Manager Dean Lombardi stated that the clock was correct and no extra time had been added due to the way the clock self @-@ corrects at various times \",\n",
       " 'Howson stated on the team \\'s blog that \" It is an amazing coincidence that with the Kings on a power play at Staples Center and with a mad scramble around our net in the dying seconds of the third period of a 2 – 2 hockey game that the clock stopped for at least one full second , \" adding that , \" Either there was a deliberate stopping of the clock or the clock malfunctioned ',\n",
       " '\" NHL Senior Vice President of Hockey Operations Colin Campbell stated that the Blue Jackets were wronged , but that the outcome of the game could not be changed , and that the delay was not noticed by the off @-@ ice officials or the situation room in Toronto ',\n",
       " \"To determine the true cause of the clock pause , the NHL launched an investigation , talking with the clock 's manufacturer and interviewing Staples Center staff \",\n",
       " '\\n Two weeks prior to the NHL trade deadline , Columbus announced that unlike earlier in the season , they would listen to trade proposals involving Rick Nash , though they were not actively shopping him ',\n",
       " 'Howson stated that the team was open to all options for improving the team , including trading Nash ',\n",
       " 'Speculation was that in return for Nash the Blue Jackets would ask for a \" combination of young , proven players , high @-@ end prospects and draft picks ',\n",
       " '\" Leading up to the trade deadline , the Blue Jackets dealt Antoine <unk> to the Phoenix Coyotes for two draft picks and goaltender Curtis McElhinney ',\n",
       " 'Despite being injured at the time , the acquisition of McElhinney was believed to give Columbus the flexibility to trade Curtis Sanford ',\n",
       " 'The following day , on February 23 , Columbus traded Jeff Carter to the Kings ',\n",
       " 'In the deal , Columbus acquired defenseman Jack Johnson and a first @-@ round draft pick ; the team was given the choice of taking the pick in either 2012 or 2013 ',\n",
       " 'At the deadline , Columbus was unable to come to terms on a deal involving Nash , but they did make one more move ; they sent center Samuel Pahlsson to the Vancouver Canucks in exchange for two fourth @-@ round draft picks and minor league defenseman Taylor Ellington ',\n",
       " \"Following the trade deadline , Howson announced that the team had attempted to trade Nash at the player 's request \",\n",
       " 'Nash stated that he had requested the trade after being informed that the franchise was going into another rebuilding phase ',\n",
       " 'He further noted that he felt that he \" could be a huge part of that towards bringing assets in , \" and in his view \" it was the best thing for the team , the organization , and personally for [ his ] career ',\n",
       " '\" After the personnel changes , the Blue Jackets closed out the month with a three @-@ game losing streak ',\n",
       " '\\n \\n = = = March – April = = = \\n \\n Columbus started March with a 2 – 0 shutout against the Colorado Avalanche ',\n",
       " 'They proceeded to win their next game against the Phoenix Coyotes 5 – 2 , which marked the first time that the Blue Jackets posted back @-@ to @-@ back regulation victories during the season ',\n",
       " 'Columbus again defeated the Coyotes three days later to earn their first three @-@ game win streak of the season ',\n",
       " 'They extended the streak to four with a win over the Los Angeles Kings before it came to an end with a 4 – 1 loss to the St',\n",
       " 'Louis Blues ',\n",
       " 'It was the only four @-@ game win streak of the season for the Blue Jackets ',\n",
       " 'They immediately matched their four @-@ game win streak with a four @-@ game losing streak and with ten games remaining , the Blue Jackets were the first team eliminated from playoff contention ',\n",
       " 'Shortly after being eliminated , they were defeated by the Edmonton Oilers 6 – 3 ; the loss clinched last place in the NHL for Columbus ',\n",
       " 'It was the first time in franchise history the Blue Jackets finished in 30th place ',\n",
       " '\\n Three days later , on March 28 , goaltender Steve Mason was injured in the morning skate when a shot from Colton Gillies hit him in the mask ',\n",
       " 'With Sanford again injured , York made an emergency start ',\n",
       " 'Playing against the Detroit Red Wings , York made 29 saves , including 17 in the third period , helping Columbus to a 4 – 2 victory and giving York his first career NHL win ',\n",
       " 'York remained the starter and led the Blue Jackets to a second three @-@ game winning streak ',\n",
       " 'In his fourth start , Columbus was shutout by the Coyotes despite a franchise @-@ record 54 shots on goal , losing 2 – 0 ',\n",
       " 'The 54 saves by Phoenix goaltender Mike Smith set an NHL record for a regulation shutout ',\n",
       " \"Mason returned to the starter 's role for the final two games , winning both \",\n",
       " 'The two victories gave Columbus 65 points for the year , their third @-@ lowest total in franchise history ',\n",
       " '\\n The Blue Jackets struggled in shorthanded situations , allowing the most power @-@ play goals in the League , with 64 , and having the lowest penalty @-@ kill percentage , at 76 @.@ 64 % \\n \\n = = Post @-@ season = = \\n \\n Finishing with the worst record in the NHL , Columbus had the best chance of receiving the first overall pick in the 2012 draft ',\n",
       " \"With the NHL 's weighted draft lottery the Blue Jackets had a 48 @.@ 2 % chance of drafting first overall \",\n",
       " 'However , the lottery was won by the Edmonton Oilers , who proceeded to leapfrog Columbus and secure the number one draft pick for a third consecutive year ',\n",
       " \"It was the fifth time that the Blue Jackets were dropped one draft position in the franchise 's 12 lottery participations \",\n",
       " '\\n A month later , on May 14 , the Blue Jackets announced that Richards would remain as head coach and signed him to a two @-@ year contract ',\n",
       " 'During the press conference , Howson noted , \" Our team continuously improved under Todd and he has earned the opportunity to build upon the work he started ',\n",
       " '\" Columbus posted an 18 – 21 – 2 record under Richards , including winning seven of their final 11 games ',\n",
       " '\\n \\n = = Standings = = \\n \\n Since being founded as an expansion team , the Blue Jackets have played in the Central Division of the Western Conference ',\n",
       " 'Division rivals Chicago Blackhawks , Detroit Red Wings , Nashville Predators and St',\n",
       " 'Louis Blues , all made the playoff during the 2011 – 12 season , which helped Columbus finish 36 points behind fourth place Chicago and 44 points out of first ',\n",
       " \"\\n Divisions : CE – Central , NW – Northwest , PA – Pacific \\n bold - qualified for playoffs , y – Won division , p – Won Presidents ' Trophy ( best record in NHL ) \\n \\n = = Schedule and results = = \\n \\n \\n = = = Pre @-@ season = = = \\n \\n \\n = = = Regular season = = = \\n \\n Green background indicates win ( 2 points ) \",\n",
       " '\\n Red background indicates regulation loss ( 0 points ) ',\n",
       " '\\n Silver background indicates overtime / shootout loss ( 1 point ) ',\n",
       " \"\\n \\n = = Player statistics = = \\n \\n In ice hockey , a combination of a player 's goals and assists are collectively called points \",\n",
       " 'Penalty minutes are the total number of minutes assigned to a player for infractions assessed during the <unk> @-@ minus is a statistic that tracks when a player was on the ice while goals were scored , both for and against their team , though some in game situations will not effect the statistic ',\n",
       " 'Below is a listing of all player statistics for the Blue Jackets during the season ',\n",
       " '\\n \\n = = = Skaters = = = \\n \\n Note : Pos \\n = Position ; GP = \\n Games played in ; G \\n = Goals ; A = \\n Assists ; Pts \\n = Points ; PIM = \\n Penalty minutes ; + / - = Plus / minus \\n \\n = = = Goaltenders = = = \\n \\n Note : GP \\n = Games Played ; TOI = \\n Time On Ice ( minutes ) ; W \\n = Wins ; L = \\n Losses ; OT \\n = Overtime Losses ; GA = \\n Goals Against ; GAA = Goals Against Average ; SA = Shots Against ; SV \\n = Saves ; Sv % = \\n Save Percentage ; SO = Shutouts \\n † Denotes player spent time with another team before joining Blue Jackets ',\n",
       " 'Stats reflect time with the Blue Jackets only ',\n",
       " '‡ Traded mid @-@ season \\n \\n = = Milestones = = \\n \\n When Mason was injured in warm @-@ ups late in the year , Columbus was without an active goaltender on their roster ',\n",
       " 'To remedy the situation , the team signed former University of Michigan goaltender Shawn Hunwick to a one @-@ day , amateur tryout contract ',\n",
       " 'After being eliminated from the NCAA Tournament just days prior , Hunwick skipped an astronomy class and drove his worn down 2003 Ford Ranger to Columbus to make the game ',\n",
       " 'He served as the back @-@ up to Allen York during the game , and the following day , he signed a contract for the remainder of the year ',\n",
       " \"With Mason returning from injury , Hunwick was third on the team 's depth chart when an injury to York allowed Hunwick to remain as the back @-@ up for the final two games of the year \",\n",
       " 'In the final game of the season , the Blue Jackets were leading the Islanders 7 – 3 with 2 : 33 remaining when , at the behest of his teammates , Head Coach Todd Richards put Hunwick in to finish the game ',\n",
       " 'He did not face a shot ',\n",
       " 'Hunwick was the franchise record ninth player to make his NHL debut during the season ',\n",
       " 'Conversely , Vaclav <unk> played in his 1,000th NHL game during the year ',\n",
       " '\\n \\n = = Transactions = = \\n \\n During the off @-@ season the Blue Jackets parted ways with defensemen Jan Hejda , Anton Stralman , Sami <unk> and Mike Commodore ',\n",
       " 'Hejda , who played four of his first five NHL seasons with the Blue Jackets , was offered a contract by Columbus , but felt that the organization undervalued him and left via free agency ',\n",
       " 'Columbus had offered him a three @-@ year , $ 7 @.@ 5 million contract ',\n",
       " 'He instead signed a four @-@ year , $ 13 million deal with the Colorado Avalanche ',\n",
       " 'Stralman and <unk> were not given qualifying offers which made them unrestricted free agents , and both signed with other teams ',\n",
       " 'Commodore had originally signed a big contract with the Blue Jackets in 2008 , but fell out of favor ',\n",
       " 'He was waived , sent to the minors and eventually had his contract bought out ',\n",
       " 'In order to replace the departed players , Columbus not only acquired James Wisniewski , but also signed ten @-@ year NHL veteran Radek <unk> ',\n",
       " '<unk> played only seven games with the Blue Jackets before suffering a concussion and missing the remainder of the season ',\n",
       " 'Brett <unk> was brought in to replace him .',\n",
       " 'The Gregorian Tower ( Italian : Torre <unk> ) or Tower of the Winds ( Italian : Torre dei Venti ) is a round tower located above the Gallery of Maps , which connects the Villa Belvedere with the Apostolic Palace in Vatican City ',\n",
       " 'The tower was built between 1578 and 1580 to a design by the Bolognese architect Ottaviano Mascherino ( who was credited with building the Apostolic Palace ) mainly to promote the study of astronomy for the Gregorian Calendar Reform which was commissioned by Pope Gregory XIII and promulgated in 1582 ',\n",
       " 'It was then also known as the Tower of Winds ',\n",
       " 'The tower is now called the \" <unk> Astronomica Vaticana \" , the Vatican Observatory ',\n",
       " 'Four stages of progressive development have occurred since it was first established ',\n",
       " 'The tower was an edifice of great value for astronomical observations made using a sundial as they provided essential confirmation of the need to reform the Julian calendar ',\n",
       " '\\n \\n = = Early history = = \\n \\n The first stage of building of the tower , as recorded by Leo XIII in his motu proprio Ut <unk> of 1891 , is credited to Pope Gregory XIII , Pope from 1572 to 1585 ',\n",
       " 'The directive was to build a tower at a suitable location in the Vatican and equip it with the \" greatest and best instruments of the time \" ',\n",
       " 'The design was effected after a series of meetings of the experts who had been appointed to reform the Julian calendar , in use since 45 BC , to verify their proposed reforms ',\n",
       " 'Christoph Clavius , a Jesuit mathematician from the Roman College , was the expert on the committee who suggested the new system for the observations ',\n",
       " 'The 73 metres ( 240 ft ) tower was then built above the museum and library , flanked by the Belvedere and della Pigna courtyards ',\n",
       " 'The instrumentation for the observation of the sun rays falling over it consisted of a meridian line designed by Ignazio <unk> of Perugia ',\n",
       " 'It was in the form of a circular marble plate in the centre , embellished with scientific designs ',\n",
       " 'The tower still remains today , but has undergone improvements over the centuries ',\n",
       " '\\n \\n = = Second stage = = \\n \\n The second stage of construction in the 17th and 18th centuries , when the tower was under the charge of the Vatican librarian , involved Mgr ',\n",
       " 'Filippo Luigi Gilii , a clergyman of St',\n",
       " \"Peter 's Basilica \",\n",
       " \"Earlier in 1797 , Pius VI gave approval to placing a Latin inscription <unk> Vaticana at the entrance to the upper part of the tower , which was implemented by Cardinal <unk> with plans to enhance the instrumentation system in the tower 's observatory \",\n",
       " 'The original observatory was then set up above the second level of the tower with the agreement of Pope Pius VI ',\n",
       " 'Its instrumentation , apart from many normal devices ( such as meteorological and magnetic equipment , with a seismograph and a small transit and pendulum clock , ) was noted for the <unk> Telescope ',\n",
       " 'The instrumentation facilitated recording of occurrences of eclipse , appearance of comets , Satellites of Jupiter and Mercury ’ s transit ',\n",
       " 'As an addition , under the patronage of Pope Pius X , four rotary observatory domes were also added at strategic locations on the 1 @,@ 300 feet ( 400 m ) long fortification walls , more than a thousand years old ',\n",
       " 'Gilii , highly respected as a polyglot with a knowledge of physics , biology , archeology and the Hebrew language , was in charge of the observatory from 1800 to 1821 ',\n",
       " 'He carried out continuous meteorological observations ( twice a day at 6 AM and 2 PM ) conforming to the programme of the Mannheim Meteorological Society ',\n",
       " 'While the observation records for seven years were published , the balance data in a manuscript form was preserved in the Vatican Library ',\n",
       " \"Subsequent to Gilii 's death in 1821 , the observatory on the tower was discontinued and the instruments were moved to the observatory at the Roman College \",\n",
       " 'Established in 1787 , it was considered more suitable for making observations than the Vatican ',\n",
       " '\\n \\n = = Third stage = = \\n \\n The revival of the observatory on the Gregorian Tower was initiated by the <unk> Francesco Denza with the approval of Pope Leo XIII ',\n",
       " 'High quality instruments were procured , partly with generous donations from Hicks of London , and the automatic recording instruments were procured from Richard in Paris ',\n",
       " 'A four @-@ inch equatorial , a three @-@ inch transit instrument , and four pendulum clocks with two chronometers , were also procured from the observatory at Modena ',\n",
       " 'In 1888 , the gift of a 16 inch long telescope to Pope Leo XIII , became a part of the observatory ',\n",
       " 'Father Denza joined the observatory in 1889 after it was upgraded with more modern instruments ',\n",
       " 'The same year , a second tower was built some 400 metres ( 1 @,@ 300 ft ) away from the main Gregorian Tower , overlooking the Vatican Gardens behind St',\n",
       " \"Peter 's Basilica on the south @-@ west border \",\n",
       " 'It was built to a diameter of 17 metres ( 56 ft ) with a lower wall thickness of 4 @.@ 5 metres ( 15 ft ) , which could bear the load of a 13 inch photographic refractor , newly procured from Paris ',\n",
       " 'Augustinian Father Rodriguez was the expert meteorologist who held the post of director from 1898 to 1905 ',\n",
       " 'In 1891 , Pope Leo XIII , promulgating the motu proprio Ut <unk> , designated the second tower as the seat of the newly established Vatican Observatory , a decision which required altering the roof to provide a flat terrace for astronomical observations ',\n",
       " '\\n \\n = = Fourth stage = = \\n \\n The fourth stage involved remedying the problem of communicating between the two towers during the time of Pope Pius X',\n",
       " 'His plans were to make the Gregorian Tower into a historical tower and to record and carry out observations at the second tower by linking the two towers along the fortified wall with a 83 metres ( 272 ft ) iron bridge spanning the gap ',\n",
       " 'At the west end of this bridge , a four @-@ inch equatorial was installed on semicircular bastion ',\n",
       " 'The east end of the bridge , above the barracks of the gendarmes , had a heliograph , with a camera attached , used to photograph the Sun ( <unk> ) ',\n",
       " 'A new 16 @-@ inch visual telescope , called Torre Pio X , was erected in the second tower ',\n",
       " 'As a result of these modifications , the original library was moved to the Pontifical Academy Lincei , and the old meteorological and seismic instruments were shifted to the Valle di Pompei observatory ',\n",
       " 'The new Astronomical Library was housed in two rooms of the building ',\n",
       " 'The two new <unk> machines were used for recording on the <unk> plates ',\n",
       " 'The recorded observations were published along with explanatory notes together with the last two series of the atlas of stars ',\n",
       " 'Charts were printed on silver bromide paper ',\n",
       " '\\n \\n = = Features = = \\n \\n The tower had two floors and a mezzanine ',\n",
       " 'On the first floor was the famous Sundial Room or Meridian Room , which was initially an open loggia ',\n",
       " 'Pope Urban VIII had it enclosed and it was subsequently decorated with long sequences of frescoes painted between 1580 and 1582 by Simon Lagi and the two Flemish artists Paul and Matthijs <unk> ',\n",
       " 'Today the tower has paintings by Cristoforo Roncalli and <unk> da Siena ',\n",
       " '\\n The Sundial Room , also called the Meridian Hall , was once the residence of Queen Christina of Sweden , then newly converted to Catholicism ',\n",
       " 'The room was further modified by two additions which gave it its current name : a sundial , and a delicate but sophisticated <unk> which was fixed to the ceiling of the Meridian Hall ',\n",
       " 'These were created by Ignazio <unk> , the papal <unk> , in association with the Gregorian Calendar Reform ',\n",
       " 'The sundial consisted of a straight line in white marble running across the floor in a north @-@ south direction , intended to measure the height of the Sun at noon according to the seasons of the year ',\n",
       " 'The observations made with the sundial provided essential confirmation of the need to reform the Julian calendar ',\n",
       " 'The <unk> , in contrast , was a complex mechanism attached to the ceiling which was used to measure the strength and direction of the wind but soon stopped functioning ',\n",
       " 'The instrument may have led to the other name of the tower , Tower of the Winds ; however , an ancient observatory at Athens was also called the Tower of the Winds and might have been the source for inspiration ',\n",
       " '\\n The interior walls and ceiling of the hall were richly decorated , in some cases with gaudy frescoes of the hills and Roman countryside , the <unk> , religious themes , the buildings surrounding the area , and naval shipwrecks with Jesus calming the storm and so forth ',\n",
       " '\" There \\'s Got to Be a Way \" is a song by American singer and songwriter Mariah Carey from her self @-@ titled debut studio album ( 1990 ) ',\n",
       " 'Columbia released it as the fifth and final single from the album in the United Kingdom ',\n",
       " 'It was one of four songs Carey wrote with Ric Wake during their first recording session together , but \" There \\'s Got to Be a Way \" was the only composition to make the final track listing ',\n",
       " 'It is a socio @-@ political conscious R & B @-@ pop song which addresses the existence of poverty , racism and war in the world which gradually becomes more aspirational and positive as it progresses ',\n",
       " \"The track garnered a mixed reception upon the album 's release in 1990 \",\n",
       " \"While Carey 's vocals were praised , it was seen as too political \",\n",
       " 'An accompanying music video highlights social injustices ',\n",
       " 'The song reached number 54 on the UK Singles Chart ',\n",
       " '\\n \\n = = Background and release = = \\n \\n \" There \\'s Got to Be a Way \" was written by Mariah Carey and Ric Wake for Carey \\'s self @-@ titled debut studio album ( 1990 ) ',\n",
       " \"It was written during Carey and Wake 's first recording session together \",\n",
       " 'They composed four songs , but only \" There \\'s Got to Be a Way \" was chosen for the final track listing ',\n",
       " 'Co @-@ produced by Wake and Narada Michael Walden , it appears as the second of ten songs on the track listing ',\n",
       " 'The track was recorded and engineered by Bob <unk> at Cove City Sound Studios and The Power Station , both located in New York City ',\n",
       " 'He was assisted by Dana Jon Chappelle ',\n",
       " 'It was mixed by David Frazer at Tarpan Studios in San Rafael ',\n",
       " 'The keyboards , bass and rhythm engineering was carried out by Louis Biancaniello , while Joe Franco performed the percussion , Vernon \" Ice \" Black played the guitar , and Rich Tancredo also performing on the keyboards ',\n",
       " 'Walter Afanasieff played the synth horns ',\n",
       " 'Carey provided her own background vocals along with Billy T',\n",
       " 'Scott , <unk> Muhammed and The Billy T',\n",
       " 'Scott Ensemble ',\n",
       " 'The song was released as the fifth and final single from the album in the United Kingdom ',\n",
       " 'It is available to purchase as a CD single while the remixes are available on vinyl ',\n",
       " '\\n \\n = = Composition = = \\n \\n \" There \\'s Got to Be a Way \" is an R & B @-@ pop music song with elements of gospel ',\n",
       " 'The theme of social activism can be heard in the lyrics \" There ’ s got to be a way / to connect this world today ',\n",
       " '\" The song begins with Carey publicly denouncing the existence of poverty and racism in the world , and she uses the bridge to shift the lyrics towards an uplifting and aspirational tone ',\n",
       " 'Carey suggests we should be more tolerant of each other and not resort so readily to war in the lyrics \" Couldn \\'t we accept each other / Can \\'t we make ourselves aware ',\n",
       " '\" \\n \\n = = Critical reception = = \\n \\n Music critic Robert Christgau felt that Carey was being too political in her \" brave , young , idealistic attack \" on war and destitution ',\n",
       " 'Ralph Novak , David Hiltbrand and David Grogan of People wrote that it is a \" testimony to her talent that she does so much with so little ',\n",
       " '\" They continued to write that Carey \\'s \" tone and clarity \" makes \" There \\'s Got to Be a Way \" a \" mesmerizing \" track ',\n",
       " 'To mark twenty @-@ five years since the release of Mariah Carey in June 1990 , Billboard writer Trevor Anderson wrote a track @-@ by @-@ track review of the album in June 2015 ',\n",
       " 'He noted that \" There \\'s Got to Be a Way \" follows the same melodic tone as the album \\'s opener \" Vision of Love \" but highlighted their stark lyrical differences , as the former is about social activism and the latter is about love ',\n",
       " 'Although he praised Carey \\'s vocals , writing that she \" deploys \" one of her best whistle notes of her career , he felt that \" the aim for broad appeal comes at the expense of memorable lyrics ',\n",
       " '\" \\n \\n = = Music video = = \\n \\n The accompanying music video begins with a shot of an empty street , followed by clips of disadvantaged and poorer members of society going about their daily activities ',\n",
       " 'Two men play dominoes on a wooden crate outside a building , a gang make fun of an elderly man hanging newspapers outside his store and an obese woman walks down the street ',\n",
       " 'Clips of Carey leaning against a wall and sitting on some steps looking on at what is happening are shown ',\n",
       " 'As the first chorus begins , everyone starts to dance joyfully in the street and help those in need ',\n",
       " 'A gospel choir comes out of one of the buildings as the street becomes more crowded with people of all ages and backgrounds rejoicing and getting along with each other ',\n",
       " 'One of the shops in the background has a neon light outside the entrance which says \" Jesus Saves \" ',\n",
       " '\\n \\n = = Track listings = = \\n \\n \" There \\'s Got to Be a Way \" ( Original album version ) – 4 : 52 \\n \" There \\'s Got to Be a Way \" ( 7 \" remix ) \\n \" There \\'s Got to Be a Way \" ( 12 \" remix ) \\n \" There \\'s Got to Be a Way \" ( Alternative Vocal Dub Mix ) \\n \\n = = Charts = = \\n \\n',\n",
       " 'Nebraska Highway 88 ( N @-@ 88 ) is a highway in northwestern Nebraska ',\n",
       " 'It has a western terminus at Wyoming Highway 151 ( WYO 151 ) at the Wyoming – Nebraska state line ',\n",
       " 'The road travels eastward to N @-@ 71 , where it turns south ',\n",
       " 'N @-@ 88 continues east to south of Bridgeport ',\n",
       " 'The road turns north , ends at an intersection with U.S',\n",
       " 'Highway 385 ( US 385 ) and N @-@ 92 in Bridgeport ',\n",
       " 'The route was designated in 1937 , before the official state highway system was created ',\n",
       " 'It was extended to the state line in 1986 ',\n",
       " '\\n \\n = = Route description = = \\n \\n N @-@ 88 starts at the Nebraska – Wyoming state line in Banner County , where WYO 151 ends , and travels northeast ',\n",
       " 'The road quickly bends east after less than one mile ( 1 @.@ 6 km ) , and continues in a straight line ',\n",
       " 'For the next twenty miles ( 32 km ) , N @-@ 88 intersects minor streets , through rural farmland ',\n",
       " 'The route turns south at N @-@ 71 , and becomes concurrent ',\n",
       " 'Four miles ( 6 @.@ 4 km ) later , N @-@ 88 turns east , ending the concurrency with N @-@ 71 ',\n",
       " 'The route continues to travel through farmland for sixteen miles ( 26 km ) , where it enters Morrill County ',\n",
       " 'The road crosses over Pumpkin Creek four times , and enters the unincorporated community of <unk> ',\n",
       " 'Two rock formations , Courthouse and Jail Rocks , become visible from the road ',\n",
       " 'N @-@ 88 turns north toward Bridgeport soon after ',\n",
       " 'The road crosses over Pumpkin Creek for the fifth time , and enters into Bridgeport five miles ( 8 @.@ 0 km ) later ',\n",
       " 'The road intersects a railroad owned by BNSF Railway ',\n",
       " 'N @-@ 88 turns northeast soon after , and ends at the intersection of US 385 and N @-@ 92 ',\n",
       " 'In 2012 , Nebraska Department of Roads ( <unk> ) calculated as many as 2 @,@ 410 vehicles traveling on the N @-@ 71 / N @-@ 88 concurrency , and as few as 315 vehicles traveling east of the Banner – Morrill county line ',\n",
       " 'This is expressed in terms of annual average daily traffic ( AADT ) , a measure of traffic volume for any average day of the year ',\n",
       " 'Only the N @-@ 71 / N @-@ 88 concurrency is part of the National Highway System ( NHS ) , a network of highways identified as being most important for the economy , mobility and defense of the nation ',\n",
       " '\\n \\n = = History = = \\n \\n N @-@ 88 was unofficially designated around 1937 , connecting from N @-@ 29 , to N @-@ 86 and N @-@ 19 in Bridgeport ',\n",
       " 'The route remained relatively the same as the state highway system was officially designated ',\n",
       " 'Before 1955 , Nebraska did not have an adequate legal instrument to define the state highway system ',\n",
       " 'By 1960 , N @-@ 19 was renumbered to US 385 , and US 26 was rerouted north near Bridgeport ',\n",
       " 'The old alignment became part of N @-@ 92 ',\n",
       " 'Two years later , N @-@ 29 was renumbered to N @-@ 71 ',\n",
       " 'Between 1981 @-@ 82 , a road appeared on the official state map , extending from WYO 151 to N @-@ 71 ',\n",
       " 'That road became part of N @-@ 88 by 1986 ',\n",
       " 'No significant changes have been made since ',\n",
       " '\\n \\n = = Major intersections = = \\n \\n',\n",
       " 'Atlanta was a casemate ironclad that served in the Confederate and Union Navies during the American Civil War ',\n",
       " 'She was converted from a Scottish @-@ built blockade runner named Fingal by the Confederacy after she made one run to Savannah , Georgia ',\n",
       " 'After several failed attempts to attack Union blockaders , the ship was captured by two Union monitors in 1863 when she ran aground ',\n",
       " 'Atlanta was floated off , repaired , and rearmed , serving in the Union Navy for the rest of the war ',\n",
       " 'She spent most of her time deployed on the James River supporting Union forces there ',\n",
       " 'The ship was decommissioned in 1865 and placed in reserve ',\n",
       " 'Several years after the end of the war , Atlanta was sold to Haiti , but was lost at sea in December 1869 on her delivery voyage ',\n",
       " \"\\n \\n = = Description and career as Fingal = = \\n \\n Fingal was designed and built as a merchantman by J & G Thomson 's Clyde Bank Iron Shipyard at Govan in Glasgow , Scotland , and was completed early in 1861 \",\n",
       " 'She was described by Midshipman Dabney Scales , who served on the Atlanta before her battle with the monitors , as being a two @-@ masted , iron @-@ hulled ship 189 feet ( 57 @.@ 6 m ) long with a beam of 25 feet ( 7 @.@ 6 m ) ',\n",
       " 'She had a draft of 12 feet ( 3 @.@ 7 m ) and a depth of hold of 15 feet ( 4 @.@ 6 m ) ',\n",
       " 'He estimated her tonnage at around 700 tons bm ',\n",
       " 'Fingal was equipped with two vertical single @-@ cylinder direct @-@ acting steam engines using steam generated by one flue @-@ tubular boiler ',\n",
       " 'The engines drove the ship at a top speed of around 13 knots ( 24 km / h ; 15 mph ) ',\n",
       " 'They had a bore of 39 inches ( 991 mm ) and a stroke of 30 inches ( 762 mm ) ',\n",
       " \"\\n The ship briefly operated between Glasgow and other ports in Scotland for Hutcheson 's West Highland Service before she was purchased in September 1861 by James D\",\n",
       " 'Bulloch , the primary foreign agent in Great Britain for the Confederacy , to deliver the military and naval ordnance and supplies that he had purchased ',\n",
       " 'To disguise his control of Fingal , and the destination of her cargo , Bulloch hired an English crew and captain and put out his destination as Bermuda and Nassau in the Bahamas ',\n",
       " 'The cargo was loaded in Greenock in early October , although Bullock and the other passengers would not attempt to board until they rendezvoused with the ship at Holyhead , Wales ',\n",
       " 'On the night 14 / 15 October , as she was slowly rounding the breakwater at Holyhead , Fingal rammed and sank the Austrian brig <unk> , slowly swinging at anchor without lights ',\n",
       " \"Bulloch and the passengers embarked in the steamer while Bulloch dispatched a letter to his financial agents instructing them to settle damages with the brig 's owners because he could not afford to take the time to deal with the affair lest he and Fingal be detained \",\n",
       " \"The ship reached Bermuda on 2 November and , after leaving port on 7 November , Bulloch informed the crew that the steamer 's real destination was Savannah , Georgia ; he offered to take anyone who objected to the plan to Nassau \",\n",
       " 'However , all of the crew agreed to join in the effort to run the Union blockade ',\n",
       " 'Fingal was able slip safely into the Savannah estuary in a heavy fog on the night of 12 November without sighting any blockaders ',\n",
       " '\\n While Fingal was discharging her cargo , Bulloch went to Richmond to confer with Stephen Mallory , Secretary of the Navy ',\n",
       " \"Mallory endorsed Bulloch 's plan to load Fingal with cotton to sell on the Navy Department 's account to be used to purchase more ships and equipment in Europe \",\n",
       " 'He returned to Savannah on 23 November and it took him almost a month to purchase a cargo and acquire enough coal ',\n",
       " 'He made one attempt to break through the blockade on 23 December , but it proved impossible to do as the Union controlled every channel from Savannah , aided by their occupation of Tybee Island at the mouth of the Savannah River ',\n",
       " 'Bulloch reported to Mallory in late January 1862 that breaking out was hopeless so Mallory ordered him to turn the ship over to another officer and to return to Europe some other way ',\n",
       " '\\n \\n = = As Atlanta = = \\n \\n The brothers Asa and Nelson Tift received the contract to convert the blockade runner into an ironclad in early 1862 with the name of Atlanta , after the city in Georgia ',\n",
       " 'This was largely financed by contributions from the women of Savannah ',\n",
       " 'Fingal was cut down to her main deck and large wooden sponsons were built out from the sides of her hull to support her casemate ',\n",
       " 'After the conversion , Atlanta was 204 feet ( 62 @.@ 2 m ) long overall and had a beam of 41 feet ( 12 m ) ',\n",
       " 'Her depth of hold was now 17 feet ( 5 @.@ 2 m ) and she now had a draft of 15 feet 9 inches ( 4 @.@ 8 m ) ',\n",
       " 'Atlanta now displaced 1 @,@ 006 long tons ( 1 @,@ 022 t ) and her speed was estimated at 7 – 10 knots ( 13 – 19 km / h ; 8 @.@ 1 – 11 @.@ 5 mph ) ',\n",
       " '\\n The armor of the casemate was angled at 30 ° from the horizontal and made from two layers of railroad rails , rolled into plates 2 inches ( 51 mm ) thick and 7 inches ( 180 mm ) wide ',\n",
       " 'The outer layer ran vertically and the inner layer horizontally ',\n",
       " 'Her armor was backed by 3 inches ( 76 mm ) of oak , vertically oriented , and two layers of 7 @.@ 5 inches ( 191 mm ) of pine , alternating in direction ',\n",
       " 'The bottom of the casemate was some 20 inches ( 508 mm ) from the waterline and its top was 8 feet 6 inches ( 2 @.@ 59 m ) above the waterline ',\n",
       " 'The pyramidal pilothouse was armored in the same way and had room for two men ',\n",
       " \"The upper portion of Atlanta 's hull received two inches of armor \",\n",
       " '\\n The rectangular casemate was pierced with eight narrow gun ports , one each at the bow and stern and three along each side ',\n",
       " 'Each gun port was protected by an armored shutter made of two layers of iron riveted together and allowed the guns to elevate only to a maximum of + 5 to + 7 ° ',\n",
       " 'Atlanta was armed with single @-@ banded , 7 @-@ inch ( 178 mm ) Brooke rifles on pivot mounts at the bow and stern ',\n",
       " 'The middle gun port on each side was occupied by a single @-@ banded , 6 @.@ 4 @-@ inch ( 163 mm ) Brooke rifle ',\n",
       " 'The 17 @-@ caliber , seven @-@ inch guns weighed about 15 @,@ 000 pounds ( 6 @,@ 800 kg ) and fired 80 @-@ pound ( 36 kg ) armor @-@ piercing \" bolts \" and 110 @-@ pound ( 50 kg ) explosive shells ',\n",
       " 'The equivalent statistics for the 18 @.@ 5 @-@ caliber , 6 @.@ 4 @-@ inch gun were 9 @,@ 110 pounds ( 4 @,@ 130 kg ) with 80 @-@ pound bolts and 64 @-@ pound ( 29 kg ) shells ',\n",
       " 'Atlanta was also armed with a 20 @-@ foot ( 6 @.@ 1 m ) , solid iron , ram that was reinforced by a series of vertical steel bars ',\n",
       " 'In front of the ram was a spar torpedo that carried 50 pounds ( 23 kg ) of black powder on a wooden pole connected to an iron lever that could be raised or lowered by means of pulleys ',\n",
       " '\\n On 31 July 1862 , under the command of Lieutenant Charles H',\n",
       " 'McBlair , Atlanta conducted her sea trials down the Savannah River toward Fort Pulaski ',\n",
       " 'The ship proved to be difficult to steer , and the additional weight of her armor and guns significantly reduced her speed and increased her draft ',\n",
       " 'This latter was a real problem in the shallow waters near Savannah ',\n",
       " 'She also leaked significantly , and her design virtually eliminated air circulation ',\n",
       " 'One report said that \" it was almost intolerable on board the Atlanta , there being no method of ventilation , and the heat was intense ',\n",
       " '\" Scales commented in his diary , \" What a comfortless , infernal and God @-@ forsaken ship ! ! \" \\n Attempts were made to fix the problems and were at least partially successful in stopping many of the leaks ',\n",
       " 'The ship was commissioned on 22 November and became the flagship of Flag Officer Josiah Tattnall , commander of the naval defenses of Georgia ',\n",
       " 'Under pressure from Mallory to engage the blockading ships , Tattnall attempted to engage them before any ironclads arrived on 5 January 1863 , but army engineers could not clear the obstacles blocking the channel in a timely manner , despite early coordination being made by Tattnall to do so ',\n",
       " 'It took another month to actually clear the obstacles and two monitors arrived before the end of January ',\n",
       " 'Nonetheless Tattnall attempted to pass through the obstructions during high tide on 3 February , but high winds prevented the water from rising enough to allow the ship to do so ',\n",
       " 'After Atlanta successfully passed through them on 19 March , Tattnall planned to attack the Union base at Port Royal , South Carolina while the monitors were attacking Charleston ',\n",
       " \"Deserters revealed Tatnall 's plan while he was waiting at the head of <unk> Sound and he was forced to retreat when three monitors augmented the defenses at Port Royal \",\n",
       " \"Dissatisfied with Tattnall 's perceived lack of aggressiveness , Mallory replaced Tattnall as commander of the Savannah squadron later that month with Commander Richard L\",\n",
       " 'Page , in his turn was relieved in May by Commander William A',\n",
       " 'Webb ; Atlanta remained the squadron flagship throughout this time ',\n",
       " \"\\n Webb demonstrated his aggressiveness when he attempted to sortie on the first spring tide ( 30 May ) after taking command , but Atlanta 's forward engine broke down after he had passed the obstructions , and the ship ran aground \",\n",
       " 'She was not damaged although it took over a day to pull her free ',\n",
       " \"He planned to make another attempt on the next full tide , rejecting Mallory 's idea that he wait until the nearly complete ironclad Savannah was finished before his next sortie \",\n",
       " 'In the meantime , Rear Admiral Samuel F',\n",
       " 'Du Pont , commander of the South Atlantic Blockading Squadron , had ordered the monitors Weehawken and Nahant into <unk> Sound ',\n",
       " 'Commander John Rodgers in Weehawken had overall command of the two ships ',\n",
       " '\\n In the early evening of 15 June , Webb began his next attempt by passing over the lower obstructions in the Wilmington River and spent the rest of the night coaling ',\n",
       " 'He moved forward the next evening to a concealed position within easy reach of the monitors for an attack early the following morning ',\n",
       " 'Webb planned to sink one of the monitors with his spar torpedo and then deal with the other one with his guns ',\n",
       " 'The gunboat <unk> and the tugboat Resolute were to accompany him to tow one or both of the monitors back to Savannah ',\n",
       " '\\n A lookout aboard Weehawken spotted Atlanta at 04 : 10 on the morning of 17 June ',\n",
       " 'When the latter ship closed to within about 1 @.@ 5 miles ( 2 @.@ 4 km ) of the two Union ships , she fired one round from her bow gun that passed over Weehawken and landed near Nahant ',\n",
       " 'Shortly afterward , Atlanta ran aground on a sandbar ; she was briefly able to free herself , but the pressure of the tide pushed her back onto the sandbar ',\n",
       " 'This time Webb was unable to get off and the monitors closed the range ',\n",
       " 'When Weehawken , the leading ship , closed to within 200 – 300 yards ( 180 – 270 m ) she opened fire with both of her guns ',\n",
       " 'The 11 @-@ inch ( 279 mm ) shell missed , but the 15 @-@ inch ( 381 mm ) shell struck the ironclad above the port middle gun port , penetrated her armor and broke the wooden backing behind it , spraying splinters and fragments that disabled the entire gun crew and half the crew of the bow gun , even though it failed to cleanly penetrate through the backing ',\n",
       " 'The next shot from the 11 @-@ inch Dahlgren gun struck the upper hull and started a small leak even though it failed to penetrate the two @-@ inch armor there ',\n",
       " \"The next shell from the 15 @-@ inch Dahlgren glanced off the middle starboard gun shutter as it was being opened , wounding half the gun 's crew with fragments \",\n",
       " 'The final shell was also from the 15 @-@ inch Dahlgren and it struck the top of the pilothouse , breaking the armor there and wounding both pilots in it ',\n",
       " 'By this time , Atlanta had been able to fire only seven shots , none of which hit either Union ship , and was hard aground with high tide not due for another hour and a half ',\n",
       " \"Weehawken and Nahant were able to freely maneuver into positions from which the Atlanta 's narrow gun ports would not allow her to reply and the damage already inflicted by the former ship made further resistance futile \",\n",
       " 'Webb surrendered his ship within 15 minutes of opening fire , before Nahant even had a chance to fire ',\n",
       " \"Of the ironclad 's 21 officers and 124 enlisted men , one man was killed and another sixteen were wounded badly enough to require hospitalization \",\n",
       " '\\n \\n = = In the Union Navy = = \\n \\n Atlanta was easily pulled free by the Union ships and she reached Port Royal under her own power ',\n",
       " 'Not badly damaged , she was repaired and bought by the Union Navy ',\n",
       " 'The prize money of $ 350 @,@ 000 was shared between the crews of Weehawken , Nahant and the gunboat Cimarron , the only ships within signaling distance ',\n",
       " 'The ship retained her name and was commissioned again on 2 February 1864 , rearmed with a pair of 8 @-@ inch ( 203 mm ) , 150 @-@ pound Parrott rifles in the bow and stern and 6 @.@ 4 @-@ inch , 100 @-@ pound Parrott rifles amidships ',\n",
       " 'The 150 @-@ pound Parrott rifle weighed 16 @,@ 500 pounds ( 7 @,@ 500 kg ) and was 17 calibers long ',\n",
       " 'The 100 @-@ pounder weighed 9 @,@ 800 pounds ( 4 @,@ 400 kg ) and was 20 calibers long ',\n",
       " 'It fired a 100 @-@ pound ( 45 kg ) shell a distance of 6 @,@ 900 yards ( 6 @,@ 300 m ) at an elevation of + 25 ° ',\n",
       " 'All four of her Brooke rifles are currently located in Willard Park in the Washington Navy Yard ',\n",
       " 'Atlanta was assigned to the North Atlantic Blockading Squadron and spent most of her time stationed up the James River where she could support operations against Richmond and defend against a sortie by the ironclads of the James River Squadron ',\n",
       " \"On 21 May 1864 , she and the gunboat Dawn fired on and dispersed Confederate cavalry that was attacking Fort Powhatan and she was deployed further upriver in February 1865 after the Battle of Trent 's Reach to better blockade the Confederate ironclads at Richmond \",\n",
       " '\\n After the end of the war in April , Atlanta was decommissioned in Philadelphia on 21 June 1865 and placed in reserve at League Island ',\n",
       " 'She was sold to Sam Ward on 4 May 1869 for the price of $ 25 @,@ 000 and subsequently delivered to representatives of Haiti on 8 December by Sydney <unk> , a lawyer who had received an advance of $ 50 @,@ 000 on her purchase price of $ 260 @,@ 000 ',\n",
       " 'The ship was briefly seized by the Customs Service , possibly for violations of neutrality laws as she had just loaded four large guns and a number of recruits for the forces of Sylvain <unk> , President of Haiti , who was embroiled in a civil war ',\n",
       " 'Atlanta was released and sailed for Port @-@ au @-@ Prince three days later ',\n",
       " 'She broke down in Delaware Bay and had to put in at Chester , Pennsylvania for repairs ',\n",
       " 'The ship , now renamed either Triumph or <unk> , departed on 18 December 1869 and vanished en route , apparently sinking with the loss of all hands , either off Cape Hatteras or the Delaware Capes ',\n",
       " 'Jacqueline Fernandez ( born 11 August 1985 ) is a Sri Lankan actress , former model , and the winner of the 2006 Miss Universe Sri Lanka pageant ',\n",
       " 'As Miss Universe Sri Lanka she represented her country at the 2006 world Miss Universe pageant ',\n",
       " 'She graduated with a degree in mass communication from the University of Sydney , and worked as a television reporter in Sri Lanka ',\n",
       " \"\\n While on a modelling assignment in India in 2009 , Fernandez successfully auditioned for Sujoy Ghosh 's fantasy drama Aladin , which marked her acting debut \",\n",
       " \"Fernandez ' breakthrough role was in Mohit Suri 's psychological thriller Murder 2 ( 2011 ) , her first commercial success \",\n",
       " 'This was followed by glamorous roles in the ensemble @-@ comedy Housefull 2 ( 2012 ) and its sequel Housefull 3 , and the action thriller Race 2 ( 2013 ) , all of which were box @-@ office successes ',\n",
       " 'Her performance in the first of these garnered her an IIFA Award for Best Supporting Actress nomination ',\n",
       " \"In 2014 , Fernandez played the leading lady in Sajid Nadiadwala 's Kick , which is one of the highest @-@ grossing Bollywood films of all time \",\n",
       " '\\n One of the most popular actresses in India , she was the recipient of the IIFA Award for Star Debut of the Year – Female in 2010 ',\n",
       " 'Alongside her screen acting career , Fernandez has participated in stage shows , and is active in humanitarian work ',\n",
       " '\\n \\n = = Early life and modeling career = = \\n \\n Fernandez was born on 11 August 1985 , in Manama , Bahrain , and was raised in a multi @-@ ethnic family ',\n",
       " 'Her father , Elroy , is Sri Lankan , and her mother , Kim , is of Malaysian descent ',\n",
       " \"Her grandfather , on her mother 's side of the family , is Canadian and her great grandparents were from Goa , India \",\n",
       " 'Her father , who was a musician in Sri Lanka , moved to Bahrain in the 1980s to escape civil unrest between the Tamils and Sinhalese and subsequently met her mother who was an air hostess ',\n",
       " 'She is the youngest of four children with one elder sister and two elder brothers ',\n",
       " 'She hosted television shows in Bahrain at the age of fourteen ',\n",
       " 'After receiving her early education in Bahrain , she pursued a degree in mass communication from the University of Sydney in Australia ',\n",
       " 'After graduating she worked as a television reporter in Sri Lanka ',\n",
       " 'She also attended the Berlitz school of languages , where she learnt Spanish and improved her French and Arabic ',\n",
       " '\\n According to Fernandez , she had aspired to become an actress at a young age and fantasized about becoming a Hollywood movie star ',\n",
       " 'She received some training at the John School of Acting ',\n",
       " 'Although , she was a television reporter , she accepted offers in the modeling industry , which came as a result of her pageant success ',\n",
       " 'In 2006 , she was crowned the winner of the Miss Universe Sri Lanka pageant and represented Sri Lanka at the world Miss Universe 2006 pageant held in Los Angeles ',\n",
       " 'In a 2015 interview , Fernandez described the modeling industry as \" a good training ground \" and said : \" It is a medium that is about shedding your inhibitions , knowing your body , confidence \" ',\n",
       " 'In 2006 , she appeared in a music video for the song \" O Sathi \" by music duo <unk> and <unk> ',\n",
       " '\\n \\n = = Acting career = = \\n \\n \\n = = = 2009 – 2013 = = = \\n \\n In 2009 , Fernandez traveled to India for a modeling assignment ',\n",
       " \"She studied acting under the mentorship of theatre director Barry John , and successfully auditioned for Sujoy Ghosh 's fantasy film Aladin ( 2009 ) her acting debut \",\n",
       " \"She played the love interest of <unk> Deshmukh 's character , a role based on the Princess Jasmine character \",\n",
       " 'Fernandez garnered mixed reviews for her performance ',\n",
       " 'Anupama Chopra of NDTV called her a \" plastic debutant [ e ] \" , and Rajeev Masand of CNN @-@ IBN felt that she was : \" easy on the eyes and appears confident but has precious little to do \" ',\n",
       " 'Although the film was a critical and commercial failure , she won the IIFA Award for Star Debut of the Year - Female ',\n",
       " '\\n In 2010 , Fernandez appeared opposite Deshmukh in the science fiction romantic comedy Jaane Kahan Se Aayi Hai ',\n",
       " 'She was cast as a girl from Venus , who lands on Earth in search of love ',\n",
       " 'The film , along with Fernandez \\'s performance , received poor reviews ; Rediff.com \\'s Sukanya Verma noted : \" She gamely makes a fool of herself whilst aping the actions of movie stars , ranging from Sridevi \\'s <unk> dance , Mithun Chakravarthy \\'s Disco Dancer moves , to Big B \\'s violent <unk> in Hum ',\n",
       " \"Her Tara could be a keeper if only Jaane Kahan Se Aayi Hai wasn 't so intent on turning her into a love @-@ struck Barbie \",\n",
       " '\" Critic Anupama Chopra also criticized Fernandez , calling her \" a pin @-@ prick on a balloon \" ',\n",
       " 'Later that year , she made a cameo appearance in Sajid Khan \\'s Housefull in the song \" <unk> \" ',\n",
       " \"\\n Mahesh Bhatt 's thriller Murder 2 was Fernandez 's first commercial success and marker a turning point in her career \",\n",
       " 'She took on the role of Priya , a lonely model who is in a confused relationship with Arjun Bhagwat ( played by Emraan Hashmi ) ',\n",
       " 'Fernandez was praised for the her performance , and for the boldness and sex appeal she displayed in the film ',\n",
       " 'Gaurav Malini of The Times of India stated that she was \" tastefully tempting \" but noted that her romance with Hashmi was \" literally half @-@ baked \" ',\n",
       " 'The following year , Fernandez appeared in the ensemble comedy Housefull 2 alongside Akshay Kumar , John Abraham , and Asin ',\n",
       " 'It became one of the top grossing productions of India that year and earned ₹ 1 @.@ 86 billion ( US $ 28 million ) worldwide ',\n",
       " 'Fernandez received mostly negative reviews for her performance ',\n",
       " 'While Gaurav Malini praised her for her looks , NDTV called her a \" <unk> bimbo \" who \" find [ s ] no pleasure in [ her role ] \" ',\n",
       " 'Despite the negative reviews , Fernandez received a Best Supporting Actress nomination at the 14th IIFA Awards for her performance ',\n",
       " '\\n Fernandez \\'s first release of 2013 was Race 2 , an ensemble action thriller ( alongside Saif Ali Khan , John Abraham , Deepika Padukone , Ameesha Patel , and Anil Kapoor ) ) , described as the \" cinematic equivalent of a trashy novel \" by critic Rajeev Masand ',\n",
       " 'She played <unk> , a femme fatale , a role which required her learn fencing and some acrobatics ',\n",
       " 'The film emerged as a commercial success , with the domestic gross of more than ₹ 1 billion ( US $ 15 million ) ',\n",
       " 'In a particularly scathing review , Saibal Chatterjee of NDTV wrote that both Fernandez and Padukone \" strut around like wound @-@ up automatons that are all decked @-@ up but have nowhere to go ',\n",
       " '\" Fernandez also appeared in an item number ( music video ) titled \" Jaadu Ki <unk> \" for Prabhu Deva \\'s <unk> <unk> <unk> ',\n",
       " \"\\n \\n = = = 2014 – present = = = \\n \\n In 2014 , Fernandez appeared in Sajid Nadiadwala 's directorial debut — the action film Kick , a remake of a 2009 Telugu film of same name \",\n",
       " 'She starred opposite Salman Khan , playing Shaina , a psychiatry student ',\n",
       " 'She retained her real voice for the first time in Kick ',\n",
       " 'While Sneha May Francis commented that she is : \" incredibly dazzling , and moves like a magic \" , Raja Sen of Rediff.com was more critical of her dialogue delivery , calling it \" unfortunate ',\n",
       " '\" The film received mixed reviews from critics , but with worldwide revenue of over ₹ 3 @.@ 75 billion ( US $ 56 million ) , it became the fourth highest @-@ grossing Bollywood film ',\n",
       " 'The film established Fernandez as one of the most popular Bollywood actresses ',\n",
       " \"\\n In 2015 , Fernandez featured in Vicky Singh 's Roy , a romantic thriller , which critic Sarita A\",\n",
       " 'Tanwar described as a \" boring , exhausting and pretentious \" film ',\n",
       " 'Fernandez played dual roles , Ayesha Aamir , a filmmaker in a relationship with another filmmaker ( played by Arjun Rampal ) and Tia Desai , a girl in love with a thief ( played by Ranbir Kapoor ) ',\n",
       " 'While India TV called it \" her best act till date \" , critic Rajeev Masand felt that she \" appears miscast in a part that required greater range ',\n",
       " '\" Roy failed to meet its box @-@ office expectations , and was a commercial failure ',\n",
       " 'Later that year , she appeared in a guest appearance for the comedy @-@ satire <unk> ',\n",
       " \"\\n Karan Malhotra 's action drama Brothers was Fernandez 's next release \",\n",
       " 'Co @-@ starring alongside Akshay Kumar and Sidharth Malhotra , Fernandez played Jenny , a fearless mother struggling for her child , a role which she described as \" challenging \" , \" intense \" , and \" difficult \" ',\n",
       " 'The role marked a departure from the glamorous characters that she had a reputation for portraying ',\n",
       " 'Film critics praised her performance , though their response to the film was mixed ',\n",
       " '<unk> Sharma of Zee News called her character \" soft , timid and promising \" , and praised her for : \" convincingly pull [ ing ] off a pleasing character of a street fighter \\'s wife \" ',\n",
       " 'Film critic Subhash K',\n",
       " 'Jha noted that she : \" ..',\n",
       " 'in a limited role gives her finest emotive shot \" , while critic Raja Sen remarked : \" [ she ] plays Kumar \\'s long @-@ sobbing wife who gets so deliriously happy on seeing a text message that it may well have contained news about a Kick sequel ',\n",
       " '\" \\n As of September 2015 , Fernandez has several projects in various stages of production ',\n",
       " \"She has completed shooting for Chandran <unk> 's English @-@ Sri Lankan crime @-@ thriller According to Mathew , and the horror thriller Definition of Fear , which marks her Hollywood debut \",\n",
       " \"Fernandez has also signed on to appear in three other projects — Rohit Dhawan 's <unk> opposite Varun Dhawan and John Abraham as a part of three @-@ film deal with Nadiadwala Grandson Entertainment , Remo D 'Souza 's Flying Jat opposite Tiger Shroff , and in an Indo @-@ Chinese film starring opposite Abhay Deol , Amitabh Bachchan , and Jackie Chan titled Gold Struck \",\n",
       " '\\n \\n = = Personal life and other work = = \\n \\n Fernandez shares a close bond with her family , and admits to missing being around them ',\n",
       " 'She says : \" I miss them so much everyday ',\n",
       " \"You don 't realise when you live away from home how difficult life can be [ ..\",\n",
       " '] At the same time , staying away from them has taught me to be more responsible ',\n",
       " 'It has taught me so many things about myself , about priorities and time management ',\n",
       " '\" In March 2012 , Fernandez turned vegetarian for a 40 @-@ day period to observe Lent , a period from Ash Wednesday to Holy Saturday ',\n",
       " \"\\n In 2008 , Fernandez started dating Bahraini prince Hassan bin Rashid Al Khalifa , whom she met at a mutual friend 's party ; they separated in 2011 \",\n",
       " 'While filming Housefull 2 in 2011 , Fernandez began a romantic relationship with director Sajid Khan ',\n",
       " 'The relationship attracted media coverage in India and there was speculation of an impending wedding ',\n",
       " 'However , the relationship ended in May 2013 ',\n",
       " '\\n In addition to acting in films , Fernandez has supported charitable organisations and a number of causes ',\n",
       " 'In 2011 , on the behalf of People for the Ethical Treatment of Animals ( PETA ) , she sent a letter to the Mumbai Municipal Commissioner asking for an end to horse @-@ drawn carriage rides in Mumbai ',\n",
       " 'In early 2013 , she asked the consulate general of the Philippines , William John T Perera in Colombo , to hasten the transfer of an elephant from its inadequate housing at the Manila Zoo to a humane sanctuary ',\n",
       " \"Later that year , she auctioned a breakfast in Mayfair , London , where she raised around £ 4000 for the Pratham NGO , which helps children 's primary education \",\n",
       " 'In 2014 , Fernandez was named \" Woman Of The Year \" by PETA ( India ) for advocating the protection of animals ',\n",
       " 'The following year , she auctioned her outfits on an online portal for a philanthropic cause ',\n",
       " 'Some of her outfits included the ones she wore in the song \" Party On My Mind \" ( from Race 2 ) and \" Hangover \" ( from Kick ) ',\n",
       " 'In March 2016 , she was part of \" Jacqueline Builds \" campaign that raised funds for the victims of the 2015 South Indian floods ',\n",
       " '\\n Fernandez has participated in several concert tours and televised award ceremonies ',\n",
       " 'In 2013 , she performed at the Temptations Reloaded in Auckland , Perth , and Sydney alongside Shah Rukh Khan , Rani Mukerji , and Madhuri Dixit ',\n",
       " 'She also performed at the live talent show \" Got Talent World Stage Live \" with Khan , Priyanka Chopra and Varun Dhawan the following year ',\n",
       " 'In July 2014 , Fernandez opened a restaurant in Colombo , <unk> Sutra , in collaboration with chef <unk> <unk> , which specialises in contemporary Sri Lankan cuisine ',\n",
       " '\\n \\n = = In the media = = \\n \\n In the early 2013 , Fernandez became the ambassador for HTC One , which she endorses in India ',\n",
       " 'She was the face of Indian Bridal Fashion Week — <unk> of 2013 ',\n",
       " \"Later that year , she became the spokesperson for Gareth Pugh 's designed <unk> Diamonds in Mumbai , and was at the inaugural opening of the Forever 21 store in Mumbai \",\n",
       " 'That year , she also launched Gillette Shaving System with Arbaaz Khan and Aditya Roy Kapur ',\n",
       " 'While analysing Fernandez \\'s career , India TV noted : \" Slowly and steadily Jacqueline Fernandez is climbing up the ladder of success [ ..',\n",
       " '] Jacqueline is comfortably grasping every aspect of the work , which an actress is required to do and is accordingly giving results ',\n",
       " '\" On the contrary , Charu Thakur of India Today criticized her acting skills , but remarked that : \" [ she has ] managed to find her feet in Bollywood now by banking on glamorous roles \" ',\n",
       " '\\n In 2008 and 2011 , Fernandez featured in the UK magazine Eastern Eye \\'s \" World \\'s Sexiest Asian Women \" list , ranking twelfth ',\n",
       " 'She was ranked third on The Times of India \\'s listing of the \" Most Desirable Woman \" in 2013 and 2014 , after being ranked eighth , seventh and fourteenth , respectively , in the preceding three years ',\n",
       " 'In 2013 , Rediff.com placed her on their list of \" Bollywood \\'s Best Dressed Actresses \" ',\n",
       " \"The following year , she held the sixty second position in the Indian edition of the Forbes ' Celebrity 100 , a list based on the income and popularity of India 's celebrities \",\n",
       " \"She has been the cover model for many Indian editions of magazines , including : Vogue , FHM , Maxim , Cosmopolitan , Grazia , Elle , Verve , Harper 's Bazaar , Women 's Health , and L 'Officiel among others \",\n",
       " '\\n \\n = = Filmography = = \\n \\n \\n = = TV Appearances = = \\n \\n \\n = = Awards = = \\n \\n',\n",
       " 'Barry John Cullen ( born August 2 , 1964 ) is a Canadian former professional ice hockey centre who played in the National Hockey League ( NHL ) for the Pittsburgh Penguins , Hartford Whalers , Toronto Maple Leafs and Tampa Bay Lightning ',\n",
       " \"He was a standout player for Boston University and is the school 's all @-@ time leading scorer \",\n",
       " \"After the Buffalo Sabres selected him in the 1986 NHL Supplemental Draft but chose not to offer him a contract , Cullen signed with the Flint Spirits of the International Hockey League ( IHL ) for the 1987 – 88 season where he was named the IHL 's co @-@ Rookie of the Year and Most Valuable Player after leading the league in scoring \",\n",
       " '\\n His career was halted in 1997 when he was diagnosed with Non @-@ Hodgkin lymphoma ',\n",
       " 'He attempted a brief comeback in 1998 after an 18 @-@ month battle with the disease , for which the NHL awarded him the Bill Masterton Memorial Trophy , before retiring to serve as an assistant coach for a year with the Lightning ',\n",
       " 'Cullen played in two NHL All @-@ Star Games in his career ',\n",
       " 'He joined his brother in the car dealership business after leaving the game , and briefly operated his own dealership until forced to close during the automotive industry crisis of 2008 – 10 ',\n",
       " '\\n \\n = = Early life = = \\n \\n Cullen was born in <unk> @-@ Ontario on August 2 , 1964 ',\n",
       " 'He is one of six children of Barry and Loretta Cullen ',\n",
       " 'His father and uncles Brian and Ray all played in the NHL , and while Cullen and his three brothers all played as well , their father never pressured them , preferring that they enjoy the game ',\n",
       " \"\\n He idolized his elder brother Terry , who was considered a top NHL prospect until Terry 's career was ended when he suffered a broken neck after being hit from behind into the boards during a college game \",\n",
       " 'While his brother was highly sought by American universities , John received only two scholarship offers , choosing to play for Boston University ( BU ) in 1983 ',\n",
       " '\\n At the same time , his mother Loretta was diagnosed with skin cancer ',\n",
       " 'Following her death early in his freshman year , Cullen contemplated returning to his Ontario home , but was convinced by his father to continue with both school and hockey ',\n",
       " \"He used the game to cope with the loss and dedicated every game he played to his mother 's memory \",\n",
       " \"Cullen felt that the inspiration he drew from his mother 's battle allowed him to become a better player \",\n",
       " '\\n \\n = = Playing career = = \\n \\n Cullen was a standout with BU ; he was named the East Coast Athletic Conference Rookie of the Year in 1983 – 84 after leading his team in scoring with 56 points ',\n",
       " 'The National Hockey League passed him over , however , as he went unclaimed in the 1984 NHL Entry Draft ',\n",
       " 'He was named to the Hockey East All @-@ Star Teams in 1985 , 1986 and 1987 , and a National Collegiate Athletic Association East Second Team All @-@ American in 1986 ',\n",
       " \"He graduated as BU 's all @-@ time scoring leader with 241 points , and was named to BU 's Hockey East 25th anniversary team in 2009 \",\n",
       " '\\n Passed over in the Entry Draft , Cullen was finally selected by the Buffalo Sabres in the 1986 NHL Supplemental Draft ',\n",
       " 'When the Sabres failed to offer him a contract , Cullen signed with the Flint Spirits of the International Hockey League ( IHL ) for the 1987 – 88 season ',\n",
       " 'He led the league with 157 points , scoring 48 goals , and won the James <unk> Memorial Trophy as league most valuable player while sharing the Gary F',\n",
       " 'Longman Memorial Trophy with Ed Belfour as rookie of the year ',\n",
       " \"Cullen 's outstanding season in Flint caught the attention of the Sabres and the Pittsburgh Penguins \",\n",
       " 'He signed a contract with the Penguins for the league minimum , passing up a superior contract offer from Buffalo as he remained upset at how they released him the year before ',\n",
       " '\\n \\n = = = National Hockey League = = = \\n \\n Cullen made his NHL debut in 1988 – 89 , appearing in 79 games with the Penguins and scoring 49 points ',\n",
       " 'He was given a greater role with the Penguins the following year after Mario Lemieux missed 21 games due to a back injury and responded by scoring 32 goals and 92 points to finish third in team scoring ',\n",
       " 'Additionally , he played for Team Canada at the 1990 World Championship , scoring four points in ten games ',\n",
       " 'Cullen had his best season in 1990 – 91 ',\n",
       " \"As one of the team 's top offensive centres , he scored 94 points in the Penguins ' first 65 games and played in his first NHL All @-@ Star Game \",\n",
       " \"However , when Lemieux returned after missing an additional 50 @-@ games due to injury , Cullen 's playing time and production declined \",\n",
       " \"\\n The Penguins ' needs led them to complete a blockbuster trade on March 1 , 1991 \",\n",
       " \"Cullen was sent to the Hartford Whalers , along with Zarley Zalapski and Jeff Parker in exchange for Hartford 's all @-@ time leading scorer , Ron Francis , along with Ulf Samuelsson and Grant Jennings \",\n",
       " \"The Penguins almost turned down the deal as they were concerned about giving up Cullen 's playmaking and leadership abilities , while his former teammates credited Cullen as being the primary reason they were in a playoff position at the time the trade happened \",\n",
       " 'After the Penguins won their first Stanley Cup that season , Phil Bourque later said it \" broke his heart \" that Cullen was not able to share in that championship ',\n",
       " \"\\n In Hartford , Cullen worked to overcome the team 's fans ' disappointment at losing Francis \",\n",
       " 'The Hartford fans initially booed him to show their dissatisfaction with the trade ',\n",
       " \"He scored 16 points in 13 regular season games to finish the season with 110 points combined between the Penguins and Whalers , and was the team 's best player in their first round loss to the Boston Bruins in the 1991 Stanley Cup Playoffs \",\n",
       " 'He initially accepted an invitation to join the Canadian team at the 1991 Canada Cup , but subsequently chose not to participate as his contract had expired , leading to greater insurance concerns ',\n",
       " 'Still without a contract when the 1991 – 92 season began , Cullen missed the first four games before signing a four @-@ year deal with Hartford worth a total of $ 4 million ',\n",
       " 'He returned to score 77 points in 77 games in his first full season with the Whalers and represented the team at the 1992 All @-@ Star Game ',\n",
       " \"\\n Midway through the 1992 – 93 NHL season , the Whalers sent Cullen to the Toronto Maple Leafs for Toronto 's second round selection at the 1993 NHL Entry Draft \",\n",
       " \"Cullen was excited to play for his father 's old team , but injuries reduced his ability to perform \",\n",
       " 'His most significant injury was a herniated disc in his neck that doctors initially feared would end his career ',\n",
       " 'A bulky neck brace allowed Cullen to return and play out his contract in Toronto ',\n",
       " 'When the Leafs chose not to re @-@ sign him following the 1993 – 94 season , he returned to the Penguins for one season before Tony Esposito convinced him to sign with the Tampa Bay Lightning in 1995 ',\n",
       " '\\n Cullen enjoyed immediate success with linemates Shawn Burr and Alexander <unk> as the trio combined to score 130 points and helped lead the Lightning to the first playoff appearance in franchise history ',\n",
       " 'They were eliminated by the Philadelphia Flyers in five games while Cullen led the team in playoff scoring with three goals and three assists ',\n",
       " 'The Lightning looked to improve in 1996 – 97 ; Cullen was leading the team in scoring , but was suffering flu @-@ like symptoms that he could not shake ',\n",
       " 'As Tampa was fighting for a playoff spot , he played through his condition for weeks ',\n",
       " \"\\n \\n = = = Cancer and comeback = = = \\n \\n After two months of quietly dealing with his symptoms , Cullen 's wife finally called team trainers and asked them to check into his illness \",\n",
       " 'The team took an x @-@ ray and found a large black shadow in his chest ',\n",
       " 'He underwent a CAT scan which revealed Cullen had a baseball @-@ sized tumor ; he was diagnosed as having Non @-@ Hodgkin lymphoma ',\n",
       " 'The diagnosis ended his season , and he immediately began chemotherapy treatments that quickly reduced his cancer ',\n",
       " 'The tumor was gone by September 1997 , but a precautionary test prior to training camp revealed that Cullen still had cancer cells in his body ',\n",
       " 'He missed the entire 1997 – 98 NHL season as he continued to battle the disease , while his teammates wore a uniform patch with his # 12 in support throughout the year ',\n",
       " '\\n On one day during his treatments , as his wife was wheeling him down a hospital corridor , Cullen went into cardiac arrest , requiring doctors to use a defibrillator to revive him ',\n",
       " 'He underwent a bone marrow transplant that briefly reduced his immune system to the point that he could have very little human contact ',\n",
       " 'Another examination in April 1998 revealed that the cancer was finally gone , and Cullen immediately began training for a comeback ',\n",
       " '\\n The Lightning signed Cullen to a one @-@ year , $ 500 @,@ 000 contract for the 1998 – 99 season ',\n",
       " 'He played his first game in nearly 18 months on September 18 , 1998 , in an exhibition game between the Lightning and Sabres at Innsbruck , Austria ',\n",
       " 'Cullen scored the game @-@ winning goal in a 3 – 1 victory , after which he said he sat on the bench in disbelief over how he was given a second chance ',\n",
       " 'He was named to the roster and was greeted with a loud standing ovation by the fans in Tampa Bay when he was introduced prior to their season opening game ',\n",
       " \"\\n Cullen appeared in four of the Lightning 's first eight games , but it was evident that he had lost much of his speed and strength \",\n",
       " \"The Lightning assigned him to the IHL 's Cleveland Lumberjacks , but also gave him the option of retiring and taking up a position as an assistant coach \",\n",
       " 'He chose to accept the demotion , giving himself one month to determine if he could continue playing ',\n",
       " 'He appeared in six games for Cleveland , and in one game against the Chicago Wolves tied an IHL record when he scored seven points in a 7 – 3 victory ',\n",
       " '\\n However , a bout of bronchitis led Cullen to fear that his cancer had returned ',\n",
       " 'Tests came back negative , but after spending time with his family , he realized that neither he nor his family were interested in returning to Cleveland ',\n",
       " 'Cullen announced his retirement on November 28 , 1998 , and accepted the Lightning offer to become an assistant coach ',\n",
       " 'In recognition of his comeback attempt , the NHL named him the 1999 winner of the Bill Masterton Memorial Trophy for dedication and perseverance , while the IHL renamed its Comeback Player of the Year award the John Cullen Award ',\n",
       " '\\n Former Lightning head coach Terry Crisp has stated publicly that Cullen was a player that stood out as something special saying “ John Cullen ..',\n",
       " 'beat cancer and came back to play and helped us win ',\n",
       " '” \\n \\n = = Off the ice = = \\n \\n Cullen and his wife Valerie have three daughters , Kennedy and twins <unk> and <unk> ',\n",
       " \"Unwilling to spend so much time away from his family , he left the Lightning in 1999 and settled in the Atlanta area , joining his brother 's car dealership in Jonesboro , Georgia \",\n",
       " 'He had always expected to become a car dealer after his hockey career , as his father , uncles and brother all worked in the industry ',\n",
       " 'After apprenticing under his brother for five years , he bought a Dodge dealership in Newnan , Georgia in 2007 ',\n",
       " 'However , he owned the dealership for less than two years before Chrysler closed him down as part of its recovery plan in response to the Automotive industry crisis of 2008 – 2010 ',\n",
       " \"He has since returned to his brother 's dealership , serving as its general manager \",\n",
       " \"\\n Cullen 's battle with cancer inspired Timm Harmon of the Moffitt Cancer Centre to partner with the Lightning to raise awareness and money for cancer research \",\n",
       " 'The NHL itself joined the cause in the winter of 1998 , creating the Hockey Fights Cancer program to raise money for research ',\n",
       " 'Cullen has spent time promoting the initiative ',\n",
       " '\\n Prior to marrying his wife Valerie , John dated Carolyn Bessette the future wife of John F',\n",
       " 'Kennedy , Jr ',\n",
       " 'The two met while attending University in Boston ',\n",
       " '\\n \\n = = Career statistics = = \\n \\n \\n = = = Regular season and playoffs = = = \\n \\n \\n = = = International = = = \\n \\n \\n = = Awards = = \\n \\n Cullen is the namesake of the John Cullen Award , previously given to key IHL players ',\n",
       " 'For the ironclad present at the Battle of Lissa of the same name , see SMS Erzherzog Ferdinand Max ( 1865 ) ',\n",
       " '\\n SMS Erzherzog Ferdinand Max ( German : \" His Majesty \\'s ship Archduke Ferdinand Max \" ) was a pre @-@ dreadnought battleship built by the Austro @-@ Hungarian Navy in 1902 ',\n",
       " 'The second ship of the Erzherzog Karl class , she was launched on 3 October 1903 ',\n",
       " 'She was assigned to the III Battleship Division ',\n",
       " '\\n For most of World War I , Erzherzog Ferdinand Max remained in her home port of Pola , in present @-@ day Croatia , except for four engagements ',\n",
       " 'In 1914 , she formed part of the Austro @-@ Hungarian flotilla sent to protect the escape of the German ships SMS Goeben and SMS Breslau from the British @-@ held Mediterranean ; she advanced as far as Brindisi before being recalled to her home port ',\n",
       " 'Her sole combat engagement occurred in late May 1915 , when she participated in the bombardment of the Italian port city of Ancona ',\n",
       " 'She also took part in suppressing a major mutiny among the crew members of several armored cruisers stationed in Cattaro between 1 – 3 February 1918 ',\n",
       " 'She also attempted to break through the Otranto Barrage in June of that year , but had to retreat when the dreadnought SMS Szent István was sunk ',\n",
       " 'After the war , Erzherzog Ferdinand Max was awarded to the United Kingdom as a war prize in 1920 ',\n",
       " '\\n \\n = = Design = = \\n \\n Erzherzog Ferdinand Max displaced 10 @,@ 472 long tons ( 10 @,@ 640 t ) ',\n",
       " 'She was 414 feet 2 inches ( 126 @.@ 2 m ) long , had a beam of 71 feet 5 inches ( 21 @.@ 8 m ) and a draft of 24 feet 7 inches ( 7 @.@ 5 m ) ',\n",
       " 'She was manned by 700 men ',\n",
       " 'She and her sisters were the last and largest pre @-@ dreadnought class built by the Austro @-@ Hungarian Navy , surpassing the Habsburg class by approximately 2 @,@ 000 tonnes ( 1 @,@ 968 long tons ) ',\n",
       " 'She was propelled by two two @-@ shaft , four cylinder vertical triple expansion steam engines ',\n",
       " 'On trials , they developed 18 @,@ 000 ihp ( 13 @,@ 423 kW ) , which propelled the ship at a speed of 20 @.@ 5 knots ( 38 @.@ 0 km / h ; 23 @.@ 6 mph ) ',\n",
       " '\\n Erzherzog Ferdinand Max carried a primary armament of four 24 @-@ centimeter ( 9 @.@ 4 in ) / 40 caliber guns in two twin turrets on the centerline ',\n",
       " 'These guns were an Austro @-@ Hungarian replica of the British 24 cm / 40 ( 9 @.@ 4 \" ) Krupp C / 94 , which was used on the Habsburgs ',\n",
       " 'Her secondary armament consisted of twelve 19 @-@ centimeter ( 7 @.@ 5 in ) / 42 caliber guns , also made by Škoda , mounted in eight single casemates on either wing of the ship and two twin turrets on the <unk> shell 20 @,@ 000 metres ( 22 @,@ 000 yd ) at maximum elevation with a muzzle velocity of 800 metres per second ( 2 @,@ 600 ft / s ) ',\n",
       " 'The gun weighed 12 @.@ 1 tons and could fire three rounds per <unk> ships had a tertiary armament for protection against torpedo boats in the form of the 6 @.@ 6 centimetres ( 2 @.@ 6 in ) / 45 caliber gun , also manufactured by Škoda ',\n",
       " 'Anti @-@ aircraft and airship protection was covered by the four 37 @-@ millimeter ( 1 @.@ 5 in ) Vickers anti @-@ aircraft guns on the ship bought from Britain in 1910 and mounted onto Erzherzog Karl ',\n",
       " 'Erzherzog Ferdinand Max was also fitted with two above water 45 @-@ centimeter ( 17 @.@ 7 in ) torpedo tubes , although rarely used ',\n",
       " '\\n \\n = = Service history = = \\n \\n At the outbreak of World War I , Erzherzog Ferdinand Max was in the III division of the Austrian @-@ Hungarian battle @-@ fleet ',\n",
       " 'She was mobilized on the eve of the war along with the remainder of the fleet to support the flight of SMS Goeben and SMS Breslau ',\n",
       " 'The two German ships were attempting to break out of Messina , which was surrounded by British troops , and make their way to Turkey ',\n",
       " 'The breakout succeeded ',\n",
       " 'When the flotilla had advanced as far south as Brindisi in south eastern Italy , the Austro @-@ Hungarian ships were recalled ',\n",
       " 'In company with other units of the Austro Hungarian navy , Erzherzog Ferdinand Max took a minor part in the bombardment of Ancona on 24 May 1915 ',\n",
       " 'There she and her sisters expended 24 rounds of 240 mm armor @-@ piercing shells at signal and semaphore stations as well as 74 rounds of 190 mm shells aimed at Italian gun @-@ batteries and other port installations ',\n",
       " '\\n A major mutiny among crews of the armored cruisers stationed in Cattaro , including Sankt Georg and Kaiser Karl VI , began on 1 February 1918 ',\n",
       " 'Two days later , Erzherzog Ferdinand Max and her sisters arrived in the port and assisted with the suppression of the mutiny ',\n",
       " 'Following the restoration of order in the naval base , the armored cruisers Sankt Georg and Kaiser Karl VI were decommissioned and Erzherzog Ferdinand Max and her sisters were stationed in Cattaro in their place ',\n",
       " 'On the morning of 11 June , Admiral Miklos Horthy planned a major assault on the Otranto Barrage ; the three Erzherzog Karls and the four Tegetthoff @-@ class battleships were to provide support for the Novara @-@ class cruisers on an assault on the Allied defenses at the Strait of Otranto ',\n",
       " 'The plan was intended to replicate the success of the raid conducted one year earlier ',\n",
       " \"Horthy 's plan was to destroy the blockading fleet by luring Allied ships to the cruisers and lighter ships , which were protected from the heavier guns of the battleships , including the guns of the Erzherzog Karl class \",\n",
       " 'However , on the morning of 10 June , the dreadnought Szent István was torpedoed and sunk by an Italian torpedo boat ',\n",
       " 'Horthy felt that the element of surprise had been compromised , and therefore called off the operation ',\n",
       " 'This was to be the last military action Erzherzog Ferdinand Max was to take part in , and she and her sisters spent the rest of their career in port ',\n",
       " '\\n Near the end of World War I , the Erzherzog Karl @-@ class battleships were handed over to the newly formed State of Slovenes , Croats and Serbs but Erzherzog Ferdinand Max was later transferred to Great Britain as a war reparation ',\n",
       " 'She was later broken up for scrap in 1921 ',\n",
       " 'Ancient Egyptian deities are the gods and goddesses worshipped in ancient Egypt ',\n",
       " 'The beliefs and rituals surrounding these gods formed the core of ancient Egyptian religion , which emerged sometime in prehistory ',\n",
       " 'Deities represented natural forces and phenomena , and the Egyptians supported and appeased them through offerings and rituals so that these forces would continue to function according to maat , or divine order ',\n",
       " \"After the founding of the Egyptian state around 3100 BC , the authority to perform these tasks was controlled by the pharaoh , who claimed to be the gods ' representative and managed the temples where the rituals were carried out \",\n",
       " \"\\n The gods ' complex characteristics were expressed in myths and in intricate relationships between deities : family ties , loose groups and hierarchies , and combinations of separate gods into one \",\n",
       " \"Deities ' diverse appearances in art — as animals , humans , objects , and combinations of different forms — also alluded , through symbolism , to their essential features \",\n",
       " '\\n In different eras , various gods were said to hold the highest position in divine society , including the solar deity Ra , the mysterious god Amun , and the mother goddess Isis ',\n",
       " 'The highest deity was usually credited with the creation of the world and often connected with the life @-@ giving power of the sun ',\n",
       " 'Some scholars have argued , based in part on Egyptian writings , that the Egyptians came to recognize a single divine power that lay behind all things and was present in all the other deities ',\n",
       " 'Yet they never abandoned their original polytheistic view of the world , except possibly during the era of Atenism in the 14th century BC , when official religion focused exclusively on the impersonal sun god Aten ',\n",
       " '\\n Gods were assumed to be present throughout the world , capable of influencing natural events and the course of human lives ',\n",
       " 'People interacted with them in temples and unofficial shrines , for personal reasons as well as for larger goals of state rites ',\n",
       " 'Egyptians prayed for divine help , used rituals to compel deities to act , and called upon them for advice ',\n",
       " \"Humans ' relations with their gods were a fundamental part of Egyptian society \",\n",
       " '\\n \\n = = Definition = = \\n \\n The beings in ancient Egyptian tradition who might be labeled as deities are difficult to count ',\n",
       " ...]"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = collate_fn_sentim\n",
    "\n",
    "train_loader = DataLoader(train_data,\n",
    "                          batch_size=32,\n",
    "                          collate_fn=collate_fn)\n",
    "\n",
    "test_loader = DataLoader(test_data,\n",
    "                         batch_size=32,\n",
    "                         collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_loader):\n",
    "    print(len(batch[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_performance(data_loader, mp_trainer, num_of_classes = 64):\n",
    "    # Evaluation\n",
    "    f1_micro = 0\n",
    "    prec_micro = 0\n",
    "    recall_micro = 0\n",
    "    accuracy = 0.\n",
    "    for batch in data_loader:\n",
    "        lambs, poss, texts, labels, lens = batch[:5]\n",
    "        logits = mp_trainer.predict(batch)\n",
    "\n",
    "        predicted_classes = torch.argmax(logits, dim=1)\n",
    "        if num_of_classes == 2:\n",
    "            average = 'binary'\n",
    "        else:\n",
    "            average = 'micro'\n",
    "        f1_micro += f1_score(labels.cpu(), predicted_classes.cpu(), average= average)\n",
    "        prec_micro += precision_score(labels.cpu(), predicted_classes.cpu(), average= average)\n",
    "        recall_micro += recall_score(labels.cpu(), predicted_classes.cpu(), average= average)\n",
    "        accuracy += accuracy_score(labels.cpu(), predicted_classes.cpu())\n",
    "\n",
    "    f1_micro /= len(data_loader)\n",
    "    prec_micro /= len(data_loader)\n",
    "    recall_micro /= len(data_loader)\n",
    "    accuracy /= len(data_loader)\n",
    "\n",
    "    return f1_micro, prec_micro, recall_micro, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_name = 'saved_models/sst_model1+/'\n",
    "cfg['trainerfilename'] = repo_name\n",
    "cfg['logfilename'] = repo_name + 'log.txt'\n",
    "\n",
    "# Task specific settings\n",
    "cfg['num_of_classes'] = 64\n",
    "cfg['language'] = 'en'\n",
    "\n",
    "# model specific settings\n",
    "cfg['normalize_lamb'] = True\n",
    "cfg['laplacian'] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n"
     ]
    }
   ],
   "source": [
    "with open(cfg['logfilename'], 'a+') as logfile:\n",
    "    logfile.write(\n",
    "        '{} training samples set into {} batches, {} test samples set into {} batches\\n'.format(len(train_data),\n",
    "                                                                                                len(train_loader),\n",
    "                                                                                                len(test_data),\n",
    "                                                                                                len(test_loader)))\n",
    "    logfile.write('Start training.\\n')\n",
    "\n",
    "all_losses = []\n",
    "performance = {'acc_test': [], 'prec_test': [], 'f1_test': [], 'recall_test': [],\n",
    "               'acc_train': [], 'prec_train': [], 'f1_train': [], 'recall_train': [],\n",
    "               'loss': []}\n",
    "print('Start training')\n",
    "best_accuracy = 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450\n"
     ]
    }
   ],
   "source": [
    "mp_trainer = MLM(cfg, cuda=cfg['cuda'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/51 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "  0%|                                                                                           | 0/51 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 0:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-060c60656420>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmp_trainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[0mepoch_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-0edb74e6b38d>\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconst_word_vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlemma_vec\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mA_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlambs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         loss = log_lik = norm*F.binary_cross_entropy(A_pred.view(-1), \n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "epochs = cfg['epochs']\n",
    "for epoch in tqdm(range(cfg['epochs'] + 1)):\n",
    "    if epoch > int(epochs*0.8):\n",
    "        for g in mp_trainer.optim.param_groups:\n",
    "            g['lr'] = g['lr']/10\n",
    "\n",
    "#     f1_macro_test, prec_macro_test, recall_macro_test, accuracy_test = test_performance(test_loader,\n",
    "#                                                                                         mp_trainer,\n",
    "#                                                                                         num_of_classes = cfg['output_dimesion'])\n",
    "#     f1_macro_train, prec_macro_train, recall_macro_train, accuracy_train = test_performance(train_loader,\n",
    "#                                                                                             mp_trainer,\n",
    "#                                                                                             num_of_classes = cfg['output_dimesion'])\n",
    "#     # Save vals for test:\n",
    "#     performance['acc_test'].append(accuracy_test)\n",
    "#     performance['prec_test'].append(prec_macro_test)\n",
    "#     performance['f1_test'].append(f1_macro_test)\n",
    "#     performance['recall_test'].append(recall_macro_test)\n",
    "\n",
    "#     # Save vals for train:\n",
    "#     performance['acc_train'].append(accuracy_train)\n",
    "#     performance['prec_train'].append(prec_macro_train)\n",
    "#     performance['f1_train'].append(f1_macro_train)\n",
    "#     performance['recall_train'].append(recall_macro_train)\n",
    "\n",
    "#     with open(cfg['logfilename'], 'a+') as logfile:\n",
    "#         logfile.write('On test we have accuracy = {}, f1 = {}, prec = {}, recall = {}\\n'.format(accuracy_test,\n",
    "#                                                                                                 f1_macro_test,\n",
    "#                                                                                                 prec_macro_test,\n",
    "#                                                                                                 recall_macro_test))\n",
    "#         logfile.write('On train we have accuracy = {}, f1 = {}, prec = {}, recall = {}\\n'.format(accuracy_train,\n",
    "#                                                                                                 f1_macro_train,\n",
    "#                                                                                                 prec_macro_train,\n",
    "#                                                                                                 recall_macro_train))\n",
    "\n",
    "#     if accuracy_test > best_accuracy:\n",
    "#         mp_trainer.save(cfg['trainerfilename'])\n",
    "#         with open(cfg['logfilename'], 'a+') as logfile:\n",
    "#             logfile.write(\n",
    "#                 'New best model with accuracy = {} saved at {}\\n'.format(accuracy_test, cfg['trainerfilename']))\n",
    "#         best_accuracy = accuracy_test\n",
    "#     else:\n",
    "#         with open(cfg['logfilename'], 'a+') as logfile:\n",
    "#             logfile.write('Best model has accuracy = {}\\n'.format(best_accuracy))\n",
    "\n",
    "#     # save current performance.\n",
    "#     json.dump(performance, open(repo_name + 'performance.json', 'w'))\n",
    "#     # plot performance\n",
    "#     visualize_performance(performance, repo_name)\n",
    "\n",
    "    if epoch == range(cfg['epochs']):\n",
    "        # It's the last epoch, don't train again.\n",
    "        break\n",
    "\n",
    "    print('Train epoch {}:'.format(epoch))\n",
    "    epoch_loss = []\n",
    "    for i, batch in tqdm(enumerate(train_loader)):\n",
    "        loss = mp_trainer.update(batch)\n",
    "        epoch_loss.append(float(loss.detach()))\n",
    "        print(loss)\n",
    "        if i % 50 == 0:\n",
    "            with open(cfg['logfilename'], 'a+') as logfile:\n",
    "                logfile.write('sample {} of {} in epoch {} of {}.\\n'.format(i,\n",
    "                                                                            len(train_loader),\n",
    "                                                                            epoch,\n",
    "                                                                            cfg['epochs']))\n",
    "\n",
    "    #performance['loss'].append(np.mean(np.array(epoch_loss)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10,64,450"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MISC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([20, 64, 64])\n",
      "torch.Size([1, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "for batch in test_loader:\n",
    "    #print(np.shape(batch))\n",
    "    print(np.shape(batch[0]))\n",
    "    #print(batch[0][3][2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"election on an anti-slavery platform, an initial seven slave states declared their secession from the country to form the Confederacy. War broke out in April 1861 \"\n",
    "        \n",
    "doc = nlp(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "election on an anti-slavery platform, an initial seven slave states declared their secession from the country to form the Confederacy. War broke out in April 1861 "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(64-len(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(doc) <64:\n",
    "    txt = txt + ' PAD'*(63-len(doc))\n",
    "    doc = nlp(txt)\n",
    "elif len(doc) > 64:\n",
    "    doc = doc[:64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9114,\n",
       " 114,\n",
       " 117,\n",
       " 2873,\n",
       " 30,\n",
       " 7398,\n",
       " 1,\n",
       " 28,\n",
       " 117,\n",
       " 7540,\n",
       " 6888,\n",
       " 7323,\n",
       " 16878,\n",
       " 301,\n",
       " 191,\n",
       " 1,\n",
       " 455,\n",
       " 8,\n",
       " 5943,\n",
       " 6,\n",
       " 3110,\n",
       " 8,\n",
       " 1,\n",
       " 37,\n",
       " 4693,\n",
       " 6097,\n",
       " 220,\n",
       " 125,\n",
       " 14842,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.map([token.text for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['election',\n",
       " 'on',\n",
       " 'an',\n",
       " 'anti',\n",
       " '-',\n",
       " 'slavery',\n",
       " 'platform',\n",
       " ',',\n",
       " 'an',\n",
       " 'initial',\n",
       " 'seven',\n",
       " 'slave',\n",
       " 'states',\n",
       " 'declared',\n",
       " 'their',\n",
       " 'secession',\n",
       " 'from',\n",
       " 'the',\n",
       " 'country',\n",
       " 'to',\n",
       " 'form',\n",
       " 'the',\n",
       " 'Confederacy',\n",
       " '.',\n",
       " 'War',\n",
       " 'broke',\n",
       " 'out',\n",
       " 'in',\n",
       " 'April',\n",
       " '1861',\n",
       " ' ',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.text for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOUN',\n",
       " 'ADP',\n",
       " 'DET',\n",
       " 'ADJ',\n",
       " 'ADJ',\n",
       " 'ADJ',\n",
       " 'NOUN',\n",
       " 'PUNCT',\n",
       " 'DET',\n",
       " 'ADJ',\n",
       " 'NUM',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'VERB',\n",
       " 'PRON',\n",
       " 'NOUN',\n",
       " 'ADP',\n",
       " 'DET',\n",
       " 'NOUN',\n",
       " 'PART',\n",
       " 'VERB',\n",
       " 'DET',\n",
       " 'PROPN',\n",
       " 'PUNCT',\n",
       " 'NOUN',\n",
       " 'VERB',\n",
       " 'ADP',\n",
       " 'ADP',\n",
       " 'PROPN',\n",
       " 'NUM',\n",
       " 'SPACE',\n",
       " 'PROPN',\n",
       " 'PROPN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'PROPN',\n",
       " 'PROPN',\n",
       " 'PROPN']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.pos_ for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['election',\n",
       " 'on',\n",
       " 'an',\n",
       " 'anti',\n",
       " '-',\n",
       " 'slavery',\n",
       " 'platform',\n",
       " ',',\n",
       " 'an',\n",
       " 'initial',\n",
       " 'seven',\n",
       " 'slave',\n",
       " 'state',\n",
       " 'declare',\n",
       " 'their',\n",
       " 'secession',\n",
       " 'from',\n",
       " 'the',\n",
       " 'country',\n",
       " 'to',\n",
       " 'form',\n",
       " 'the',\n",
       " 'Confederacy',\n",
       " '.',\n",
       " 'war',\n",
       " 'break',\n",
       " 'out',\n",
       " 'in',\n",
       " 'April',\n",
       " '1861',\n",
       " ' ',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'pad',\n",
       " 'pad',\n",
       " 'pad',\n",
       " 'pad',\n",
       " 'pad',\n",
       " 'pad',\n",
       " 'pad',\n",
       " 'pad',\n",
       " 'pad',\n",
       " 'pad',\n",
       " 'pad',\n",
       " 'pad',\n",
       " 'pad',\n",
       " 'pad',\n",
       " 'pad',\n",
       " 'pad',\n",
       " 'pad',\n",
       " 'pad',\n",
       " 'pad',\n",
       " 'pad',\n",
       " 'pad',\n",
       " 'pad',\n",
       " 'pad',\n",
       " 'pad',\n",
       " 'pad',\n",
       " 'pad',\n",
       " 'pad',\n",
       " 'pad',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.lemma_ for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj, root_id = doc_to_adj(doc, directed=False, self_loop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 1., 0., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 1.],\n",
       "        [0., 0., 0.,  ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = vocab.map([token.text for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = vocab.map([token.text for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random array of floats in equal dimension to input_ids\n",
    "rand = torch.rand(np.shape(vocab.map([token.text for token in doc])))\n",
    "# where the random array is less than 0.15, we set true\n",
    "mask_arr = rand < 0.15\n",
    "mask_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create selection from mask_arr\n",
    "selection = torch.flatten((mask_arr).nonzero()).tolist()\n",
    "selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in selection: \n",
    "    inputs[i] = 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
