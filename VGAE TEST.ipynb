{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import argparse\n",
    "\n",
    "\n",
    "# class Config()\n",
    "\n",
    "\n",
    "def visualize_config(args):\n",
    "    \"\"\"\n",
    "    Visualize the configuration on the terminal to check the state\n",
    "    :param args:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    print(\"\\nUsing this arguments check it\\n\")\n",
    "    for key, value in sorted(vars(args).items()):\n",
    "        if value is not None:\n",
    "            print(\"{} -- {} --\".format(key, value))\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--load_config',\n",
    "                        dest='config.ymal',\n",
    "                        # type=argparse.FileType(mode='r'),\n",
    "                        help='The yaml configuration file')\n",
    "    args, unprocessed_args = parser.parse_known_args()\n",
    "\n",
    "    # parser.add_argument('--data_root', default=None, required=True, help='The data folder')\n",
    "    # parser.add_argument('--phase', default=None, required=True, help='train or val')\n",
    "\n",
    "    if args.config_file:\n",
    "        with open(args.config_file, 'r') as f:\n",
    "            parser.set_defaults(**yaml.load(f))\n",
    "\n",
    "    args = parser.parse_args(unprocessed_args)\n",
    "    visualize_config(args)\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'dataset': \"Cora\",\n",
    "\n",
    "'enc_in_channels': 1433,\n",
    "'enc_hidden_channels': 32,\n",
    "'enc_out_channels': 16,\n",
    "\n",
    "'lr': 0.01,\n",
    "'epoch': 400}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn.models import InnerProductDecoder, VGAE\n",
    "from torch_geometric.nn.conv import GCNConv\n",
    "from torch_geometric.utils import negative_sampling, remove_self_loops, add_self_loops\n",
    "\n",
    "\n",
    "class GCNEncoder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCNEncoder, self).__init__()\n",
    "        self.gcn_shared = GCNConv(in_channels, hidden_channels)\n",
    "        self.gcn_mu = GCNConv(hidden_channels, out_channels)\n",
    "        self.gcn_logvar = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.gcn_shared(x, edge_index))\n",
    "        mu = self.gcn_mu(x, edge_index)\n",
    "        logvar = self.gcn_logvar(x, edge_index)\n",
    "        return mu, logvar\n",
    "\n",
    "\n",
    "class DeepVGAE(VGAE):\n",
    "    def __init__(self, args):\n",
    "        super(DeepVGAE, self).__init__(encoder=GCNEncoder(args['enc_in_channels'],\n",
    "                                                          args['enc_hidden_channels'],\n",
    "                                                          args['enc_out_channels']),\n",
    "                                       decoder=InnerProductDecoder())\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        z = self.encode(x, edge_index)\n",
    "        adj_pred = self.decoder.forward_all(z)\n",
    "        return adj_pred\n",
    "\n",
    "    def loss(self, x, pos_edge_index, all_edge_index):\n",
    "        z = self.encode(x, pos_edge_index)\n",
    "\n",
    "        pos_loss = -torch.log(\n",
    "            self.decoder(z, pos_edge_index, sigmoid=True) + 1e-15).mean()\n",
    "\n",
    "        # Do not include self-loops in negative samples\n",
    "        all_edge_index_tmp, _ = remove_self_loops(all_edge_index)\n",
    "        all_edge_index_tmp, _ = add_self_loops(all_edge_index_tmp)\n",
    "\n",
    "        neg_edge_index = negative_sampling(all_edge_index_tmp, z.size(0), pos_edge_index.size(1))\n",
    "        neg_loss = -torch.log(1 - self.decoder(z, neg_edge_index, sigmoid=True) + 1e-15).mean()\n",
    "\n",
    "        kl_loss = 1 / x.size(0) * self.kl_loss()\n",
    "\n",
    "        return pos_loss + neg_loss + kl_loss\n",
    "\n",
    "    def single_test(self, x, train_pos_edge_index, test_pos_edge_index, test_neg_edge_index):\n",
    "        with torch.no_grad():\n",
    "            z = self.encode(x, train_pos_edge_index)\n",
    "        roc_auc_score, average_precision_score = self.test(z, test_pos_edge_index, test_neg_edge_index)\n",
    "        return roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Basit\\Anaconda3\\lib\\site-packages\\torch_geometric\\deprecation.py:12: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], val_pos_edge_index=[2, 263], test_pos_edge_index=[2, 527], train_pos_edge_index=[2, 8976], train_neg_adj_mask=[2708, 2708], val_neg_edge_index=[2, 263], test_neg_edge_index=[2, 527])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "\n",
    "\n",
    "torch.manual_seed(12345)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "\n",
    "model = DeepVGAE(args).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=args['lr'])\n",
    "\n",
    "os.makedirs(\"datasets\", exist_ok=True)\n",
    "dataset = Planetoid(\"datasets\", args['dataset'], transform=T.NormalizeFeatures())\n",
    "data = dataset[0].to(device)\n",
    "all_edge_index = data.edge_index\n",
    "data = train_test_split_edges(data, 0.05, 0.1)\n",
    "print(data)\n",
    "\n",
    "for epoch in range(args['epoch']):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    break\n",
    "    loss = model.loss(data.x, data.train_pos_edge_index, all_edge_index)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 2 == 0:\n",
    "        model.eval()\n",
    "        roc_auc, ap = model.single_test(data.x,\n",
    "                                        data.train_pos_edge_index,\n",
    "                                        data.test_pos_edge_index,\n",
    "                                        data.test_neg_edge_index)\n",
    "        print(\"Epoch {} - Loss: {} ROC_AUC: {} Precision: {}\".format(epoch, loss.cpu().item(), roc_auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
